{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP69LnHqxImm"
      },
      "source": [
        "# Welcome to Multi-agent Training using IPPO!\n",
        "You will be responsible for completing two functions below (you can search for `NotImplementedError` functions to skip straight to them!) Once you have instantiated those, you will be able to run all cells and begin training your IPPO policies!\n",
        "\n",
        "This tutorial will walk you through code for teaching a robotic ant to walk!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![GIF](https://gymnasium.farama.org/_images/ant.gif)"
      ],
      "metadata": {
        "id": "7CR6wuERXMor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, we will treat each of the ant's 4 legs as seperate agents:\n",
        "\n",
        "![Diagram](https://robotics.farama.org/_images/ant_2x4.png)\n",
        "\n",
        "As such, Agent 1 will control joints 0 and 1, Agent 2 will control joints 2 and 3, etc."
      ],
      "metadata": {
        "id": "1Qyn-a8tYNhw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D33ZbVWLUjW6"
      },
      "source": [
        "# Intial Setup\n",
        "In this section we just install the necessary packages and download the `demo.xml` file from the shared drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3pMsdx9MUZNm",
        "outputId": "2910ea35-fed7-44fc-95b9-fc8dd48e025b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n",
            "Requirement already satisfied: equinox in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: brax in /usr/local/lib/python3.11/dist-packages (0.12.4)\n",
            "Requirement already satisfied: distreqx in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
            "Requirement already satisfied: jax>=0.4.38 in /usr/local/lib/python3.11/dist-packages (from equinox) (0.5.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.20 in /usr/local/lib/python3.11/dist-packages (from equinox) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from equinox) (4.14.1)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from equinox) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from brax) (1.4.0)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.11/dist-packages (from brax) (1.13.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from brax) (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (from brax) (6.0.1)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (from brax) (0.10.6)\n",
            "Requirement already satisfied: jaxlib>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from brax) (0.5.3)\n",
            "Requirement already satisfied: jaxopt in /usr/local/lib/python3.11/dist-packages (from brax) (0.8.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from brax) (3.1.6)\n",
            "Requirement already satisfied: ml-collections in /usr/local/lib/python3.11/dist-packages (from brax) (1.1.0)\n",
            "Requirement already satisfied: mujoco in /usr/local/lib/python3.11/dist-packages (from brax) (3.3.4)\n",
            "Requirement already satisfied: mujoco-mjx in /usr/local/lib/python3.11/dist-packages (from brax) (3.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from brax) (2.0.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from brax) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from brax) (0.11.20)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from brax) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from brax) (1.16.1)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.11/dist-packages (from brax) (2.6.4)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (from brax) (4.7.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.38->equinox) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.38->equinox) (3.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (3.1.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax->brax) (1.1.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax->brax) (0.1.76)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax->brax) (13.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax->brax) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax->brax) (0.1.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->brax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->brax) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->brax) (0.1.2)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.11/dist-packages (from mujoco->brax) (2.9.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco->brax) (3.1.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco->brax) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco->brax) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco->brax) (3.23.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->brax) (0.1.90)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->brax) (0.12.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (24.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (3.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx->brax) (25.0)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ulG1WBbTFxkr2N9Yuf7DbGWSjBZBN04j\n",
            "From (redirected): https://drive.google.com/uc?id=1ulG1WBbTFxkr2N9Yuf7DbGWSjBZBN04j&confirm=t&uuid=3e549b3e-92de-45a0-ab2e-a5d88377733a\n",
            "To: /content/demo.xml\n",
            "100% 5.92k/5.92k [00:00<00:00, 11.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip                # Update pip\n",
        "!pip install equinox brax distreqx        # Install neccesary libraries\n",
        "!gdown 1ulG1WBbTFxkr2N9Yuf7DbGWSjBZBN04j  # Download demo.xml file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA_dbJeiVzOS"
      },
      "source": [
        "# Multi-Agent Reinforcement Learning\n",
        "This code is set up to perform the neccesary inputs once and be able to run all cells below to develop the classes and helper functions needed to train policies. Each agent in the scenario will be modelled by an ActorCritic object, which internally handles the parameters for its Multi-Layer-Preceptron(MLP)/Artifical-Neural-Network(ANN) machine learning model.\n",
        "\n",
        "We also have a training environment class `IPPO_Ant_Env` which takes in our description of the Ant robot in `demo.xml` and creates a high-fidelity simulator which can be vectorized (meaning we can make many many copies of the training environment at once and load them onto a GPU for very fast computation!)\n",
        "\n",
        "We then have seperate training functions **(some of which you will have to fill in as part of your assignment)** which uses our ActorCritic networks to sample trajectories from our IPPO_Ant_env training environment and update the network parameters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1bsq6K6SAP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w0rLfSFfZfTJ"
      },
      "outputs": [],
      "source": [
        "# Environment Wrapper\n",
        "import os, json\n",
        "from datetime import datetime\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "from jaxtyping import Array, PRNGKeyArray\n",
        "import optax\n",
        "import equinox as eqx\n",
        "from tensorboardX import SummaryWriter\n",
        "import mujoco as mj # we use mj to change some foundational things in the simulation\n",
        "from brax import math # this contains some useful things, like safe_norm and quaternion utils\n",
        "from typing import Dict, Literal, Optional, Tuple, Callable, List, Union, NamedTuple, Sequence\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Mujoco/BRAX requires our env inherits from PipelineEnv, and the state used is State\n",
        "from brax.envs.base import PipelineEnv, State\n",
        "\n",
        "# mjcf interprets Mujoco XML files for BRAX, html will render rollouts of BRAX States\n",
        "from brax.io import mjcf, html\n",
        "\n",
        "import distreqx.distributions as dist\n",
        "import dataclasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRYezQvGIS5l"
      },
      "source": [
        "## Training Code (Assignment Functions are here!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HGJyIxT-ZFe2"
      },
      "outputs": [],
      "source": [
        "def make_train(env, train_config, rng_init):\n",
        "    # create a directory for saving the model and logs\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_path = f'data/ippo_ant/{current_datetime}'\n",
        "    os.makedirs(save_path, exist_ok=False)\n",
        "    writer = SummaryWriter(log_dir=save_path)\n",
        "    with open(os.path.join(save_path, 'config.json'), 'w') as f:\n",
        "        json.dump(train_config, f, indent=4)\n",
        "\n",
        "    train_config[\"NUM_ACTORS\"] = env.num_agents * train_config[\"NUM_ENVS\"]\n",
        "    train_config[\"NUM_UPDATES\"] = (\n",
        "        train_config[\"TOTAL_TIMESTEPS\"] // train_config[\"NUM_STEPS\"] // train_config[\"NUM_ENVS\"]\n",
        "    )\n",
        "    train_config[\"MINIBATCH_SIZE\"] = (\n",
        "        train_config[\"NUM_ACTORS\"] * train_config[\"NUM_STEPS\"] // train_config[\"NUM_MINIBATCHES\"]\n",
        "    )\n",
        "\n",
        "    def linear_schedule(count):\n",
        "        frac = 1.0 - (count // (train_config[\"NUM_MINIBATCHES\"] * train_config[\"UPDATE_EPOCHS\"])) / train_config[\"NUM_UPDATES\"]\n",
        "        return config[\"LR\"] * frac\n",
        "\n",
        "    network = ActorCritic(\n",
        "        key=rng_init,\n",
        "        actor_layer_sizes=[env.observation_space(env.agents[0]).shape[0], 64, 64, env.action_space(env.agents[0]).shape[0]],\n",
        "        critic_layer_sizes=[env.observation_space(env.agents[0]).shape[0], 64, 64, 1],\n",
        "        actor_kernel_init=[jnp.sqrt(2), jnp.sqrt(2), 0.01],\n",
        "        critic_kernel_init=[jnp.sqrt(2), jnp.sqrt(2), 1],\n",
        "        activation=jax.nn.tanh,\n",
        "    )\n",
        "\n",
        "    if config[\"ANNEAL_LR\"]:\n",
        "        opt = optax.chain(\n",
        "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
        "            optax.adam(learning_rate=linear_schedule, eps=1e-5),\n",
        "        )\n",
        "    else:\n",
        "        opt = optax.chain(\n",
        "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
        "            optax.adam(config[\"LR\"], eps=1e-5)\n",
        "        )\n",
        "\n",
        "    opt_state = opt.init(network)\n",
        "\n",
        "    def train(rng):\n",
        "        # INIT ENV\n",
        "        rng, _rng = jr.split(rng)\n",
        "        reset_rng = jr.split(_rng, config[\"NUM_ENVS\"])\n",
        "        obsv, env_state = jax.vmap(env.reset)(reset_rng)\n",
        "\n",
        "        # TRAIN LOOP\n",
        "        def _update_step(runner_state, unused):\n",
        "            # COLLECT TRAJECTORIES\n",
        "            def _env_step(runner_state, unused):\n",
        "                network, opt_state, env_state, last_obs, update_count, rng = runner_state\n",
        "                obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "                # SELECT ACTION\n",
        "                rng, _rng = jr.split(rng)\n",
        "                mean, scale, value = eqx.filter_vmap(network)(obs_batch)\n",
        "\n",
        "                pi = eqx.filter_vmap(dist.MultivariateNormalDiag)(mean, scale)\n",
        "                pi_log_prob = lambda d, a: d.log_prob(a)  # helper for filter_vmap\n",
        "                action = pi.sample(_rng)\n",
        "                log_prob = eqx.filter_vmap(pi_log_prob)(pi, action)\n",
        "\n",
        "                env_act = unbatchify(action, env.agents, config[\"NUM_ENVS\"], env.num_agents)\n",
        "\n",
        "                # STEP ENV\n",
        "                rng, _rng = jr.split(rng)\n",
        "                rng_step = jr.split(_rng, config[\"NUM_ENVS\"])\n",
        "                obsv, env_state, reward, done, info = jax.vmap(env.step)(\n",
        "                    rng_step, env_state, env_act,\n",
        "                )\n",
        "\n",
        "                info = jax.tree.map(lambda x: x.reshape((config[\"NUM_ACTORS\"])), info)\n",
        "                transition = Transition(\n",
        "                    batchify(done, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    action,\n",
        "                    value,\n",
        "                    batchify(reward, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    log_prob,\n",
        "                    obs_batch,\n",
        "                    info,\n",
        "                )\n",
        "                runner_state = (network, opt_state, env_state, obsv, update_count, rng)\n",
        "                return runner_state, transition\n",
        "\n",
        "            runner_state, traj_batch = filter_scan(\n",
        "                _env_step, runner_state, None, config[\"NUM_STEPS\"]\n",
        "            )\n",
        "            # CALCULATE ADVANTAGE\n",
        "            network, opt_state, env_state, last_obs, update_count, rng = runner_state\n",
        "\n",
        "            last_obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "            _, _, last_val = eqx.filter_vmap(network)(last_obs_batch)\n",
        "\n",
        "            def _calculate_gae(traj_batch, last_val):\n",
        "                def _get_advantages(gae_and_next_value, transition) -> Tuple[Tuple[jax.Array, jax.Array], jax.Array]:\n",
        "                    gae, next_value = gae_and_next_value\n",
        "                    done, value, reward = (transition.done, transition.value,transition.reward,)\n",
        "                    gamma = config[\"GAMMA\"] * (1 - done)\n",
        "                    gae_lambda = config[\"GAE_LAMBDA\"]\n",
        "\n",
        "                    # raise NotImplementedError('GAE Calculation not implemented yet!')\n",
        "                    # TODO: USE THE INPUTS TO CALCULATE THE GAE\n",
        "                    delta = reward + gamma * next_value - value\n",
        "                    gae = delta + gamma * gae_lambda * gae\n",
        "\n",
        "                    return (gae, value), gae\n",
        "\n",
        "                _, advantages = jax.lax.scan(\n",
        "                    _get_advantages,\n",
        "                    (jnp.zeros_like(last_val), last_val),\n",
        "                    traj_batch,\n",
        "                    reverse=True,\n",
        "                    unroll=8,\n",
        "                )\n",
        "                return advantages, advantages + traj_batch.value\n",
        "\n",
        "            advantages, targets = _calculate_gae(traj_batch, last_val)\n",
        "\n",
        "            # UPDATE NETWORK\n",
        "            def _update_epoch(update_state, unused):\n",
        "                def _update_minbatch(train_state, batch_info):\n",
        "                    traj_batch, advantages, targets = batch_info\n",
        "\n",
        "                    def _loss_fn(network, traj_batch, gae, targets):\n",
        "                        # RERUN NETWORK\n",
        "                        mean, scale, value = eqx.filter_vmap(network)(traj_batch.obs)\n",
        "                        pi = eqx.filter_vmap(dist.MultivariateNormalDiag)(mean, scale)\n",
        "                        pi_log_prob = lambda d, a: d.log_prob(a)  # helper for filter_vmap\n",
        "                        log_prob = eqx.filter_vmap(pi_log_prob)(pi, traj_batch.action)\n",
        "\n",
        "                        # CALCULATE VALUE LOSS\n",
        "                        value_pred_clipped = traj_batch.value + (\n",
        "                            value - traj_batch.value\n",
        "                        ).clip(-config[\"CLIP_EPS\"], config[\"CLIP_EPS\"])\n",
        "                        value_losses = jnp.square(value - targets)\n",
        "                        value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
        "                        value_loss = (\n",
        "                            0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
        "                        )\n",
        "\n",
        "                        # CALCULATE ACTOR LOSS\n",
        "                        gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
        "\n",
        "                        def _loss_actor(log_prob, log_prob_k, normalized_gae, clip_epsilon):\n",
        "                          # raise NotImplementedError('Actor Loss not implemented yet!')\n",
        "                          # TODO: USE THE INPUTS TO THIS FUNCTION TO CALCULATE THE ACTOR LOSS\n",
        "                          loss_actor = jnp.minimum(jnp.exp(log_prob - log_prob_k) * normalized_gae, jnp.clip(jnp.exp(log_prob - log_prob_k), 1 - clip_epsilon, 1 + clip_epsilon) * normalized_gae)\n",
        "\n",
        "                          return loss_actor\n",
        "\n",
        "                        loss_actor = -_loss_actor(log_prob, traj_batch.log_prob, gae, config[\"CLIP_EPS\"]).mean()\n",
        "\n",
        "                        pi_entropy = lambda d: d.entropy()\n",
        "                        entropy = eqx.filter_vmap(pi_entropy)(pi).mean()\n",
        "                        ratio = jnp.exp(log_prob - traj_batch.log_prob) # Calculate ratio here\n",
        "\n",
        "                        total_loss = (\n",
        "                            loss_actor\n",
        "                            + config[\"VF_COEF\"] * value_loss\n",
        "                            - config[\"ENT_COEF\"] * entropy\n",
        "                        )\n",
        "                        return total_loss, (value_loss, loss_actor, entropy, ratio)\n",
        "\n",
        "                    network, opt_state = train_state\n",
        "                    grad_fn = eqx.filter_value_and_grad(_loss_fn, has_aux=True)\n",
        "                    total_loss, grads = grad_fn(network, traj_batch, advantages, targets)\n",
        "                    updates, opt_state = opt.update(grads, opt_state)\n",
        "                    network = eqx.apply_updates(network, updates)\n",
        "\n",
        "                    loss_info = {\n",
        "                        \"total_loss\": total_loss[0],\n",
        "                        \"actor_loss\": total_loss[1][1],\n",
        "                        \"critic_loss\": total_loss[1][0],\n",
        "                        \"entropy\": total_loss[1][2],\n",
        "                        \"ratio\": total_loss[1][3],\n",
        "                    }\n",
        "                    return (network, opt_state), loss_info\n",
        "                network, opt_state, traj_batch, advantages, targets, rng = update_state\n",
        "\n",
        "                rng, _rng = jr.split(rng)\n",
        "                batch_size = config[\"MINIBATCH_SIZE\"] * config[\"NUM_MINIBATCHES\"]\n",
        "                assert (\n",
        "                    batch_size == config[\"NUM_STEPS\"] * config[\"NUM_ACTORS\"]\n",
        "                ), \"batch size must be equal to number of steps * number of actors\"\n",
        "                permutation = jr.permutation(_rng, batch_size)\n",
        "                batch = (traj_batch, advantages, targets)\n",
        "                batch = jax.tree.map(\n",
        "                    lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n",
        "                )\n",
        "                shuffled_batch = jax.tree.map(\n",
        "                    lambda x: jnp.take(x, permutation, axis=0), batch\n",
        "                )\n",
        "                minibatches = jax.tree.map(\n",
        "                    lambda x: jnp.reshape(\n",
        "                        x, [config[\"NUM_MINIBATCHES\"], -1] + list(x.shape[1:])\n",
        "                    ),\n",
        "                    shuffled_batch,\n",
        "                )\n",
        "                (network, opt_state), loss_info = filter_scan(\n",
        "                    _update_minbatch, (network, opt_state), minibatches\n",
        "                )\n",
        "                update_state = (network, opt_state, traj_batch, advantages, targets, rng)\n",
        "                return update_state, loss_info\n",
        "\n",
        "            def callback(metric):\n",
        "                step = metric[\"update_step\"]\n",
        "                for key, value in metric.items():\n",
        "                    if key != \"update_step\":\n",
        "                        writer.add_scalar(key, value, step)\n",
        "\n",
        "            update_state = (network, opt_state, traj_batch, advantages, targets, rng)\n",
        "\n",
        "            update_state, loss_info = filter_scan(\n",
        "                _update_epoch, update_state, None, config[\"UPDATE_EPOCHS\"]\n",
        "            )\n",
        "            network, opt_state = update_state[0], update_state[1]\n",
        "\n",
        "            metric = traj_batch.info\n",
        "            rng = update_state[-1]\n",
        "\n",
        "            update_count = update_count + 1\n",
        "            r0 = {\"ratio0\": loss_info[\"ratio\"][0,0].mean()}\n",
        "            loss_info = jax.tree.map(lambda x: x.mean(), loss_info)\n",
        "            metric = jax.tree.map(lambda x: x.mean(), metric)\n",
        "            metric[\"update_step\"] = update_count\n",
        "            metric[\"env_step\"] = update_count * config[\"NUM_STEPS\"] * config[\"NUM_ENVS\"]\n",
        "            metric = {**metric, **loss_info, **r0}\n",
        "            jax.experimental.io_callback(callback, None, metric)\n",
        "            runner_state = (network, opt_state, env_state, last_obs, update_count, rng)\n",
        "            return runner_state, metric\n",
        "\n",
        "        rng, _rng = jr.split(rng)\n",
        "        runner_state = (network, opt_state, env_state, obsv, jnp.array(0), _rng)\n",
        "        runner_state, metric = filter_scan(\n",
        "            _update_step, runner_state, None, config[\"NUM_UPDATES\"]\n",
        "        )\n",
        "\n",
        "        current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        eqx.tree_serialise_leaves(f\"data/training_network_{current_datetime}.eqx\", network)\n",
        "        return {\"runner_state\": runner_state, \"metrics\": metric, \"network\": network}\n",
        "\n",
        "    return train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_KpuEg6Yh8R"
      },
      "source": [
        "## Our Actor-Critic Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BctJ-vimV1xr"
      },
      "outputs": [],
      "source": [
        "class ActorCritic(eqx.Module):\n",
        "    \"\"\"\n",
        "    This is a feed forward actor critic combined module. This is useful for IPPO\n",
        "    where we modify both the actor and critic simultaneously and therefore can\n",
        "    group the actor and critic together here and use optax to get an optimization\n",
        "    state across the entire eqx.Module\n",
        "    \"\"\"\n",
        "\n",
        "    # Learned variables\n",
        "    actor_layers: Tuple[eqx.nn.Linear, ...]\n",
        "    critic_layers: Tuple[eqx.nn.Linear, ...]\n",
        "    log_std: jax.Array\n",
        "\n",
        "    # Static parameters\n",
        "    activation: Callable = eqx.field(static=True)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        key: jr.PRNGKey,\n",
        "        actor_layer_sizes: List[int] = [6, 64, 64, 2],\n",
        "        critic_layer_sizes: List[int] = [6, 64, 64, 1],\n",
        "        actor_kernel_init: List[float] = [jnp.sqrt(2), jnp.sqrt(2), 0.01],\n",
        "        critic_kernel_init: List[float] = [jnp.sqrt(2), jnp.sqrt(2), 1.0],\n",
        "        activation: Callable = jax.nn.relu,\n",
        "    ):\n",
        "        self.activation = activation\n",
        "        actor_key, critic_key = jr.split(key)\n",
        "\n",
        "        # —— actor network ——\n",
        "        actor_keys = jr.split(actor_key, num=len(actor_layer_sizes))\n",
        "        self.actor_layers = []\n",
        "\n",
        "        for i, (in_f, out_f) in enumerate(\n",
        "            zip(actor_layer_sizes[:-1], actor_layer_sizes[1:])\n",
        "        ):\n",
        "            layer = eqx.nn.Linear(in_f, out_f, key=actor_keys[i])\n",
        "\n",
        "            # (Re‑)initialise using orthogonal(scale) + constant(0) bias\n",
        "            wkey, _ = jr.split(actor_keys[i])\n",
        "            weight = jax.nn.initializers.orthogonal(actor_kernel_init[i])(\n",
        "                wkey, (out_f, in_f), jnp.float32\n",
        "            )\n",
        "            bias = jnp.zeros((out_f,), dtype=jnp.float32)\n",
        "\n",
        "            # Update the layer – eqx Modules are frozen, so use object.__setattr__\n",
        "            object.__setattr__(layer, \"weight\", weight)\n",
        "            object.__setattr__(layer, \"bias\", bias)\n",
        "\n",
        "            self.actor_layers.append(layer)\n",
        "\n",
        "        # —— critic network ——\n",
        "        critic_keys = jr.split(critic_key, len(critic_layer_sizes) - 1)\n",
        "        self.critic_layers = []\n",
        "\n",
        "        for i, (in_f, out_f) in enumerate(\n",
        "            zip(critic_layer_sizes[:-1], critic_layer_sizes[1:])\n",
        "        ):\n",
        "            layer = eqx.nn.Linear(in_f, out_f, key=critic_keys[i])\n",
        "\n",
        "            wkey, _ = jr.split(critic_keys[i])\n",
        "            weight = jax.nn.initializers.orthogonal(critic_kernel_init[i])(\n",
        "                wkey, (out_f, in_f), jnp.float32\n",
        "            )\n",
        "            bias = jnp.zeros((out_f,), dtype=jnp.float32)\n",
        "\n",
        "            object.__setattr__(layer, \"weight\", weight)\n",
        "            object.__setattr__(layer, \"bias\", bias)\n",
        "\n",
        "            self.critic_layers.append(layer)\n",
        "\n",
        "        # —— learnable log‑std parameter ——\n",
        "        self.log_std = jnp.zeros((actor_layer_sizes[-1],))  # broadcasted over batch at runtime\n",
        "\n",
        "    def __call__(self, x: jax.Array) -> Tuple[jax.Array, jax.Array, jax.Array]:\n",
        "        \"\"\"Returns (policy_dist, value_estimate) for an input batch `x`.\"\"\"\n",
        "\n",
        "        # —— actor ——\n",
        "        h = x\n",
        "        for layer in self.actor_layers[:-1]:\n",
        "            h = self.activation(layer(h))\n",
        "        actor_mean = self.actor_layers[-1](h)                        # (B, action_dim)\n",
        "        actor_scale = jnp.exp(self.log_std)\n",
        "\n",
        "        # —— critic ——\n",
        "        h = x\n",
        "        for layer in self.critic_layers[:-1]:\n",
        "            h = self.activation(layer(h))\n",
        "        value = jnp.squeeze(self.critic_layers[-1](h), axis=-1)      # (B,)\n",
        "\n",
        "        return actor_mean, actor_scale, value\n",
        "\n",
        "\n",
        "def filter_scan(f, init, xs, length=None, reverse=False, unroll=1):\n",
        "    \"\"\"\n",
        "    although simple to implement equinox does not by default include a filter_scan\n",
        "    function; see: https://github.com/patrick-kidger/equinox/issues/709\n",
        "    \"\"\"\n",
        "\n",
        "    # Partition the initial carry and sequence inputs into dynamic and static parts\n",
        "    init_dynamic, init_static = eqx.partition(init, eqx.is_array)\n",
        "    xs_dynamic, xs_static = eqx.partition(xs, eqx.is_array)\n",
        "\n",
        "    # Define the scanned function, handling the combination and partitioning\n",
        "    def scanned_fn(carry_dynamic, x_dynamic):\n",
        "        # Combine dynamic and static parts for the carry and input\n",
        "        carry = eqx.combine(carry_dynamic, init_static)\n",
        "        x = eqx.combine(x_dynamic, xs_static)\n",
        "\n",
        "        # Apply the original function\n",
        "        out_carry, out_y = f(carry, x)\n",
        "\n",
        "        # Partition the outputs into dynamic and static parts\n",
        "        out_carry_dynamic, out_carry_static = eqx.partition(out_carry, eqx.is_array)\n",
        "        out_y_dynamic, out_y_static = eqx.partition(out_y, eqx.is_array)\n",
        "\n",
        "        # Return dynamic outputs and wrap static outputs using Static to prevent tracing\n",
        "        return out_carry_dynamic, (out_y_dynamic, eqx.internal.Static((out_carry_static, out_y_static)))\n",
        "\n",
        "    # Use lax.scan with the modified scanned function\n",
        "    final_carry_dynamic, (ys_dynamic, static_out) = jax.lax.scan(\n",
        "        scanned_fn, init_dynamic, xs_dynamic, length=length, reverse=reverse, unroll=unroll\n",
        "    )\n",
        "\n",
        "    # Extract static outputs\n",
        "    out_carry_static, ys_static = static_out.value\n",
        "\n",
        "    # Combine dynamic and static parts of the outputs\n",
        "    final_carry = eqx.combine(final_carry_dynamic, out_carry_static)\n",
        "    ys = eqx.combine(ys_dynamic, ys_static)\n",
        "\n",
        "    return final_carry, ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnlM4z669Ytw"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ECo-U6Ck9pRW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Built off Gymnax spaces.py, this module contains jittable classes for action and\n",
        "observation spaces.\n",
        "\"\"\"\n",
        "class Space(object):\n",
        "    \"\"\"\n",
        "    Minimal jittable class for abstract jaxmarl space.\n",
        "    \"\"\"\n",
        "\n",
        "    def sample(self, rng: PRNGKeyArray) -> Array:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def contains(self, x: jnp.int_) -> bool: # pyright: ignore\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Box(Space):\n",
        "\t\"\"\"\n",
        "\tMinimal jittable class for array-shaped gymnax spaces.\n",
        "\tAdd unboundedness - sampling from other distributions, etc.\n",
        "\t\"\"\"\n",
        "\tdef __init__(\n",
        "\t\tself,\n",
        "\t\tlow: float,\n",
        "\t\thigh: float,\n",
        "\t\tshape: Tuple[int],\n",
        "\t\tdtype: jnp.dtype = jnp.float32,\n",
        "\t):\n",
        "\t\tself.low = low\n",
        "\t\tself.high = high\n",
        "\t\tself.shape = shape\n",
        "\t\tself.dtype = dtype\n",
        "\n",
        "\tdef sample(self, rng: PRNGKeyArray) -> Array:\n",
        "\t\t\"\"\"Sample random action uniformly from 1D continuous range.\"\"\"\n",
        "\t\treturn jax.random.uniform(\n",
        "\t\t\trng, shape=self.shape, minval=self.low, maxval=self.high\n",
        "\t\t).astype(self.dtype)\n",
        "\n",
        "\tdef contains(self, x: jnp.int_) -> bool: # pyright: ignore\n",
        "\t\t\"\"\"Check whether specific object is within space.\"\"\"\n",
        "\t\t# type_cond = isinstance(x, self.dtype)\n",
        "\t\t# shape_cond = (x.shape == self.shape)\n",
        "\t\trange_cond = jnp.logical_and(\n",
        "\t\t\tjnp.all(x >= self.low), jnp.all(x <= self.high)\n",
        "\t\t)\n",
        "\t\treturn range_cond\n",
        "\n",
        "class Transition(NamedTuple):\n",
        "  done: jnp.ndarray\n",
        "  action: jnp.ndarray\n",
        "  value: jnp.ndarray\n",
        "  reward: jnp.ndarray\n",
        "  log_prob: jnp.ndarray\n",
        "  obs: jnp.ndarray\n",
        "  info: jnp.ndarray\n",
        "\n",
        "def batchify(x: dict, agent_list, num_actors):\n",
        "    max_dim = max([x[a].shape[-1] for a in agent_list])\n",
        "    def pad(z):\n",
        "        return jnp.concatenate([z, jnp.zeros(z.shape[:-1] + (max_dim - z.shape[-1],))], -1)\n",
        "    x = jnp.stack([x[a] if x[a].shape[-1] == max_dim else pad(x[a]) for a in agent_list])\n",
        "    return x.reshape((num_actors, -1))\n",
        "\n",
        "def unbatchify(x: jnp.ndarray, agent_list, num_envs, num_actors):\n",
        "    x = x.reshape((num_actors, num_envs, -1))\n",
        "    return {a: x[i] for i, a in enumerate(agent_list)}\n",
        "\n",
        "class LogEnvState(NamedTuple):\n",
        "    env_state: State\n",
        "    episode_returns: float\n",
        "    episode_lengths: int\n",
        "    returned_episode_returns: float\n",
        "    returned_episode_lengths: int\n",
        "    step_in_episode: jnp.ndarray\n",
        "    first_pipeline_state: State\n",
        "    first_obs: jnp.ndarray\n",
        "    truncation: jnp.ndarray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXnX38fSad9_"
      },
      "source": [
        "## IPPO Training Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EYPHudGYadBA"
      },
      "outputs": [],
      "source": [
        "# LEAVE EVERYTHING IN THIS CELL UNCHANGED FOR ASSIGNMENT\n",
        "\n",
        "\n",
        "# we must map each agent to their observations and actions in the whole environment\n",
        "# This is a helper function to convert the ranges of observations\n",
        "def listerize(ranges: List[Union[int, Tuple[int, int]]]) -> List[int]:\n",
        "    \"\"\"\n",
        "    tuples mean that all global observations indexed from (0, 5) are included in that agents observation\n",
        "    integers add that single global observation to the agent's observation\n",
        "    in this case I am passing global observations to each agent for simplicity.\n",
        "    Here is an example:\n",
        "\n",
        "    ranges = {\n",
        "        \"agent_0\": [(0,8)], # example: [(0, 5), 6, 7] == [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "        \"agent_1\": [(0,8)] # example: [(2, 5), 9, 10] == [2, 3, 4, 5, 9, 10]\n",
        "    }\n",
        "    agent_obs_mapping = {k: jnp.array(listerize(v)) for k, v in ranges.items()} # _agent_observation_mapping[env_name]\n",
        "    \"\"\"\n",
        "    return [\n",
        "        i\n",
        "        for r in ranges\n",
        "        for i in (range(r[0], r[1] + 1) if isinstance(r, tuple) else [r])\n",
        "    ]\n",
        "\n",
        "# ================================ #\n",
        "# Our Multi-agent Ant Training Environment!\n",
        "# ================================ #\n",
        "class IPPO_Ant_Env(PipelineEnv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        mode: Literal[\"centralized\", \"decentralized\"] = \"decentralized\",\n",
        "\n",
        "        # base env settings\n",
        "        xml_path='demo.xml',\n",
        "        backend='positional', # this is important for the ant\n",
        "        ctrl_cost_weight=0.5,\n",
        "        use_contact_forces=False,\n",
        "        contact_cost_weight=5e-4,\n",
        "        healthy_reward=1.0,\n",
        "        terminate_when_unhealthy=True,\n",
        "        healthy_z_range=(0.2, 1.0),\n",
        "        contact_force_range=(-1.0, 1.0),\n",
        "        reset_noise_scale=0.1,\n",
        "        exclude_current_positions_from_observation=True,\n",
        "\n",
        "        # multi agent env settings\n",
        "        episode_length: int = 1000,\n",
        "        action_repeat: int = 1,\n",
        "        auto_reset: bool = True,\n",
        "        homogenisation_method: Optional[Literal[\"max\", \"concat\"]] = None,\n",
        "\n",
        "        # logging settings\n",
        "        replace_info: bool = False,\n",
        "        **kwargs\n",
        "    ):\n",
        "\n",
        "        # ============================= #\n",
        "        # Mujoco/BRAX System Init #\n",
        "        # ============================= #\n",
        "\n",
        "        # brax provides utils to load xml file into mujoco\n",
        "        sys = mjcf.load(xml_path)\n",
        "\n",
        "        # n_frames are the number of simulation timesteps between new actions\n",
        "        # in the interim we zero-order-hold the previous action\n",
        "        n_frames = 5\n",
        "\n",
        "        # in the case of the Ant the physics backed matters, and they reduce the physics timestep\n",
        "        # from 0.01 to 0.005 and double n_frames to keep the interaction timestep the same.\n",
        "        # I speculate that the increased fidelity of the timestep for these backends is required\n",
        "        # for reliable, robust physics calculations\n",
        "        if backend in ['spring', 'positional']:\n",
        "            sys = sys.tree_replace({'opt.timestep': 0.005})\n",
        "            n_frames = 10\n",
        "\n",
        "        # again more examples of using the \"sys\" to modify fundamental parts of the simulator.\n",
        "        if backend == 'mjx':\n",
        "            sys = sys.tree_replace({\n",
        "                'opt.solver': mj.mjtSolver.mjSOL_NEWTON, # this determins how we solve contact forces\n",
        "                'opt.disableflags': mj.mjtDisableBit.mjDSBL_EULERDAMP, # I believe this damping term stabilizes some dynamics\n",
        "                'opt.iterations': 1, # number of optimization iterations for contact\n",
        "                'opt.ls_iterations': 4, # number of line search iterations per optimization iteration for contact\n",
        "            })\n",
        "\n",
        "        # again more examples of using the \"sys\" to modify fundamental parts of the simulator\n",
        "        if backend == 'positional':\n",
        "            # does the same actuator strength work as in spring\n",
        "            sys = sys.replace(\n",
        "                actuator=sys.actuator.replace(\n",
        "                    gear=200 * jnp.ones_like(sys.actuator.gear)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # the kwargs are designed to pass options to the brax backend, in this case we\n",
        "        # modify the kwargs n_frames according to the above code before passing it to super\n",
        "        kwargs['n_frames'] = kwargs.get('n_frames', n_frames)\n",
        "\n",
        "        # actually creating the BRAX system\n",
        "        super().__init__(sys=sys, backend=backend, **kwargs)\n",
        "\n",
        "        # various parameters for the Ant environment\n",
        "        self._ctrl_cost_weight = ctrl_cost_weight\n",
        "        self._use_contact_forces = use_contact_forces\n",
        "        self._contact_cost_weight = contact_cost_weight\n",
        "        self._healthy_reward = healthy_reward\n",
        "        self._terminate_when_unhealthy = terminate_when_unhealthy\n",
        "        self._healthy_z_range = healthy_z_range\n",
        "        self._contact_force_range = contact_force_range\n",
        "        self._reset_noise_scale = reset_noise_scale\n",
        "        self._exclude_current_positions_from_observation = (\n",
        "            exclude_current_positions_from_observation\n",
        "        )\n",
        "        if self._use_contact_forces:\n",
        "            raise NotImplementedError('use_contact_forces not implemented.')\n",
        "\n",
        "\n",
        "        # ================================== #\n",
        "        # Multi-Agent Environment Init #\n",
        "        # ================================== #\n",
        "\n",
        "        # UNCHANGED logging settings\n",
        "        self.replace_info = replace_info\n",
        "        self.episode_length = episode_length\n",
        "        self.action_repeat = action_repeat\n",
        "        self.auto_reset = auto_reset\n",
        "        self.homogenisation_method = homogenisation_method\n",
        "\n",
        "        # tuples mean that all global observations indexed from (0, 5) are included in that agents observation\n",
        "        # integers add that single global observation to the agent's observation\n",
        "        # in this case I am passing global observations to each agent for simplicity\n",
        "        ranges = {\n",
        "            # below is an example, also check out the listerize helper function above\n",
        "            \"agent_0\": [(0, 5), 6, 7, 9, 11, (13, 18), 19, 20],\n",
        "            \"agent_1\": [(0, 5), 7, 8, 9, 11, (13, 18), 21, 22],\n",
        "            \"agent_2\": [(0, 5), 7, 9, 10, 11, (13, 18), 23, 24],\n",
        "            \"agent_3\": [(0, 5), 7, 9, 11, 12, (13, 18), 25, 26],\n",
        "        }\n",
        "        self.agent_obs_mapping = {k: jnp.array(listerize(v)) for k, v in ranges.items()} # _agent_observation_mapping[env_name]\n",
        "\n",
        "        # the agent action mapping is simpler, so we just use the indices of the actions\n",
        "        self.agent_action_mapping = {\n",
        "            \"agent_0\": jnp.array([0, 1]),\n",
        "            \"agent_1\": jnp.array([2, 3]),\n",
        "            \"agent_2\": jnp.array([4, 5]),\n",
        "            \"agent_3\": jnp.array([6, 7]),\n",
        "        }\n",
        "        self.agents = list(self.agent_obs_mapping.keys())\n",
        "\n",
        "        # ======================================================== #\n",
        "        # UNCHANGED: Boilerplate That Doesn't Require Modification #\n",
        "        # ======================================================== #\n",
        "\n",
        "        # setup the obs and action spaces for each agent\n",
        "        self.num_agents = len(self.agent_obs_mapping)\n",
        "        obs_sizes = {\n",
        "            agent: self.num_agents\n",
        "            + max([o.size for o in self.agent_obs_mapping.values()])\n",
        "            if homogenisation_method == \"max\"\n",
        "            else self.env.observation_size\n",
        "            if homogenisation_method == \"concat\"\n",
        "            else obs.size\n",
        "            for agent, obs in self.agent_obs_mapping.items()\n",
        "        }\n",
        "        act_sizes = {\n",
        "            agent: max([a.size for a in self.agent_action_mapping.values()])\n",
        "            if homogenisation_method == \"max\"\n",
        "            else self.env.action_size\n",
        "            if homogenisation_method == \"concat\"\n",
        "            else act.size\n",
        "            for agent, act in self.agent_action_mapping.items()\n",
        "        }\n",
        "        self.observation_spaces = {\n",
        "            agent: Box(-jnp.inf, jnp.inf, shape=(obs_sizes[agent],),)\n",
        "            for agent in self.agents\n",
        "        }\n",
        "        self.action_spaces = {\n",
        "            agent: Box(-1.0, 1.0, shape=(act_sizes[agent],),)\n",
        "            for agent in self.agents\n",
        "        }\n",
        "\n",
        "        # utility function to batchify floats originally placed in JaxMARLWrapper\n",
        "        self._batchify_floats = lambda x: jnp.stack([x[a] for a in self.agents])\n",
        "\n",
        "        # utility function to get obs, action spaces for each agent - required by the ppo algs\n",
        "        self.observation_space = lambda agent: self.observation_spaces[agent]\n",
        "        self.action_space = lambda agent: self.action_spaces[agent]\n",
        "\n",
        "    # ======================================== #\n",
        "    # design global observation function #\n",
        "    # ======================================== #\n",
        "\n",
        "    def get_global_obs(self, pipeline_state: State) -> jax.Array:\n",
        "\n",
        "        # the pipeline_state is an attribute of env_state, which in turn is an attribute of state.\n",
        "        # pipeline_state is what defines the physical simulation state, primarily through\n",
        "        # pipeline_state.q and pipeline_state.qd which are the generalized positions and\n",
        "        # velocities respectively. The rest of pipeline_state is read_only and useful\n",
        "        # for creating expressive observations - as we can do in this function\n",
        "\n",
        "        qpos = pipeline_state.q\n",
        "        qvel = pipeline_state.qd\n",
        "\n",
        "        if self._exclude_current_positions_from_observation:\n",
        "            qpos = pipeline_state.q[2:]\n",
        "\n",
        "        return jnp.concatenate([qpos] + [qvel])\n",
        "\n",
        "    # ================================================= #\n",
        "    # design pipeline_state random reset function #\n",
        "    # ================================================= #\n",
        "\n",
        "    def get_random_pipeline_state(self, rng):\n",
        "\n",
        "        # here you must decide how to randomly instantiate the generalized positions and\n",
        "        # velocities q, and qd of the pipeline_state and then create the pipeline_state\n",
        "        # to be used in the reset function and the automatic reset functionality later on.\n",
        "        # I will explain the automatic reset later! fear not!\n",
        "\n",
        "        rng, rng1, rng2 = jax.random.split(rng, 3)\n",
        "\n",
        "        low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
        "        q = self.sys.init_q + jax.random.uniform(\n",
        "            rng1, (self.sys.q_size(),), minval=low, maxval=hi\n",
        "        )\n",
        "        qd = hi * jax.random.normal(rng2, (self.sys.qd_size(),))\n",
        "\n",
        "        pipeline_state = self.pipeline_init(q, qd)\n",
        "        return pipeline_state\n",
        "\n",
        "    def reset(self, rng: jr.PRNGKey) -> Tuple[Dict[str, jax.Array], State]:\n",
        "        # =========================== #\n",
        "        # ResetS the environment #\n",
        "        # =========================== #\n",
        "\n",
        "        # reset the global environment as you see fit for your environment. You\n",
        "        # should end up with a new env_state: State and agent_obs: Dict[str, jax.Array]\n",
        "        # as the below example does. NOTE you should also include the exact same info\n",
        "        # dict in the resulting env_state as the example does.\n",
        "\n",
        "        pipeline_state = self.get_random_pipeline_state(rng); rng, _ = jr.split(rng)\n",
        "        global_obs = self.get_global_obs(pipeline_state)\n",
        "\n",
        "        reward, done, zero = jnp.zeros(3)\n",
        "        metrics = {\n",
        "            'reward_forward': zero,\n",
        "            'reward_survive': zero,\n",
        "            'reward_ctrl': zero,\n",
        "            'reward_contact': zero,\n",
        "            'x_position': zero,\n",
        "            'y_position': zero,\n",
        "            'distance_from_origin': zero,\n",
        "            'x_velocity': zero,\n",
        "            'y_velocity': zero,\n",
        "            'forward_reward': zero,\n",
        "        }\n",
        "\n",
        "        # NOTE it is essential that info is created like this and added to env_state\n",
        "        info = {\n",
        "            \"returned_episode_returns\": jnp.zeros(self.num_agents),\n",
        "            \"returned_episode_lengths\": jnp.zeros(self.num_agents),\n",
        "            \"returned_episode\": jnp.zeros(self.num_agents).astype(jnp.bool_)\n",
        "        }\n",
        "\n",
        "        env_state = State(pipeline_state, global_obs, reward, done, metrics, info)\n",
        "\n",
        "        agent_obs = self.map_global_obs_to_agents(global_obs)\n",
        "\n",
        "        # ============================= #\n",
        "        # UNCHANGED: log state wrapping #\n",
        "        # ============================= #\n",
        "\n",
        "        # NOTE we change the \"first_pipeline_state\" and \"first_obs\" at every\n",
        "        # usage, therefore we generate a new pair here to be used as the first\n",
        "        # upon the next automatic reset in step - I will explain the automatic reset\n",
        "        # later! fear not!\n",
        "\n",
        "        new_first_pipeline_state = self.get_random_pipeline_state(rng)\n",
        "        new_first_obs = self.get_global_obs(new_first_pipeline_state)\n",
        "\n",
        "        # the struct we use to log the agent observations and the env state\n",
        "        log_state = LogEnvState(\n",
        "            env_state,\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((), jnp.int32), # the env step number in the current rollout\n",
        "            new_first_pipeline_state,\n",
        "            new_first_obs,\n",
        "            jnp.array(0.)\n",
        "        )\n",
        "\n",
        "        return agent_obs, log_state\n",
        "\n",
        "    def step(\n",
        "        self,\n",
        "        rng: jr.PRNGKey, # this is not used in our deterministic env\n",
        "        state: State, # this is the LogEnvState\n",
        "        actions: Dict[str, jax.Array], # this is the agentic actions\n",
        "    ) -> Tuple[\n",
        "        Dict[str, jax.Array], State, Dict[str, float], Dict[str, bool], Dict\n",
        "    ]:\n",
        "\n",
        "        # We first ensure that states that were previously done (that already\n",
        "        # have had their states reset) have their done flag reset\n",
        "        state = state._replace(\n",
        "            env_state=state.env_state.replace(\n",
        "                done=jnp.zeros_like(state.env_state.done)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # =============================================================== #\n",
        "        # global env_state step (reward, obs, state, metrics, done) #\n",
        "        # =============================================================== #\n",
        "        # here we calculate the global reward, obs, state, metrics, and the global_done\n",
        "        # NOTE the global_done is only for early termination (the end of episode termination\n",
        "        # situation is handled later automatically - look through the remainder of this\n",
        "        # method to understand)\n",
        "\n",
        "        # we get the global actions\n",
        "        global_action = self.map_agents_to_global_action(actions)\n",
        "\n",
        "        # save the old pipeline_state to calculate some velocities\n",
        "        pipeline_state0 = state.env_state.pipeline_state\n",
        "        assert pipeline_state0 is not None\n",
        "\n",
        "        # get the NEXT pipeline state yaaay\n",
        "        next_pipeline_state = self.pipeline_step(state.env_state.pipeline_state, global_action)  # type: ignore\n",
        "\n",
        "        # environment specific calculations\n",
        "        velocity = (next_pipeline_state.x.pos[0] - pipeline_state0.x.pos[0]) / self.dt\n",
        "        forward_reward = velocity[0]\n",
        "\n",
        "        min_z, max_z = self._healthy_z_range\n",
        "\n",
        "        is_healthy = jnp.where(next_pipeline_state.x.pos[0, 2] < min_z, 0.0, 1.0)\n",
        "        is_healthy = jnp.where(next_pipeline_state.x.pos[0, 2] > max_z, 0.0, is_healthy)\n",
        "\n",
        "        if self._terminate_when_unhealthy:\n",
        "            healthy_reward = self._healthy_reward\n",
        "        else:\n",
        "            healthy_reward = self._healthy_reward * is_healthy\n",
        "        ctrl_cost = self._ctrl_cost_weight * jnp.sum(jnp.square(global_action))\n",
        "        contact_cost = 0.0\n",
        "\n",
        "        # finalise the global_obs, global_reward, and global_done (just for early termination)\n",
        "        global_obs = self.get_global_obs(next_pipeline_state)\n",
        "        global_reward = forward_reward + healthy_reward - ctrl_cost - contact_cost\n",
        "        global_done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
        "\n",
        "        # finally we update the environment specific metrics that you have chosen to track\n",
        "        state.env_state.metrics.update(\n",
        "            reward_forward=forward_reward,\n",
        "            reward_survive=healthy_reward,\n",
        "            reward_ctrl=-ctrl_cost,\n",
        "            reward_contact=-contact_cost,\n",
        "            x_position=next_pipeline_state.x.pos[0, 0],\n",
        "            y_position=next_pipeline_state.x.pos[0, 1],\n",
        "            distance_from_origin=math.safe_norm(next_pipeline_state.x.pos[0]),\n",
        "            x_velocity=velocity[0],\n",
        "            y_velocity=velocity[1],\n",
        "            forward_reward=forward_reward,\n",
        "        )\n",
        "\n",
        "        # agent obs is formed AFTER we decide if the env is reset or not as this will\n",
        "        # change the state which we observe\n",
        "\n",
        "        # ==================================================================== #\n",
        "        # UNCHANGED: Episode Wrapping Step (brax.envs.wrappers.EpisodeWrapper) #\n",
        "        # ==================================================================== #\n",
        "\n",
        "        step_in_episode = state.step_in_episode + self.action_repeat\n",
        "\n",
        "        global_done = jnp.where(step_in_episode >= self.episode_length, jnp.ones_like(state.env_state.done), global_done)\n",
        "        state = state._replace(\n",
        "            truncation = jnp.where(\n",
        "                step_in_episode >= jnp.array(self.episode_length), 1 - global_done, jnp.zeros_like(state.env_state.done)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # ===================================== #\n",
        "        # Agentic Rewards Dones Transform #\n",
        "        # ===================================== #\n",
        "        # default behaviour is just to give all agents same global reward\n",
        "        reward = {agent: global_reward for agent in self.agents}\n",
        "        reward[\"__all__\"] = global_reward\n",
        "        done = {agent: global_done.astype(jnp.bool_) for agent in self.agents}\n",
        "        done[\"__all__\"] = global_done.astype(jnp.bool_)\n",
        "\n",
        "        # create new env_state here in ase global rewards or global dones rely on agentic things\n",
        "        env_state = state.env_state.replace(\n",
        "            pipeline_state=next_pipeline_state,\n",
        "            obs=global_obs,\n",
        "            reward=global_reward,\n",
        "            done=global_done\n",
        "        )\n",
        "\n",
        "        # ============================================================================== #\n",
        "        # UNCHANGED: Auto Reset Wrapping Post-Step (brax.envs.wrappers.AutoResetWrapper) #\n",
        "        # ============================================================================== #\n",
        "        def where_done(x, y):\n",
        "            done = env_state.done\n",
        "            if done.shape:\n",
        "                done = jnp.reshape(done, [x.shape[0]] + [1] * (len(x.shape) - 1))  # type: ignore\n",
        "            return jnp.where(done, x, y)\n",
        "\n",
        "\n",
        "        next_pipeline_state = jax.tree.map(\n",
        "            where_done, state.first_pipeline_state, env_state.pipeline_state\n",
        "        )\n",
        "\n",
        "        global_obs = jax.tree.map(where_done, state.first_obs, global_obs)\n",
        "        env_state = env_state.replace(pipeline_state=next_pipeline_state, obs=global_obs)\n",
        "        agent_obs = self.map_global_obs_to_agents(global_obs)\n",
        "\n",
        "        first_pipeline_state = self.get_random_pipeline_state(rng); rng, _ = jr.split(rng)\n",
        "        first_obs = self.get_global_obs(first_pipeline_state)\n",
        "        state = state._replace(\n",
        "            first_pipeline_state=first_pipeline_state,\n",
        "            first_obs=first_obs\n",
        "        )\n",
        "\n",
        "        if self.auto_reset is True:\n",
        "            step_in_episode = jnp.where(env_state.done, jnp.zeros_like(step_in_episode), step_in_episode)\n",
        "            state = state._replace(step_in_episode=step_in_episode)\n",
        "\n",
        "        # ======================= #\n",
        "        # UNCHANGED: Log wrapping #\n",
        "        # ======================= #\n",
        "        ep_done = done[\"__all__\"]\n",
        "        new_episode_return = state.episode_returns + self._batchify_floats(reward)\n",
        "        new_episode_length = state.episode_lengths + 1\n",
        "        state = state._replace(\n",
        "            env_state=env_state,\n",
        "            episode_returns=new_episode_return * (1 - ep_done),\n",
        "            episode_lengths=new_episode_length * (1 - ep_done),\n",
        "            returned_episode_returns=state.returned_episode_returns * (1 - ep_done)\n",
        "            + new_episode_return * ep_done,\n",
        "            returned_episode_lengths=state.returned_episode_lengths * (1 - ep_done)\n",
        "            + new_episode_length * ep_done,\n",
        "            step_in_episode=step_in_episode\n",
        "        )\n",
        "\n",
        "        info = env_state.info\n",
        "        if self.replace_info:\n",
        "            info = {}\n",
        "        info[\"returned_episode_returns\"] = state.returned_episode_returns\n",
        "        info[\"returned_episode_lengths\"] = state.returned_episode_lengths\n",
        "        info[\"returned_episode\"] = jnp.full((self.num_agents,), ep_done)\n",
        "\n",
        "        return agent_obs, state, reward, done, info\n",
        "\n",
        "    # ================================================================ #\n",
        "    # UNCHANGED: mapping agent actions and obs to and from global actions and obs #\n",
        "    # ================================================================ #\n",
        "    def map_agents_to_global_action(\n",
        "        self, agent_actions: Dict[str, jnp.ndarray]\n",
        "    ) -> jnp.ndarray:\n",
        "        global_action = jnp.zeros(self.action_size)\n",
        "        for agent_name, action_indices in self.agent_action_mapping.items():\n",
        "            if self.homogenisation_method == \"max\":\n",
        "                global_action = global_action.at[action_indices].set(\n",
        "                    agent_actions[agent_name][: action_indices.size]\n",
        "                )\n",
        "            elif self.homogenisation_method == \"concat\":\n",
        "                global_action = global_action.at[action_indices].set(\n",
        "                    agent_actions[agent_name][action_indices]\n",
        "                )\n",
        "            else:\n",
        "                global_action = global_action.at[action_indices].set(\n",
        "                    agent_actions[agent_name]\n",
        "                )\n",
        "        return global_action\n",
        "\n",
        "    def map_global_obs_to_agents(self, global_obs: jax.Array) -> Dict[str, jax.Array]:\n",
        "        \"\"\"Maps the global observation vector to the individual agent observations.\n",
        "        Args:\n",
        "            global_obs: The global observation vector.\n",
        "        Returns:\n",
        "            A dictionary mapping agent names to their observations. The mapping method\n",
        "            is determined by the homogenisation_method parameter.\n",
        "        \"\"\"\n",
        "        agent_obs = {}\n",
        "        for agent_idx, (agent_name, obs_indices) in enumerate(\n",
        "            self.agent_obs_mapping.items()\n",
        "        ):\n",
        "            if self.homogenisation_method == \"max\":\n",
        "                # Vector with the agent idx one-hot encoded as the first num_agents\n",
        "                # elements and then the agent's own observations (zero padded to\n",
        "                # the size of the largest agent observation vector)\n",
        "                agent_obs[agent_name] = (\n",
        "                    jnp.zeros(\n",
        "                        self.num_agents\n",
        "                        + max([v.size for v in self.agent_obs_mapping.values()])\n",
        "                    )\n",
        "                    .at[agent_idx]\n",
        "                    .set(1)\n",
        "                    .at[agent_idx + 1 : agent_idx + 1 + obs_indices.size]\n",
        "                    .set(global_obs[obs_indices])\n",
        "                )\n",
        "            elif self.homogenisation_method == \"concat\":\n",
        "                # Zero vector except for the agent's own observations\n",
        "                # (size of the global observation vector)\n",
        "                agent_obs[agent_name] = (\n",
        "                    jnp.zeros(global_obs.shape)\n",
        "                    .at[obs_indices]\n",
        "                    .set(global_obs[obs_indices])\n",
        "                )\n",
        "            else:\n",
        "                # Just agent's own observations\n",
        "                agent_obs[agent_name] = global_obs[obs_indices]\n",
        "        return agent_obs\n",
        "\n",
        "def IPPO_generate_rollout(env, rng, jit=True, num_timesteps=100):\n",
        "    agent_obs, state = env.reset(rng=rng); rng, _rng = jr.split(rng)\n",
        "    rollout = []\n",
        "    if jit is True:\n",
        "        env_step = jax.jit(env.step)\n",
        "    else:\n",
        "        env_step = env.step\n",
        "    ctrl = jr.uniform(_rng, shape=(env.action_size), minval=-1, maxval=1)\n",
        "\n",
        "    agents = env.agents\n",
        "    agent_ctrls = {\"agent_0\": ctrl[:2], \"agent_1\": ctrl[2:4], \"agent_2\": ctrl[4:6], \"agent_3\": ctrl[6:]}\n",
        "    for i in range(num_timesteps):\n",
        "        print(f\"ctrl action chosen: {ctrl}\")\n",
        "        agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "        print(f\"state.done: {done}\")\n",
        "        print(f\"state.reward: {reward}\")\n",
        "        rollout.append(state.env_state.pipeline_state)\n",
        "        print(f\"step: {i}\")\n",
        "        print(f\"info: {info}\")\n",
        "        if i == env.episode_length:\n",
        "            print(\"THE PRIOR STATE.DONE SHOULD HAVE BEEN TRUE\")\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_name = f'data/rollouts/{current_datetime}.html'\n",
        "    os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "    with open(save_name, 'w') as f:\n",
        "        f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))\n",
        "\n",
        "def generate_rollout(env, policy, rng, jit=True, num_timesteps=100):\n",
        "    agent_obs, state = env.reset(rng=rng); rng, _rng = jr.split(rng)\n",
        "    rollout = []\n",
        "    if jit is True:\n",
        "        env_step = jax.jit(env.step)\n",
        "    else:\n",
        "        env_step = env.step\n",
        "    ctrl = network(agent_obs)\n",
        "\n",
        "    agents = env.agents\n",
        "    agent_ctrls = {\"agent_0\": ctrl[:2], \"agent_1\": ctrl[2:4], \"agent_2\": ctrl[4:6], \"agent_3\": ctrl[6:]}\n",
        "    # agent_ctrls = {agents[i]: ctrl[:2], \"agent_1\": ctrl[2:]}\n",
        "    for i in range(num_timesteps):\n",
        "        print(f\"ctrl action chosen: {ctrl}\")\n",
        "        agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "        print(f\"state.done: {done}\")\n",
        "        print(f\"state.reward: {reward}\")\n",
        "        rollout.append(state.env_state.pipeline_state)\n",
        "        print(f\"step: {i}\")\n",
        "        print(f\"info: {info}\")\n",
        "        if i == env.episode_length:\n",
        "            print(\"THE PRIOR STATE.DONE SHOULD HAVE BEEN TRUE\")\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_name = f'data/rollouts/{current_datetime}.html'\n",
        "    os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "    with open(save_name, 'w') as f:\n",
        "        f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj2Nd-Vd6NLu"
      },
      "source": [
        "## Perform IPPO Training\n",
        "\n",
        "Here we can begin training our IPPO policies! The first time you run this cell, set `debug_mode` to `True` so that you can ensure that all code has been compiled correctly. **Note: This will print out a lot of information**\n",
        "\n",
        "If there are no errors, turn `debug_mode` to `False` to train your IPPO policies!\n",
        "\n",
        "# ***REMEMBER TO DOWNLOAD YOUR `data/` FOLDER AFTER TRAINING!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0AdrS8-uZT0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e846c7ab-0d01-4906-a481-dcd7af5e52b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false' # dynamically allocate memory like pytorch does\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"                       # if you have NVIDIA + EGL drivers for rendering\n",
        "\n",
        "jax.config.update('jax_default_matmul_precision', \"highest\") # sometimes certain contact dynamics need higher accuracy to prevent nans\n",
        "\n",
        "# this set of configs lets us cache more values to lower JIT and thus compute times\n",
        "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
        "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
        "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)\n",
        "jax.config.update(\"jax_persistent_cache_enable_xla_caches\", \"xla_gpu_per_fusion_autotune_cache_dir\")\n",
        "\n",
        "config = {\n",
        "    \"LR\": 1e-3,\n",
        "    \"NUM_ENVS\": 64,\n",
        "    \"NUM_STEPS\": 300,\n",
        "    \"TOTAL_TIMESTEPS\": 1e7,\n",
        "    \"UPDATE_EPOCHS\": 4,\n",
        "    \"NUM_MINIBATCHES\": 4,\n",
        "    \"GAMMA\": 0.99,\n",
        "    \"GAE_LAMBDA\": 0.95,\n",
        "    \"CLIP_EPS\": 0.2,\n",
        "    \"ENT_COEF\": 2e-6,\n",
        "    \"VF_COEF\": 4.5,\n",
        "    \"MAX_GRAD_NORM\": 0.5,\n",
        "    \"SEED\": 0,\n",
        "    \"ANNEAL_LR\": True,\n",
        "    \"DEVICE\": 0,\n",
        "    \"DISABLE_JIT\": False,\n",
        "}\n",
        "\n",
        "rng = jr.PRNGKey(config[\"SEED\"])\n",
        "rng, _rng = jr.split(rng)\n",
        "env = IPPO_Ant_Env()\n",
        "agent_obs, state = env.reset(jr.PRNGKey(0))\n",
        "\n",
        "debug_mode = False\n",
        "if(debug_mode):\n",
        "  jax.config.update(\"jax_debug_nans\", True)   # will error if a nan is detected\n",
        "  jax.config.update(\"jax_log_compiles\", True) # will print out recompilations\n",
        "\n",
        "  # a single test step\n",
        "  action = {\"agent_0\": jnp.array([0.5, 0.5]), \"agent_1\": jnp.array([-0.5, -0.5]), \"agent_2\": jnp.array([-0.5, -0.5]), \"agent_3\": jnp.array([-0.5, -0.5])}\n",
        "  agent_obs, state, reward, done, info = env.step(jr.PRNGKey(0), state, action)\n",
        "\n",
        "  # a test rollout\n",
        "  IPPO_generate_rollout(env, jr.PRNGKey(0), jit=True, num_timesteps=700)\n",
        "\n",
        "# else:\n",
        "#   jax.config.update(\"jax_debug_nans\", False)\n",
        "#   jax.config.update(\"jax_log_compiles\", False)\n",
        "\n",
        "#   # Start Training!\n",
        "#   print(\"INFO: training started!\")\n",
        "#   config[\"ENV_NAME\"] = env.__class__.__name__\n",
        "#   train = make_train(env, config, _rng)\n",
        "#   train_jit = jax.jit(train, device=jax.devices()[config[\"DEVICE\"]])\n",
        "#   out = train_jit(rng)\n",
        "#   print(out)\n",
        "\n",
        "#   print(\"INFO: training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the /data to local /Desktop\n",
        "\n",
        "!zip -r /content/data.zip /content/data\n",
        "!google.colab.files.download('/content/data.zip')"
      ],
      "metadata": {
        "id": "g1ABwWyNziMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tensorboard to generate plots of results\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir data/ippo_ant"
      ],
      "metadata": {
        "id": "IT3tJDIsHKnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.keys()"
      ],
      "metadata": {
        "id": "_2D0O30raJ6Q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out['runner_state']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6y5Fc0GvqGmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax, jax.numpy as jnp, jax.random as jr\n",
        "from datetime import datetime\n",
        "import brax.io.html as html\n",
        "import os\n",
        "import equinox as eqx\n",
        "\n",
        "ckpt_path = \"/content/training_network_2025-07-31_23-25-42.eqx\"\n",
        "\n",
        "# Instantiate the environment to get the correct observation and action space sizes\n",
        "env = IPPO_Ant_Env()\n",
        "obs_size = env.observation_space(env.agents[0]).shape[0]\n",
        "action_size = env.action_space(env.agents[0]).shape[0]\n",
        "\n",
        "# Create a 'like' instance of ActorCritic with the correct layer sizes\n",
        "network_like = ActorCritic(\n",
        "    key=jr.PRNGKey(0), # The key here is just for initialization structure, actual weights are loaded\n",
        "    actor_layer_sizes=[obs_size, 64, 64, action_size],\n",
        "    critic_layer_sizes=[obs_size, 64, 64, 1],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "network = eqx.tree_deserialise_leaves(ckpt_path, network_like)\n",
        "\n",
        "\n",
        "def test_generate_rollout(env, policy, rng, jit=True, num_timesteps=100):\n",
        "    agent_obs, state = env.reset(rng=rng)\n",
        "    rng, _rng = jr.split(rng)\n",
        "    rollout = []\n",
        "\n",
        "    env_step = jax.jit(env.step) if jit else env.step\n",
        "\n",
        "    def get_actions(agent_obs_dict, rng):\n",
        "        actions = []\n",
        "        scales = []\n",
        "        for agent_id in env.agents:\n",
        "            obs = agent_obs_dict[agent_id]# [None, :]  # (1, obs_dim)\n",
        "            mean, scale, value = policy(obs)        # 不用 vmap\n",
        "            pi = dist.MultivariateNormalDiag(mean, scale)\n",
        "            action = pi.sample(rng)\n",
        "            actions.append(action)\n",
        "        return jnp.concatenate(actions)\n",
        "\n",
        "    ctrl = get_actions(agent_obs, rng); _rng, rng = jr.split(rng)\n",
        "    agent_ctrls = {\n",
        "        \"agent_0\": ctrl[:2],\n",
        "        \"agent_1\": ctrl[2:4],\n",
        "        \"agent_2\": ctrl[4:6],\n",
        "        \"agent_3\": ctrl[6:]\n",
        "    }\n",
        "\n",
        "    for i in range(num_timesteps):\n",
        "        agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "        rollout.append(state.env_state.pipeline_state)\n",
        "        print(agent_obs)\n",
        "        ctrl = get_actions(agent_obs, rng); _rng, rng = jr.split(rng)\n",
        "        print(f\"ctrl action chosen: {ctrl}\")\n",
        "        agent_ctrls = {\n",
        "            \"agent_0\": ctrl[:2],\n",
        "            \"agent_1\": ctrl[2:4],\n",
        "            \"agent_2\": ctrl[4:6],\n",
        "            \"agent_3\": ctrl[6:]\n",
        "        }\n",
        "        print(f\"state.done: {done}\")\n",
        "        print(f\"state.reward: {reward}\")\n",
        "        print(f\"step: {i}\")\n",
        "        print(f\"info: {info}\")\n",
        "\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_name = f'data/rollouts/{current_datetime}.html'\n",
        "    os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "    with open(save_name, 'w') as f:\n",
        "        f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))\n",
        "\n",
        "test_generate_rollout(env, network, rng, jit=True, num_timesteps=520)\n",
        "\n",
        "\n",
        "# def generate_rollout(env, network, rng, jit=True, num_timesteps=100):\n",
        "#     agent_obs, state = env.reset(rng=rng)\n",
        "#     agents   = env.agents\n",
        "#     env_step = jax.jit(env.step) if jit else env.step\n",
        "#     rollout  = []\n",
        "\n",
        "#     # vmap 讓 network 一次處理多隻 agent\n",
        "#     batch_forward = jax.vmap(network)          # (4,18) -> tuple_of_arrays\n",
        "\n",
        "#     for _ in range(num_timesteps):\n",
        "#         rng, step_rng = jr.split(rng)\n",
        "\n",
        "#         # 1. (4,18) 觀測矩陣\n",
        "#         obs_mat = jnp.stack([agent_obs[a] for a in agents])\n",
        "\n",
        "#         # 2. 前向推論：取回傳 tuple 的「第一項」當動作\n",
        "#         outputs = batch_forward(obs_mat)\n",
        "#         if isinstance(outputs, tuple):\n",
        "#             ctrl_mat = outputs[0]              # 取 action_mean (4,2)\n",
        "#         else:\n",
        "#             ctrl_mat = outputs                 # 已經是 (4,2)\n",
        "\n",
        "#         # 3. 還原成字典\n",
        "#         agent_ctrls = {a: row for a, row in zip(agents, ctrl_mat)}\n",
        "\n",
        "#         # 4. 環境一步\n",
        "#         agent_obs, state, reward, done, info = env_step(step_rng, state, agent_ctrls)\n",
        "#         rollout.append(state.env_state.pipeline_state)\n",
        "#         if all(done.values()):      # ⇐ 每隻 agent 都完成才 break\n",
        "#           break\n",
        "\n",
        "#     # 5. 存成 HTML\n",
        "#     ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "#     html_path = f\"data/rollouts/{ts}.html\"\n",
        "#     os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "#     with open(html_path, \"w\") as f:\n",
        "#         f.write(html.render(env.sys.tree_replace({\"opt.timestep\": env.dt}), rollout))\n",
        "#     print(f\"✅ Rollout saved to {html_path}\")\n",
        "\n",
        "# generate_rollout(env, network, rng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgHtUEgzd478",
        "outputId": "5434589d-1a4d-4fd1-fd19-4a0dcee43da9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "        0.04825592,  0.57825446, -0.40638447, -0.7642144 , -2.762092  ,\n",
            "       -0.24710447,  1.2876642 ,  7.5446076 ], dtype=float32), 'agent_2': Array([ 0.50774914,  0.11952605, -0.03622562,  0.01822266,  0.9920026 ,\n",
            "       -0.5698897 , -0.5240425 , -0.54816186, -0.9438862 , -0.54349667,\n",
            "        0.04825592,  0.57825446, -0.40638447, -0.7642144 , -2.762092  ,\n",
            "       -0.24710447,  0.37063038,  7.374226  ], dtype=float32), 'agent_3': Array([ 0.50774914,  0.11952605, -0.03622562,  0.01822266,  0.9920026 ,\n",
            "       -0.5698897 , -0.5240425 , -0.54816186, -0.54349667,  0.84743315,\n",
            "        0.04825592,  0.57825446, -0.40638447, -0.7642144 , -2.762092  ,\n",
            "       -0.24710447,  0.31830725,  5.6418076 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.7502204 -1.5491948 -1.7502468 -1.5366732 -1.75075   -1.539629\n",
            " -1.7490022 -1.537308 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.1921024, dtype=float32), 'agent_0': Array(-4.1921024, dtype=float32), 'agent_1': Array(-4.1921024, dtype=float32), 'agent_2': Array(-4.1921024, dtype=float32), 'agent_3': Array(-4.1921024, dtype=float32)}\n",
            "step: 275\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5060682 ,  0.12332882, -0.03314387,  0.04064663,  0.990979  ,\n",
            "       -0.5625063 ,  0.64486396, -0.5321224 , -0.54162765, -0.558375  ,\n",
            "        0.8196354 , -0.12711883, -0.04199743,  1.1884916 ,  0.9931982 ,\n",
            "       -0.07236685,  0.65446085, -6.5446253 ], dtype=float32), 'agent_1': Array([ 0.5060682 ,  0.12332882, -0.03314387,  0.04064663,  0.990979  ,\n",
            "       -0.5625063 , -0.5321224 , -1.0270774 , -0.54162765, -0.558375  ,\n",
            "        0.8196354 , -0.12711883, -0.04199743,  1.1884916 ,  0.9931982 ,\n",
            "       -0.07236685, -0.8874101 , -5.2847147 ], dtype=float32), 'agent_2': Array([ 0.5060682 ,  0.12332882, -0.03314387,  0.04064663,  0.990979  ,\n",
            "       -0.5625063 , -0.5321224 , -0.54162765, -1.0508242 , -0.558375  ,\n",
            "        0.8196354 , -0.12711883, -0.04199743,  1.1884916 ,  0.9931982 ,\n",
            "       -0.07236685, -0.18630545, -5.052622  ], dtype=float32), 'agent_3': Array([ 5.0606823e-01,  1.2332882e-01, -3.3143871e-02,  4.0646628e-02,\n",
            "        9.9097902e-01, -5.6250632e-01, -5.3212237e-01, -5.4162765e-01,\n",
            "       -5.5837500e-01,  6.1571211e-01,  8.1963539e-01, -1.2711883e-01,\n",
            "       -4.1997433e-02,  1.1884916e+00,  9.9319822e-01, -7.2366849e-02,\n",
            "        7.0686997e-03, -8.0278082e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.20657477 0.5678658  0.20360984 0.56965965 0.20370227 0.5701716\n",
            " 0.2073002  0.5695674 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.384408, dtype=float32), 'agent_0': Array(-9.384408, dtype=float32), 'agent_1': Array(-9.384408, dtype=float32), 'agent_2': Array(-9.384408, dtype=float32), 'agent_3': Array(-9.384408, dtype=float32)}\n",
            "step: 276\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.1203477e-01,  1.8078041e-01, -3.6402191e-03,  2.5489081e-02,\n",
            "        9.8318648e-01, -3.8955343e-01,  7.0437318e-01, -4.6269202e-01,\n",
            "       -3.8873342e-01, -4.1819203e-01,  1.1715889e-01,  5.2497983e-01,\n",
            "        3.5076141e-01, -7.0844412e-01, -1.8387024e+00, -2.5334327e+00,\n",
            "        4.0072241e+00,  3.3770351e+00], dtype=float32), 'agent_1': Array([ 5.1203477e-01,  1.8078041e-01, -3.6402191e-03,  2.5489081e-02,\n",
            "        9.8318648e-01, -3.8955343e-01, -4.6269202e-01, -9.1745842e-01,\n",
            "       -3.8873342e-01, -4.1819203e-01,  1.1715889e-01,  5.2497983e-01,\n",
            "        3.5076141e-01, -7.0844412e-01, -1.8387024e+00, -2.5334327e+00,\n",
            "        1.8934747e+00,  4.3557301e+00], dtype=float32), 'agent_2': Array([ 5.1203477e-01,  1.8078041e-01, -3.6402191e-03,  2.5489081e-02,\n",
            "        9.8318648e-01, -3.8955343e-01, -4.6269202e-01, -3.8873342e-01,\n",
            "       -9.1307819e-01, -4.1819203e-01,  1.1715889e-01,  5.2497983e-01,\n",
            "        3.5076141e-01, -7.0844412e-01, -1.8387024e+00, -2.5334327e+00,\n",
            "        3.7469957e+00,  4.4780316e+00], dtype=float32), 'agent_3': Array([ 0.5120348 ,  0.18078041, -0.00364022,  0.02548908,  0.9831865 ,\n",
            "       -0.38955343, -0.46269202, -0.38873342, -0.41819203,  0.62714666,\n",
            "        0.11715889,  0.5249798 ,  0.3507614 , -0.7084441 , -1.8387024 ,\n",
            "       -2.5334327 ,  3.4566436 ,  3.009794  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8892164  -0.07819544  0.8870865  -0.0801032   0.8888186  -0.07639766\n",
            "  0.88849336 -0.07815631]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.72185975, dtype=float32), 'agent_0': Array(0.72185975, dtype=float32), 'agent_1': Array(0.72185975, dtype=float32), 'agent_2': Array(0.72185975, dtype=float32), 'agent_3': Array(0.72185975, dtype=float32)}\n",
            "step: 277\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3968215e-01,  4.0416873e-01, -4.4430508e-03,  1.3960964e-02,\n",
            "        9.1456717e-01,  2.3282480e-01,  6.7098081e-01,  8.0561817e-02,\n",
            "        2.1378188e-01,  1.5448171e-01, -1.7127991e-01,  3.3541322e-01,\n",
            "        3.9600134e-01, -3.8622168e-01,  5.4927353e-02, -1.1684453e+01,\n",
            "        1.5383381e+01, -1.7104820e+00], dtype=float32), 'agent_1': Array([ 5.3968215e-01,  4.0416873e-01, -4.4430508e-03,  1.3960964e-02,\n",
            "        9.1456717e-01,  2.3282480e-01,  8.0561817e-02, -8.7150049e-01,\n",
            "        2.1378188e-01,  1.5448171e-01, -1.7127991e-01,  3.3541322e-01,\n",
            "        3.9600134e-01, -3.8622168e-01,  5.4927353e-02, -1.1684453e+01,\n",
            "        1.4068284e+01, -4.0981314e-01], dtype=float32), 'agent_2': Array([ 5.39682150e-01,  4.04168725e-01, -4.44305083e-03,  1.39609640e-02,\n",
            "        9.14567173e-01,  2.32824802e-01,  8.05618167e-02,  2.13781878e-01,\n",
            "       -8.78341496e-01,  1.54481709e-01, -1.71279907e-01,  3.35413218e-01,\n",
            "        3.96001339e-01, -3.86221677e-01,  5.49273528e-02, -1.16844530e+01,\n",
            "        1.48233757e+01, -1.09262116e-01], dtype=float32), 'agent_3': Array([ 5.3968215e-01,  4.0416873e-01, -4.4430508e-03,  1.3960964e-02,\n",
            "        9.1456717e-01,  2.3282480e-01,  8.0561817e-02,  2.1378188e-01,\n",
            "        1.5448171e-01,  6.3213086e-01, -1.7127991e-01,  3.3541322e-01,\n",
            "        3.9600134e-01, -3.8622168e-01,  5.4927353e-02, -1.1684453e+01,\n",
            "        1.4320921e+01, -7.7791202e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.20385477 -1.0402467   0.2018942  -1.0375644   0.20405535 -1.0339777\n",
            "  0.20331816 -1.0366323 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7514987, dtype=float32), 'agent_0': Array(-0.7514987, dtype=float32), 'agent_1': Array(-0.7514987, dtype=float32), 'agent_2': Array(-0.7514987, dtype=float32), 'agent_3': Array(-0.7514987, dtype=float32)}\n",
            "step: 278\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.541901  ,  0.5211066 , -0.0353365 ,  0.00948686,  0.85270697,\n",
            "        0.57197773,  0.46666804,  0.41638476,  0.5580014 ,  0.5159646 ,\n",
            "       -0.05373955,  0.25288463, -0.2439022 , -0.68227786,  0.51480824,\n",
            "       -0.5116133 , -0.66750777, -0.4265204 ], dtype=float32), 'agent_1': Array([ 0.541901  ,  0.5211066 , -0.0353365 ,  0.00948686,  0.85270697,\n",
            "        0.57197773,  0.41638476, -1.1438789 ,  0.5580014 ,  0.5159646 ,\n",
            "       -0.05373955,  0.25288463, -0.2439022 , -0.68227786,  0.51480824,\n",
            "       -0.5116133 ,  1.5368284 , -7.0107117 ], dtype=float32), 'agent_2': Array([ 0.541901  ,  0.5211066 , -0.0353365 ,  0.00948686,  0.85270697,\n",
            "        0.57197773,  0.41638476,  0.5580014 , -1.1350893 ,  0.5159646 ,\n",
            "       -0.05373955,  0.25288463, -0.2439022 , -0.68227786,  0.51480824,\n",
            "       -0.5116133 ,  0.3012487 , -7.431743  ], dtype=float32), 'agent_3': Array([ 0.541901  ,  0.5211066 , -0.0353365 ,  0.00948686,  0.85270697,\n",
            "        0.57197773,  0.41638476,  0.5580014 ,  0.5159646 ,  0.46307358,\n",
            "       -0.05373955,  0.25288463, -0.2439022 , -0.68227786,  0.51480824,\n",
            "       -0.5116133 ,  2.0575347 ,  0.29921183], dtype=float32)}\n",
            "ctrl action chosen: [0.93930846 1.413536   0.94664854 1.4082272  0.9448708  1.406799\n",
            " 0.9404038  1.4176898 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2863703, dtype=float32), 'agent_0': Array(-1.2863703, dtype=float32), 'agent_1': Array(-1.2863703, dtype=float32), 'agent_2': Array(-1.2863703, dtype=float32), 'agent_3': Array(-1.2863703, dtype=float32)}\n",
            "step: 279\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7826525e-01,  5.2971375e-01,  8.7793805e-03,  3.6191309e-03,\n",
            "        8.4812331e-01,  5.3416973e-01,  7.4271828e-01,  5.4920310e-01,\n",
            "        5.4568529e-01,  5.6216788e-01, -1.3012886e+00,  5.8350563e-01,\n",
            "        1.4894366e+00,  8.8628298e-01, -1.7115172e+00,  1.1734356e-01,\n",
            "       -1.2128907e+00,  7.4150429e+00], dtype=float32), 'agent_1': Array([ 5.7826525e-01,  5.2971375e-01,  8.7793805e-03,  3.6191309e-03,\n",
            "        8.4812331e-01,  5.3416973e-01,  5.4920310e-01, -9.5989108e-01,\n",
            "        5.4568529e-01,  5.6216788e-01, -1.3012886e+00,  5.8350563e-01,\n",
            "        1.4894366e+00,  8.8628298e-01, -1.7115172e+00,  1.1734356e-01,\n",
            "        2.0125124e+00,  5.9140482e+00], dtype=float32), 'agent_2': Array([ 5.7826525e-01,  5.2971375e-01,  8.7793805e-03,  3.6191309e-03,\n",
            "        8.4812331e-01,  5.3416973e-01,  5.4920310e-01,  5.4568529e-01,\n",
            "       -9.8738205e-01,  5.6216788e-01, -1.3012886e+00,  5.8350563e-01,\n",
            "        1.4894366e+00,  8.8628298e-01, -1.7115172e+00,  1.1734356e-01,\n",
            "       -9.9208242e-01,  5.4798532e+00], dtype=float32), 'agent_3': Array([ 5.7826525e-01,  5.2971375e-01,  8.7793805e-03,  3.6191309e-03,\n",
            "        8.4812331e-01,  5.3416973e-01,  5.4920310e-01,  5.4568529e-01,\n",
            "        5.6216788e-01,  7.6361614e-01, -1.3012886e+00,  5.8350563e-01,\n",
            "        1.4894366e+00,  8.8628298e-01, -1.7115172e+00,  1.1734356e-01,\n",
            "        1.1506647e-01,  7.9678531e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.08624003 -0.10223886  0.08633106 -0.08846966  0.08451981 -0.09515638\n",
            "  0.08499403 -0.09869234]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.4419184, dtype=float32), 'agent_0': Array(-5.4419184, dtype=float32), 'agent_1': Array(-5.4419184, dtype=float32), 'agent_2': Array(-5.4419184, dtype=float32), 'agent_3': Array(-5.4419184, dtype=float32)}\n",
            "step: 280\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1316681e-01,  5.0241041e-01,  2.1341609e-02,  2.4509570e-04,\n",
            "        8.6436582e-01,  4.2768848e-01,  9.5357770e-01,  5.4409695e-01,\n",
            "        4.3259189e-01,  4.7494963e-01, -9.4490051e-01,  4.3781996e-01,\n",
            "        3.3451319e-01,  2.5844154e-01, -3.7759134e-01,  1.2418780e+00,\n",
            "       -1.6070117e+00,  3.5620031e+00], dtype=float32), 'agent_1': Array([ 6.1316681e-01,  5.0241041e-01,  2.1341609e-02,  2.4509570e-04,\n",
            "        8.6436582e-01,  4.2768848e-01,  5.4409695e-01, -9.0189284e-01,\n",
            "        4.3259189e-01,  4.7494963e-01, -9.4490051e-01,  4.3781996e-01,\n",
            "        3.3451319e-01,  2.5844154e-01, -3.7759134e-01,  1.2418780e+00,\n",
            "       -8.2269543e-01,  1.1343930e+00], dtype=float32), 'agent_2': Array([ 6.1316681e-01,  5.0241041e-01,  2.1341609e-02,  2.4509570e-04,\n",
            "        8.6436582e-01,  4.2768848e-01,  5.4409695e-01,  4.3259189e-01,\n",
            "       -9.3978959e-01,  4.7494963e-01, -9.4490051e-01,  4.3781996e-01,\n",
            "        3.3451319e-01,  2.5844154e-01, -3.7759134e-01,  1.2418780e+00,\n",
            "       -1.9770135e+00,  1.0283344e+00], dtype=float32), 'agent_3': Array([ 6.1316681e-01,  5.0241041e-01,  2.1341609e-02,  2.4509570e-04,\n",
            "        8.6436582e-01,  4.2768848e-01,  5.4409695e-01,  4.3259189e-01,\n",
            "        4.7494963e-01,  9.8752660e-01, -9.4490051e-01,  4.3781996e-01,\n",
            "        3.3451319e-01,  2.5844154e-01, -3.7759134e-01,  1.2418780e+00,\n",
            "       -1.8952760e+00,  3.8912621e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.4980724  -0.7815962  -0.4969476  -0.77474725 -0.4971514  -0.7761577\n",
            " -0.49794927 -0.78072757]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.10443341, dtype=float32), 'agent_0': Array(-0.10443341, dtype=float32), 'agent_1': Array(-0.10443341, dtype=float32), 'agent_2': Array(-0.10443341, dtype=float32), 'agent_3': Array(-0.10443341, dtype=float32)}\n",
            "step: 281\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2058318e-01,  3.8174799e-01,  7.4301066e-04,  8.5647327e-05,\n",
            "        9.2426616e-01,  8.6026713e-02,  8.7826568e-01,  2.3598719e-01,\n",
            "        9.1889940e-02,  1.4345537e-01, -7.4319839e-01,  3.4689307e-01,\n",
            "       -5.0401688e-02, -4.3589631e-01,  1.5958669e+00,  6.5126824e+00,\n",
            "       -8.4677410e+00, -4.1970906e+00], dtype=float32), 'agent_1': Array([ 6.2058318e-01,  3.8174799e-01,  7.4301066e-04,  8.5647327e-05,\n",
            "        9.2426616e-01,  8.6026713e-02,  2.3598719e-01, -1.0285146e+00,\n",
            "        9.1889940e-02,  1.4345537e-01, -7.4319839e-01,  3.4689307e-01,\n",
            "       -5.0401688e-02, -4.3589631e-01,  1.5958669e+00,  6.5126824e+00,\n",
            "       -7.9941282e+00, -4.8455868e+00], dtype=float32), 'agent_2': Array([ 6.2058318e-01,  3.8174799e-01,  7.4301066e-04,  8.5647327e-05,\n",
            "        9.2426616e-01,  8.6026713e-02,  2.3598719e-01,  9.1889940e-02,\n",
            "       -1.0867527e+00,  1.4345537e-01, -7.4319839e-01,  3.4689307e-01,\n",
            "       -5.0401688e-02, -4.3589631e-01,  1.5958669e+00,  6.5126824e+00,\n",
            "       -8.0964231e+00, -5.4997821e+00], dtype=float32), 'agent_3': Array([ 6.2058318e-01,  3.8174799e-01,  7.4301066e-04,  8.5647327e-05,\n",
            "        9.2426616e-01,  8.6026713e-02,  2.3598719e-01,  9.1889940e-02,\n",
            "        1.4345537e-01,  9.3505335e-01, -7.4319839e-01,  3.4689307e-01,\n",
            "       -5.0401688e-02, -4.3589631e-01,  1.5958669e+00,  6.5126824e+00,\n",
            "       -7.7589965e+00, -3.7406394e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.12906791  0.88184947 -0.12871751  0.88395625 -0.12904488  0.87979513\n",
            " -0.1303014   0.88751215]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5380082, dtype=float32), 'agent_0': Array(-1.5380082, dtype=float32), 'agent_1': Array(-1.5380082, dtype=float32), 'agent_2': Array(-1.5380082, dtype=float32), 'agent_3': Array(-1.5380082, dtype=float32)}\n",
            "step: 282\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0185391e-01,  2.8863165e-01,  2.1846151e-02, -9.6318424e-03,\n",
            "        9.5714253e-01, -1.7577760e-01,  1.0444254e+00, -5.3445543e-03,\n",
            "       -1.5913461e-01, -9.7072527e-02, -1.1373997e+00,  6.2937140e-01,\n",
            "       -5.9530735e-01, -1.5863027e-01, -1.6238989e+00,  3.2072322e+00,\n",
            "       -4.2619615e+00,  5.5828786e+00], dtype=float32), 'agent_1': Array([ 0.6018539 ,  0.28863165,  0.02184615, -0.00963184,  0.95714253,\n",
            "       -0.1757776 , -0.00534455, -0.90257615, -0.15913461, -0.09707253,\n",
            "       -1.1373997 ,  0.6293714 , -0.59530735, -0.15863027, -1.6238989 ,\n",
            "        3.2072322 , -3.4847896 ,  4.818737  ], dtype=float32), 'agent_2': Array([ 0.6018539 ,  0.28863165,  0.02184615, -0.00963184,  0.95714253,\n",
            "       -0.1757776 , -0.00534455, -0.15913461, -0.9705536 , -0.09707253,\n",
            "       -1.1373997 ,  0.6293714 , -0.59530735, -0.15863027, -1.6238989 ,\n",
            "        3.2072322 , -4.347183  ,  5.0506945 ], dtype=float32), 'agent_3': Array([ 0.6018539 ,  0.28863165,  0.02184615, -0.00963184,  0.95714253,\n",
            "       -0.1757776 , -0.00534455, -0.15913461, -0.09707253,  1.102434  ,\n",
            "       -1.1373997 ,  0.6293714 , -0.59530735, -0.15863027, -1.6238989 ,\n",
            "        3.2072322 , -3.7225907 ,  5.15527   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.44714975  0.7027596  -0.44486818  0.70735997 -0.44600305  0.7066911\n",
            " -0.44629613  0.70689416]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6307362, dtype=float32), 'agent_0': Array(-1.6307362, dtype=float32), 'agent_1': Array(-1.6307362, dtype=float32), 'agent_2': Array(-1.6307362, dtype=float32), 'agent_3': Array(-1.6307362, dtype=float32)}\n",
            "step: 283\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56127924,  0.15783635,  0.05027055, -0.02805148,  0.9857858 ,\n",
            "       -0.50617707,  1.2825825 , -0.31236595, -0.5112151 , -0.43323392,\n",
            "       -1.0141373 ,  0.5005002 , -1.0539651 , -0.2851683 , -1.0692296 ,\n",
            "        6.0428987 , -7.155063  ,  0.55723965], dtype=float32), 'agent_1': Array([ 0.56127924,  0.15783635,  0.05027055, -0.02805148,  0.9857858 ,\n",
            "       -0.50617707, -0.31236595, -0.6096047 , -0.5112151 , -0.43323392,\n",
            "       -1.0141373 ,  0.5005002 , -1.0539651 , -0.2851683 , -1.0692296 ,\n",
            "        6.0428987 , -7.3187337 ,  7.597385  ], dtype=float32), 'agent_2': Array([ 0.56127924,  0.15783635,  0.05027055, -0.02805148,  0.9857858 ,\n",
            "       -0.50617707, -0.31236595, -0.5112151 , -0.658118  , -0.43323392,\n",
            "       -1.0141373 ,  0.5005002 , -1.0539651 , -0.2851683 , -1.0692296 ,\n",
            "        6.0428987 , -7.6392646 ,  8.017036  ], dtype=float32), 'agent_3': Array([ 0.56127924,  0.15783635,  0.05027055, -0.02805148,  0.9857858 ,\n",
            "       -0.50617707, -0.31236595, -0.5112151 , -0.43323392,  1.2781504 ,\n",
            "       -1.0141373 ,  0.5005002 , -1.0539651 , -0.2851683 , -1.0692296 ,\n",
            "        6.0428987 , -7.917553  , -0.01070786], dtype=float32)}\n",
            "ctrl action chosen: [ 0.59379095 -0.45466578  0.586853   -0.44987753  0.5870416  -0.45082816\n",
            "  0.5983342  -0.4503039 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4845423, dtype=float32), 'agent_0': Array(-1.4845423, dtype=float32), 'agent_1': Array(-1.4845423, dtype=float32), 'agent_2': Array(-1.4845423, dtype=float32), 'agent_3': Array(-1.4845423, dtype=float32)}\n",
            "step: 284\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5417524 ,  0.23032278,  0.06089886, -0.02710284,  0.97082865,\n",
            "       -0.31179383,  1.219325  , -0.1448313 , -0.3156502 , -0.2842842 ,\n",
            "       -0.20365715, -0.13614297, -0.3099203 ,  0.10301563, -0.36631936,\n",
            "       -5.803894  ,  7.3925123 , -1.0741236 ], dtype=float32), 'agent_1': Array([ 0.5417524 ,  0.23032278,  0.06089886, -0.02710284,  0.97082865,\n",
            "       -0.31179383, -0.1448313 , -0.50939137, -0.3156502 , -0.2842842 ,\n",
            "       -0.20365715, -0.13614297, -0.3099203 ,  0.10301563, -0.36631936,\n",
            "       -5.803894  ,  6.9129243 , -0.23288414], dtype=float32), 'agent_2': Array([ 0.5417524 ,  0.23032278,  0.06089886, -0.02710284,  0.97082865,\n",
            "       -0.31179383, -0.1448313 , -0.3156502 , -0.52284193, -0.2842842 ,\n",
            "       -0.20365715, -0.13614297, -0.3099203 ,  0.10301563, -0.36631936,\n",
            "       -5.803894  ,  7.8101664 ,  1.0512115 ], dtype=float32), 'agent_3': Array([ 0.5417524 ,  0.23032278,  0.06089886, -0.02710284,  0.97082865,\n",
            "       -0.31179383, -0.1448313 , -0.3156502 , -0.2842842 ,  1.1984698 ,\n",
            "       -0.20365715, -0.13614297, -0.3099203 ,  0.10301563, -0.36631936,\n",
            "       -5.803894  ,  6.738688  , -2.1176982 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.6512249  -1.0939062  -0.6534998  -1.090552   -0.65151954 -1.0854992\n",
            " -0.6532659  -1.0940549 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.54469454, dtype=float32), 'agent_0': Array(-0.54469454, dtype=float32), 'agent_1': Array(-0.54469454, dtype=float32), 'agent_2': Array(-0.54469454, dtype=float32), 'agent_3': Array(-0.54469454, dtype=float32)}\n",
            "step: 285\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2802956e-01,  1.4660074e-01,  2.2220148e-02, -3.8427911e-03,\n",
            "        9.8893869e-01, -5.0977039e-01,  7.9837620e-01, -3.6234665e-01,\n",
            "       -4.9619263e-01, -4.9938661e-01,  9.5558167e-02, -2.7036667e-01,\n",
            "       -5.2112341e-01,  1.3417892e+00,  2.8584421e+00,  6.1197991e+00,\n",
            "       -7.5048404e+00, -1.2170673e+01], dtype=float32), 'agent_1': Array([ 5.2802956e-01,  1.4660074e-01,  2.2220148e-02, -3.8427911e-03,\n",
            "        9.8893869e-01, -5.0977039e-01, -3.6234665e-01, -7.6545006e-01,\n",
            "       -4.9619263e-01, -4.9938661e-01,  9.5558167e-02, -2.7036667e-01,\n",
            "       -5.2112341e-01,  1.3417892e+00,  2.8584421e+00,  6.1197991e+00,\n",
            "       -8.1485548e+00, -9.1741943e+00], dtype=float32), 'agent_2': Array([ 5.2802956e-01,  1.4660074e-01,  2.2220148e-02, -3.8427911e-03,\n",
            "        9.8893869e-01, -5.0977039e-01, -3.6234665e-01, -4.9619263e-01,\n",
            "       -7.4833220e-01, -4.9938661e-01,  9.5558167e-02, -2.7036667e-01,\n",
            "       -5.2112341e-01,  1.3417892e+00,  2.8584421e+00,  6.1197991e+00,\n",
            "       -7.2071691e+00, -8.4060888e+00], dtype=float32), 'agent_3': Array([ 5.2802956e-01,  1.4660074e-01,  2.2220148e-02, -3.8427911e-03,\n",
            "        9.8893869e-01, -5.0977039e-01, -3.6234665e-01, -4.9619263e-01,\n",
            "       -4.9938661e-01,  7.4732554e-01,  9.5558167e-02, -2.7036667e-01,\n",
            "       -5.2112341e-01,  1.3417892e+00,  2.8584421e+00,  6.1197991e+00,\n",
            "       -8.0151711e+00, -1.2256363e+01], dtype=float32)}\n",
            "ctrl action chosen: [0.5425602  0.18236974 0.54225636 0.18501478 0.54072785 0.18709499\n",
            " 0.544003   0.18744871]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2464714, dtype=float32), 'agent_0': Array(-2.2464714, dtype=float32), 'agent_1': Array(-2.2464714, dtype=float32), 'agent_2': Array(-2.2464714, dtype=float32), 'agent_3': Array(-2.2464714, dtype=float32)}\n",
            "step: 286\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50458664,  0.2023268 , -0.01400198,  0.01882619,  0.979037  ,\n",
            "       -0.34886262,  0.48757017, -0.26822263, -0.3253899 , -0.40291703,\n",
            "        0.01850128, -0.05626678, -0.14754534,  0.04923398,  1.1924685 ,\n",
            "       -4.9480333 ,  7.004595  , -2.3883247 ], dtype=float32), 'agent_1': Array([ 0.50458664,  0.2023268 , -0.01400198,  0.01882619,  0.979037  ,\n",
            "       -0.34886262, -0.26822263, -0.9835381 , -0.3253899 , -0.40291703,\n",
            "        0.01850128, -0.05626678, -0.14754534,  0.04923398,  1.1924685 ,\n",
            "       -4.9480333 ,  5.3177066 , -2.2536018 ], dtype=float32), 'agent_2': Array([ 0.50458664,  0.2023268 , -0.01400198,  0.01882619,  0.979037  ,\n",
            "       -0.34886262, -0.26822263, -0.3253899 , -0.91950417, -0.40291703,\n",
            "        0.01850128, -0.05626678, -0.14754534,  0.04923398,  1.1924685 ,\n",
            "       -4.9480333 ,  7.1296234 , -1.4040039 ], dtype=float32), 'agent_3': Array([ 0.50458664,  0.2023268 , -0.01400198,  0.01882619,  0.979037  ,\n",
            "       -0.34886262, -0.26822263, -0.3253899 , -0.40291703,  0.47747967,\n",
            "        0.01850128, -0.05626678, -0.14754534,  0.04923398,  1.1924685 ,\n",
            "       -4.9480333 ,  5.3941307 ,  0.0787081 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.3280883 -1.1851362 -2.3311212 -1.1841964 -2.3285546 -1.1805885\n",
            " -2.3299668 -1.1747121]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.320208, dtype=float32), 'agent_0': Array(0.320208, dtype=float32), 'agent_1': Array(0.320208, dtype=float32), 'agent_2': Array(0.320208, dtype=float32), 'agent_3': Array(0.320208, dtype=float32)}\n",
            "step: 287\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5236231 ,  0.10826177, -0.05569769,  0.04000454,  0.99175435,\n",
            "       -0.5486632 ,  0.4560547 , -0.5385004 , -0.5290154 , -0.59024763,\n",
            "        0.4621029 , -0.09043217,  0.67527294,  0.5042799 ,  1.6171688 ,\n",
            "        0.37814626, -0.6482793 ,  0.8801763 ], dtype=float32), 'agent_1': Array([ 0.5236231 ,  0.10826177, -0.05569769,  0.04000454,  0.99175435,\n",
            "       -0.5486632 , -0.5385004 , -1.2581697 , -0.5290154 , -0.59024763,\n",
            "        0.4621029 , -0.09043217,  0.67527294,  0.5042799 ,  1.6171688 ,\n",
            "        0.37814626, -2.1109788 , -3.422169  ], dtype=float32), 'agent_2': Array([ 0.5236231 ,  0.10826177, -0.05569769,  0.04000454,  0.99175435,\n",
            "       -0.5486632 , -0.5385004 , -0.5290154 , -1.2042825 , -0.59024763,\n",
            "        0.4621029 , -0.09043217,  0.67527294,  0.5042799 ,  1.6171688 ,\n",
            "        0.37814626, -1.3883156 , -6.3777137 ], dtype=float32), 'agent_3': Array([ 0.5236231 ,  0.10826177, -0.05569769,  0.04000454,  0.99175435,\n",
            "       -0.5486632 , -0.5385004 , -0.5290154 , -0.59024763,  0.47155175,\n",
            "        0.4621029 , -0.09043217,  0.67527294,  0.5042799 ,  1.6171688 ,\n",
            "        0.37814626,  1.2525147 ,  1.0663717 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.93573123 -0.2658615   0.9362102  -0.27089643  0.9395244  -0.2743601\n",
            "  0.9372004  -0.26061457]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.42274, dtype=float32), 'agent_0': Array(-12.42274, dtype=float32), 'agent_1': Array(-12.42274, dtype=float32), 'agent_2': Array(-12.42274, dtype=float32), 'agent_3': Array(-12.42274, dtype=float32)}\n",
            "step: 288\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.55290467,   0.28292656,  -0.07947128,   0.02401709,\n",
            "         0.95554185,  -0.10824738,   0.56853825,  -0.1690788 ,\n",
            "        -0.11041892,  -0.06017817,   0.35014153,   0.22025704,\n",
            "         0.01385212,  -0.2424448 ,   0.76406413, -10.855797  ,\n",
            "        13.812699  ,   2.4347892 ], dtype=float32), 'agent_1': Array([  0.55290467,   0.28292656,  -0.07947128,   0.02401709,\n",
            "         0.95554185,  -0.10824738,  -0.1690788 ,  -1.2628146 ,\n",
            "        -0.11041892,  -0.06017817,   0.35014153,   0.22025704,\n",
            "         0.01385212,  -0.2424448 ,   0.76406413, -10.855797  ,\n",
            "        12.197148  ,  -0.3989061 ], dtype=float32), 'agent_2': Array([  0.55290467,   0.28292656,  -0.07947128,   0.02401709,\n",
            "         0.95554185,  -0.10824738,  -0.1690788 ,  -0.11041892,\n",
            "        -1.2666376 ,  -0.06017817,   0.35014153,   0.22025704,\n",
            "         0.01385212,  -0.2424448 ,   0.76406413, -10.855797  ,\n",
            "        12.8715725 ,  -0.63380325], dtype=float32), 'agent_3': Array([ 5.52904665e-01,  2.82926559e-01, -7.94712752e-02,  2.40170863e-02,\n",
            "        9.55541849e-01, -1.08247384e-01, -1.69078797e-01, -1.10418916e-01,\n",
            "       -6.01781718e-02,  5.86691618e-01,  3.50141525e-01,  2.20257044e-01,\n",
            "        1.38521194e-02, -2.42444798e-01,  7.64064133e-01, -1.08557968e+01,\n",
            "        1.63628216e+01,  2.40015459e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.7351724  -0.67037433 -0.7406927  -0.6807132  -0.7389494  -0.6782271\n",
            " -0.7322008  -0.6689464 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.558071, dtype=float32), 'agent_0': Array(-0.558071, dtype=float32), 'agent_1': Array(-0.558071, dtype=float32), 'agent_2': Array(-0.558071, dtype=float32), 'agent_3': Array(-0.558071, dtype=float32)}\n",
            "step: 289\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53140557,  0.22730896, -0.10432237,  0.0384757 ,  0.9674539 ,\n",
            "       -0.20808992,  0.50912565, -0.34457755, -0.25966847, -0.09001008,\n",
            "        0.37469864, -0.13415813, -0.8498788 ,  0.31533477,  1.4333458 ,\n",
            "        6.818935  , -7.794602  , -3.2774065 ], dtype=float32), 'agent_1': Array([ 0.53140557,  0.22730896, -0.10432237,  0.0384757 ,  0.9674539 ,\n",
            "       -0.20808992, -0.34457755, -1.2451243 , -0.25966847, -0.09001008,\n",
            "        0.37469864, -0.13415813, -0.8498788 ,  0.31533477,  1.4333458 ,\n",
            "        6.818935  , -9.063196  ,  0.6809928 ], dtype=float32), 'agent_2': Array([ 0.53140557,  0.22730896, -0.10432237,  0.0384757 ,  0.9674539 ,\n",
            "       -0.20808992, -0.34457755, -0.25966847, -1.2488366 , -0.09001008,\n",
            "        0.37469864, -0.13415813, -0.8498788 ,  0.31533477,  1.4333458 ,\n",
            "        6.818935  , -8.64942   ,  1.0021397 ], dtype=float32), 'agent_3': Array([ 0.53140557,  0.22730896, -0.10432237,  0.0384757 ,  0.9674539 ,\n",
            "       -0.20808992, -0.34457755, -0.25966847, -0.09001008,  0.5076132 ,\n",
            "        0.37469864, -0.13415813, -0.8498788 ,  0.31533477,  1.4333458 ,\n",
            "        6.818935  , -6.8000507 , -3.8035011 ], dtype=float32)}\n",
            "ctrl action chosen: [0.46489948 0.3824009  0.4630318  0.3851579  0.46109223 0.38469985\n",
            " 0.46494102 0.38707575]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6150112, dtype=float32), 'agent_0': Array(-0.6150112, dtype=float32), 'agent_1': Array(-0.6150112, dtype=float32), 'agent_2': Array(-0.6150112, dtype=float32), 'agent_3': Array(-0.6150112, dtype=float32)}\n",
            "step: 290\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49866137,  0.24864121, -0.10454792,  0.03155839,  0.96241957,\n",
            "       -0.13397476,  0.5278033 , -0.32370007, -0.2232675 ,  0.02546901,\n",
            "        0.29349327,  0.11162162, -0.28491616, -0.3734493 , -0.46734768,\n",
            "       -3.433975  ,  4.904048  ,  0.21986869], dtype=float32), 'agent_1': Array([ 0.49866137,  0.24864121, -0.10454792,  0.03155839,  0.96241957,\n",
            "       -0.13397476, -0.32370007, -1.037513  , -0.2232675 ,  0.02546901,\n",
            "        0.29349327,  0.11162162, -0.28491616, -0.3734493 , -0.46734768,\n",
            "       -3.433975  ,  3.8672252 ,  5.673241  ], dtype=float32), 'agent_2': Array([ 0.49866137,  0.24864121, -0.10454792,  0.03155839,  0.96241957,\n",
            "       -0.13397476, -0.32370007, -0.2232675 , -1.0178661 ,  0.02546901,\n",
            "        0.29349327,  0.11162162, -0.28491616, -0.3734493 , -0.46734768,\n",
            "       -3.433975  ,  4.075796  ,  6.3902764 ], dtype=float32), 'agent_3': Array([ 0.49866137,  0.24864121, -0.10454792,  0.03155839,  0.96241957,\n",
            "       -0.13397476, -0.32370007, -0.2232675 ,  0.02546901,  0.5290476 ,\n",
            "        0.29349327,  0.11162162, -0.28491616, -0.3734493 , -0.46734768,\n",
            "       -3.433975  ,  5.3455167 ,  0.38401115], dtype=float32)}\n",
            "ctrl action chosen: [ 2.564872   -0.32196313  2.5635347  -0.31471947  2.5642974  -0.31305707\n",
            "  2.5647833  -0.32022017]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.6021496, dtype=float32), 'agent_0': Array(0.6021496, dtype=float32), 'agent_1': Array(0.6021496, dtype=float32), 'agent_2': Array(0.6021496, dtype=float32), 'agent_3': Array(0.6021496, dtype=float32)}\n",
            "step: 291\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.91026282e-01,  4.78326827e-01, -1.10150672e-01,  1.58230553e-03,\n",
            "        8.71244967e-01,  5.44185817e-01,  4.93297309e-01,  2.91934580e-01,\n",
            "        4.03550118e-01,  6.46308541e-01, -5.76972961e-03, -2.04610825e-01,\n",
            "       -2.36928463e-02,  1.73251212e-01, -2.91051477e-01, -6.69825315e+00,\n",
            "        1.02823105e+01,  2.61456165e-02], dtype=float32), 'agent_1': Array([ 4.9102628e-01,  4.7832683e-01, -1.1015067e-01,  1.5823055e-03,\n",
            "        8.7124497e-01,  5.4418582e-01,  2.9193458e-01, -9.5821476e-01,\n",
            "        4.0355012e-01,  6.4630854e-01, -5.7697296e-03, -2.0461082e-01,\n",
            "       -2.3692846e-02,  1.7325121e-01, -2.9105148e-01, -6.6982532e+00,\n",
            "        9.7945213e+00,  8.2014412e-02], dtype=float32), 'agent_2': Array([ 4.9102628e-01,  4.7832683e-01, -1.1015067e-01,  1.5823055e-03,\n",
            "        8.7124497e-01,  5.4418582e-01,  2.9193458e-01,  4.0355012e-01,\n",
            "       -9.1535830e-01,  6.4630854e-01, -5.7697296e-03, -2.0461082e-01,\n",
            "       -2.3692846e-02,  1.7325121e-01, -2.9105148e-01, -6.6982532e+00,\n",
            "        1.0065006e+01,  6.6702145e-01], dtype=float32), 'agent_3': Array([ 4.9102628e-01,  4.7832683e-01, -1.1015067e-01,  1.5823055e-03,\n",
            "        8.7124497e-01,  5.4418582e-01,  2.9193458e-01,  4.0355012e-01,\n",
            "        6.4630854e-01,  4.9677995e-01, -5.7697296e-03, -2.0461082e-01,\n",
            "       -2.3692846e-02,  1.7325121e-01, -2.9105148e-01, -6.6982532e+00,\n",
            "        5.0953546e+00,  2.4603985e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.2461295  -0.12026526 -0.24781981 -0.12107491 -0.2458423  -0.11685833\n",
            " -0.2503767  -0.12194929]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.066592, dtype=float32), 'agent_0': Array(-12.066592, dtype=float32), 'agent_1': Array(-12.066592, dtype=float32), 'agent_2': Array(-12.066592, dtype=float32), 'agent_3': Array(-12.066592, dtype=float32)}\n",
            "step: 292\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49092737,  0.4408764 , -0.0959598 ,  0.01062642,  0.89236027,\n",
            "        0.51443624,  0.5197992 ,  0.26796114,  0.38714704,  0.44466764,\n",
            "       -0.2942562 , -0.44517517, -0.01316667,  0.39199   , -0.23781694,\n",
            "        2.6216118 , -2.2974656 ,  0.4198353 ], dtype=float32), 'agent_1': Array([ 0.49092737,  0.4408764 , -0.0959598 ,  0.01062642,  0.89236027,\n",
            "        0.51443624,  0.26796114, -0.9488418 ,  0.38714704,  0.44466764,\n",
            "       -0.2942562 , -0.44517517, -0.01316667,  0.39199   , -0.23781694,\n",
            "        2.6216118 , -1.8737193 , -0.7423975 ], dtype=float32), 'agent_2': Array([ 0.49092737,  0.4408764 , -0.0959598 ,  0.01062642,  0.89236027,\n",
            "        0.51443624,  0.26796114,  0.38714704, -0.85631484,  0.44466764,\n",
            "       -0.2942562 , -0.44517517, -0.01316667,  0.39199   , -0.23781694,\n",
            "        2.6216118 , -1.7608675 ,  0.42387792], dtype=float32), 'agent_3': Array([ 0.49092737,  0.4408764 , -0.0959598 ,  0.01062642,  0.89236027,\n",
            "        0.51443624,  0.26796114,  0.38714704,  0.44466764,  0.52080905,\n",
            "       -0.2942562 , -0.44517517, -0.01316667,  0.39199   , -0.23781694,\n",
            "        2.6216118 , -6.1513147 ,  0.15986708], dtype=float32)}\n",
            "ctrl action chosen: [ 0.18639986 -0.48205274  0.18922637 -0.48083985  0.1850475  -0.48100436\n",
            "  0.19243139 -0.4873859 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5421414, dtype=float32), 'agent_0': Array(0.5421414, dtype=float32), 'agent_1': Array(0.5421414, dtype=float32), 'agent_2': Array(0.5421414, dtype=float32), 'agent_3': Array(0.5421414, dtype=float32)}\n",
            "step: 293\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4753386 ,  0.42862606, -0.09823246,  0.0159671 ,  0.89798397,\n",
            "        0.53050756,  0.50396514,  0.31459767,  0.44249016,  0.30283198,\n",
            "       -0.15535355, -0.4995942 , -0.46855807,  0.02796737,  0.17859411,\n",
            "       -0.7216057 ,  1.7223719 , -0.27962202], dtype=float32), 'agent_1': Array([ 0.4753386 ,  0.42862606, -0.09823246,  0.0159671 ,  0.89798397,\n",
            "        0.53050756,  0.31459767, -1.1251204 ,  0.44249016,  0.30283198,\n",
            "       -0.15535355, -0.4995942 , -0.46855807,  0.02796737,  0.17859411,\n",
            "       -0.7216057 ,  2.3823738 , -4.3626137 ], dtype=float32), 'agent_2': Array([ 0.4753386 ,  0.42862606, -0.09823246,  0.0159671 ,  0.89798397,\n",
            "        0.53050756,  0.31459767,  0.44249016, -1.006418  ,  0.30283198,\n",
            "       -0.15535355, -0.4995942 , -0.46855807,  0.02796737,  0.17859411,\n",
            "       -0.7216057 ,  2.6001935 , -4.3522363 ], dtype=float32), 'agent_3': Array([ 0.4753386 ,  0.42862606, -0.09823246,  0.0159671 ,  0.89798397,\n",
            "        0.53050756,  0.31459767,  0.44249016,  0.30283198,  0.49888068,\n",
            "       -0.15535355, -0.4995942 , -0.46855807,  0.02796737,  0.17859411,\n",
            "       -0.7216057 , -0.34986624, -0.38872102], dtype=float32)}\n",
            "ctrl action chosen: [ 0.33487475 -0.3358786   0.3394795  -0.34192368  0.3384249  -0.3392796\n",
            "  0.33532977 -0.33635893]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.25619507, dtype=float32), 'agent_0': Array(0.25619507, dtype=float32), 'agent_1': Array(0.25619507, dtype=float32), 'agent_2': Array(0.25619507, dtype=float32), 'agent_3': Array(0.25619507, dtype=float32)}\n",
            "step: 294\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.47765407,  0.44382003, -0.10094745,  0.0171783 ,  0.8902463 ,\n",
            "        0.542992  ,  0.50402033,  0.45647675,  0.5569543 ,  0.3266035 ,\n",
            "       -0.06113052, -0.7092118 ,  0.770396  , -0.12003182,  0.36330098,\n",
            "        0.31663975, -1.0510516 ,  0.18419099], dtype=float32), 'agent_1': Array([ 0.47765407,  0.44382003, -0.10094745,  0.0171783 ,  0.8902463 ,\n",
            "        0.542992  ,  0.45647675, -1.2347901 ,  0.5569543 ,  0.3266035 ,\n",
            "       -0.06113052, -0.7092118 ,  0.770396  , -0.12003182,  0.36330098,\n",
            "        0.31663975,  1.973178  , -0.28250375], dtype=float32), 'agent_2': Array([ 0.47765407,  0.44382003, -0.10094745,  0.0171783 ,  0.8902463 ,\n",
            "        0.542992  ,  0.45647675,  0.5569543 , -1.1859745 ,  0.3266035 ,\n",
            "       -0.06113052, -0.7092118 ,  0.770396  , -0.12003182,  0.36330098,\n",
            "        0.31663975,  0.300654  , -2.7572446 ], dtype=float32), 'agent_3': Array([ 0.47765407,  0.44382003, -0.10094745,  0.0171783 ,  0.8902463 ,\n",
            "        0.542992  ,  0.45647675,  0.5569543 ,  0.3266035 ,  0.49726865,\n",
            "       -0.06113052, -0.7092118 ,  0.770396  , -0.12003182,  0.36330098,\n",
            "        0.31663975,  0.08438489,  0.05435526], dtype=float32)}\n",
            "ctrl action chosen: [-0.22973418 -1.6548972  -0.22858338 -1.6524514  -0.2282646  -1.6547277\n",
            " -0.22986542 -1.6522305 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3759933, dtype=float32), 'agent_0': Array(0.3759933, dtype=float32), 'agent_1': Array(0.3759933, dtype=float32), 'agent_2': Array(0.3759933, dtype=float32), 'agent_3': Array(0.3759933, dtype=float32)}\n",
            "step: 295\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50683033,  0.37761632, -0.11066234,  0.02853034,  0.91888297,\n",
            "        0.32080173,  0.48786578,  0.37443045,  0.42286915,  0.17118083,\n",
            "       -0.20031929, -0.5886555 ,  0.3203392 ,  0.40739474,  0.01339111,\n",
            "        3.587954  , -5.3996797 ,  0.49891034], dtype=float32), 'agent_1': Array([ 0.50683033,  0.37761632, -0.11066234,  0.02853034,  0.91888297,\n",
            "        0.32080173,  0.37443045, -1.2685308 ,  0.42286915,  0.17118083,\n",
            "       -0.20031929, -0.5886555 ,  0.3203392 ,  0.40739474,  0.01339111,\n",
            "        3.587954  , -2.4706056 ,  0.05834909], dtype=float32), 'agent_2': Array([ 0.50683033,  0.37761632, -0.11066234,  0.02853034,  0.91888297,\n",
            "        0.32080173,  0.37443045,  0.42286915, -1.2704403 ,  0.17118083,\n",
            "       -0.20031929, -0.5886555 ,  0.3203392 ,  0.40739474,  0.01339111,\n",
            "        3.587954  , -3.894444  ,  0.4559803 ], dtype=float32), 'agent_3': Array([ 0.50683033,  0.37761632, -0.11066234,  0.02853034,  0.91888297,\n",
            "        0.32080173,  0.37443045,  0.42286915,  0.17118083,  0.48856622,\n",
            "       -0.20031929, -0.5886555 ,  0.3203392 ,  0.40739474,  0.01339111,\n",
            "        3.587954  , -3.8117757 ,  0.34234303], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8240152  -1.3349476   0.8237358  -1.3308364   0.8215264  -1.3333124\n",
            "  0.82205474 -1.3319569 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.6650734, dtype=float32), 'agent_0': Array(-4.6650734, dtype=float32), 'agent_1': Array(-4.6650734, dtype=float32), 'agent_2': Array(-4.6650734, dtype=float32), 'agent_3': Array(-4.6650734, dtype=float32)}\n",
            "step: 296\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50896686,  0.4414102 , -0.11883382,  0.02353661,  0.88909036,\n",
            "        0.49933502,  0.47928578,  0.58948684,  0.5786373 ,  0.4066523 ,\n",
            "        0.12197495, -0.16087294, -0.24940968, -0.17350982,  0.26937068,\n",
            "       -1.0929468 ,  3.126853  , -0.2711896 ], dtype=float32), 'agent_1': Array([ 0.50896686,  0.4414102 , -0.11883382,  0.02353661,  0.88909036,\n",
            "        0.49933502,  0.58948684, -1.2631342 ,  0.5786373 ,  0.4066523 ,\n",
            "        0.12197495, -0.16087294, -0.24940968, -0.17350982,  0.26937068,\n",
            "       -1.0929468 ,  0.8361149 ,  0.2138143 ], dtype=float32), 'agent_2': Array([ 0.50896686,  0.4414102 , -0.11883382,  0.02353661,  0.88909036,\n",
            "        0.49933502,  0.58948684,  0.5786373 , -1.2633283 ,  0.4066523 ,\n",
            "        0.12197495, -0.16087294, -0.24940968, -0.17350982,  0.26937068,\n",
            "       -1.0929468 ,  0.21061209,  0.20657898], dtype=float32), 'agent_3': Array([ 0.50896686,  0.4414102 , -0.11883382,  0.02353661,  0.88909036,\n",
            "        0.49933502,  0.58948684,  0.5786373 ,  0.4066523 ,  0.48090157,\n",
            "        0.12197495, -0.16087294, -0.24940968, -0.17350982,  0.26937068,\n",
            "       -1.0929468 ,  4.077905  , -0.20312291], dtype=float32)}\n",
            "ctrl action chosen: [ 0.09835706 -1.4307443   0.09754531 -1.4319322   0.09765267 -1.4302853\n",
            "  0.09880151 -1.4298114 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.930273, dtype=float32), 'agent_0': Array(-3.930273, dtype=float32), 'agent_1': Array(-3.930273, dtype=float32), 'agent_2': Array(-3.930273, dtype=float32), 'agent_3': Array(-3.930273, dtype=float32)}\n",
            "step: 297\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49825877,  0.43220642, -0.12248223,  0.02224883,  0.8931409 ,\n",
            "        0.54256946,  0.48019767,  0.5139783 ,  0.4993653 ,  0.48457876,\n",
            "        0.43439865, -0.09555817, -0.11020899, -0.25997925, -0.06086342,\n",
            "        0.43621722,  0.29927325,  0.11103856], dtype=float32), 'agent_1': Array([ 0.49825877,  0.43220642, -0.12248223,  0.02224883,  0.8931409 ,\n",
            "        0.54256946,  0.5139783 , -1.2545003 ,  0.4993653 ,  0.48457876,\n",
            "        0.43439865, -0.09555817, -0.11020899, -0.25997925, -0.06086342,\n",
            "        0.43621722, -2.0965016 ,  0.04331777], dtype=float32), 'agent_2': Array([ 0.49825877,  0.43220642, -0.12248223,  0.02224883,  0.8931409 ,\n",
            "        0.54256946,  0.5139783 ,  0.4993653 , -1.2590114 ,  0.48457876,\n",
            "        0.43439865, -0.09555817, -0.11020899, -0.25997925, -0.06086342,\n",
            "        0.43621722, -1.9765767 , -0.01135848], dtype=float32), 'agent_3': Array([ 0.49825877,  0.43220642, -0.12248223,  0.02224883,  0.8931409 ,\n",
            "        0.54256946,  0.5139783 ,  0.4993653 ,  0.48457876,  0.4719344 ,\n",
            "        0.43439865, -0.09555817, -0.11020899, -0.25997925, -0.06086342,\n",
            "        0.43621722,  1.0482708 , -0.03264426], dtype=float32)}\n",
            "ctrl action chosen: [0.011933   0.78678125 0.0127186  0.78428316 0.01224188 0.78216803\n",
            " 0.01268193 0.7873384 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8603306, dtype=float32), 'agent_0': Array(-2.8603306, dtype=float32), 'agent_1': Array(-2.8603306, dtype=float32), 'agent_2': Array(-2.8603306, dtype=float32), 'agent_3': Array(-2.8603306, dtype=float32)}\n",
            "step: 298\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50780576,  0.41276512, -0.07349873,  0.01400485,  0.90775925,\n",
            "        0.5307086 ,  0.7270423 ,  0.38862818,  0.38755956,  0.47560316,\n",
            "        0.09007454,  0.2069056 ,  0.33034086,  0.57018644, -2.6148567 ,\n",
            "        0.37337407,  0.09935233,  5.927853  ], dtype=float32), 'agent_1': Array([ 0.50780576,  0.41276512, -0.07349873,  0.01400485,  0.90775925,\n",
            "        0.5307086 ,  0.38862818, -0.9680166 ,  0.38755956,  0.47560316,\n",
            "        0.09007454,  0.2069056 ,  0.33034086,  0.57018644, -2.6148567 ,\n",
            "        0.37337407, -1.4712912 ,  7.6280947 ], dtype=float32), 'agent_2': Array([ 0.50780576,  0.41276512, -0.07349873,  0.01400485,  0.90775925,\n",
            "        0.5307086 ,  0.38862818,  0.38755956, -0.9859858 ,  0.47560316,\n",
            "        0.09007454,  0.2069056 ,  0.33034086,  0.57018644, -2.6148567 ,\n",
            "        0.37337407, -1.4070618 ,  7.385592  ], dtype=float32), 'agent_3': Array([ 0.50780576,  0.41276512, -0.07349873,  0.01400485,  0.90775925,\n",
            "        0.5307086 ,  0.38862818,  0.38755956,  0.47560316,  0.65918446,\n",
            "        0.09007454,  0.2069056 ,  0.33034086,  0.57018644, -2.6148567 ,\n",
            "        0.37337407, -0.03847537,  4.613594  ], dtype=float32)}\n",
            "ctrl action chosen: [0.23848158 1.3916099  0.24018385 1.3859936  0.2377316  1.3873769\n",
            " 0.2397577  1.3938963 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.01048303, dtype=float32), 'agent_0': Array(0.01048303, dtype=float32), 'agent_1': Array(0.01048303, dtype=float32), 'agent_2': Array(0.01048303, dtype=float32), 'agent_3': Array(0.01048303, dtype=float32)}\n",
            "step: 299\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3098506e-01,  4.2419139e-01,  2.1007236e-02, -5.2989414e-04,\n",
            "        9.0532881e-01,  5.5647361e-01,  1.0901424e+00,  3.9344567e-01,\n",
            "        4.0511954e-01,  5.1336855e-01, -1.7876625e-01, -2.1189451e-02,\n",
            "        4.7228336e-01,  1.5207896e+00, -4.3688626e+00, -5.3000357e-02,\n",
            "       -2.9091647e-02,  8.0100775e+00], dtype=float32), 'agent_1': Array([ 5.3098506e-01,  4.2419139e-01,  2.1007236e-02, -5.2989414e-04,\n",
            "        9.0532881e-01,  5.5647361e-01,  3.9344567e-01, -4.5824224e-01,\n",
            "        4.0511954e-01,  5.1336855e-01, -1.7876625e-01, -2.1189451e-02,\n",
            "        4.7228336e-01,  1.5207896e+00, -4.3688626e+00, -5.3000357e-02,\n",
            "       -8.6319432e-02,  8.7944212e+00], dtype=float32), 'agent_2': Array([ 5.3098506e-01,  4.2419139e-01,  2.1007236e-02, -5.2989414e-04,\n",
            "        9.0532881e-01,  5.5647361e-01,  3.9344567e-01,  4.0511954e-01,\n",
            "       -4.6533918e-01,  5.1336855e-01, -1.7876625e-01, -2.1189451e-02,\n",
            "        4.7228336e-01,  1.5207896e+00, -4.3688626e+00, -5.3000357e-02,\n",
            "        8.8385606e-01,  9.8633919e+00], dtype=float32), 'agent_3': Array([ 5.3098506e-01,  4.2419139e-01,  2.1007236e-02, -5.2989414e-04,\n",
            "        9.0532881e-01,  5.5647361e-01,  3.9344567e-01,  4.0511954e-01,\n",
            "        5.1336855e-01,  1.0343478e+00, -1.7876625e-01, -2.1189451e-02,\n",
            "        4.7228336e-01,  1.5207896e+00, -4.3688626e+00, -5.3000357e-02,\n",
            "        1.3559671e-01,  9.4488497e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.65575415 0.66819596 0.6561304  0.6680781  0.65332437 0.6714572\n",
            " 0.654454   0.66801834]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0425003, dtype=float32), 'agent_0': Array(-3.0425003, dtype=float32), 'agent_1': Array(-3.0425003, dtype=float32), 'agent_2': Array(-3.0425003, dtype=float32), 'agent_3': Array(-3.0425003, dtype=float32)}\n",
            "step: 300\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5638354 ,  0.44694915,  0.06800523, -0.00961619,  0.89191884,\n",
            "        0.5533394 ,  1.2700346 ,  0.49677446,  0.5602541 ,  0.5459443 ,\n",
            "        0.08649826, -0.52012205,  1.1412263 ,  0.0289733 , -0.80715305,\n",
            "       -0.44606656, -1.2437842 , -0.39775336], dtype=float32), 'agent_1': Array([ 0.5638354 ,  0.44694915,  0.06800523, -0.00961619,  0.89191884,\n",
            "        0.5533394 ,  0.49677446, -0.46271488,  0.5602541 ,  0.5459443 ,\n",
            "        0.08649826, -0.52012205,  1.1412263 ,  0.0289733 , -0.80715305,\n",
            "       -0.44606656,  2.4281132 , -0.8403457 ], dtype=float32), 'agent_2': Array([ 0.5638354 ,  0.44694915,  0.06800523, -0.00961619,  0.89191884,\n",
            "        0.5533394 ,  0.49677446,  0.5602541 , -0.46142164,  0.5459443 ,\n",
            "        0.08649826, -0.52012205,  1.1412263 ,  0.0289733 , -0.80715305,\n",
            "       -0.44606656,  1.562191  , -1.0481049 ], dtype=float32), 'agent_3': Array([ 0.5638354 ,  0.44694915,  0.06800523, -0.00961619,  0.89191884,\n",
            "        0.5533394 ,  0.49677446,  0.5602541 ,  0.5459443 ,  1.2770238 ,\n",
            "        0.08649826, -0.52012205,  1.1412263 ,  0.0289733 , -0.80715305,\n",
            "       -0.44606656, -0.08872198, -0.6246172 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.54930615  1.6707406  -0.5521343   1.675375   -0.55106306  1.6762863\n",
            " -0.54820704  1.6758733 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.77154446, dtype=float32), 'agent_0': Array(-0.77154446, dtype=float32), 'agent_1': Array(-0.77154446, dtype=float32), 'agent_2': Array(-0.77154446, dtype=float32), 'agent_3': Array(-0.77154446, dtype=float32)}\n",
            "step: 301\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.9294379e-01,  3.3128929e-01,  9.7183906e-02, -2.8690431e-02,\n",
            "        9.3807220e-01,  1.3681385e-01,  1.2872024e+00,  2.5952438e-01,\n",
            "        3.2883957e-01,  2.2088805e-01, -3.4332275e-03, -3.5020113e-01,\n",
            "       -4.6575069e-02, -1.1086029e-01, -1.1685885e+00,  7.0213628e+00,\n",
            "       -1.0970255e+01, -9.0184337e-01], dtype=float32), 'agent_1': Array([ 5.9294379e-01,  3.3128929e-01,  9.7183906e-02, -2.8690431e-02,\n",
            "        9.3807220e-01,  1.3681385e-01,  2.5952438e-01, -5.1004946e-01,\n",
            "        3.2883957e-01,  2.2088805e-01, -3.4332275e-03, -3.5020113e-01,\n",
            "       -4.6575069e-02, -1.1086029e-01, -1.1685885e+00,  7.0213628e+00,\n",
            "       -6.9705071e+00, -5.6346869e-01], dtype=float32), 'agent_2': Array([ 5.9294379e-01,  3.3128929e-01,  9.7183906e-02, -2.8690431e-02,\n",
            "        9.3807220e-01,  1.3681385e-01,  2.5952438e-01,  3.2883957e-01,\n",
            "       -5.1108646e-01,  2.2088805e-01, -3.4332275e-03, -3.5020113e-01,\n",
            "       -4.6575069e-02, -1.1086029e-01, -1.1685885e+00,  7.0213628e+00,\n",
            "       -7.6056190e+00, -6.6615254e-01], dtype=float32), 'agent_3': Array([ 5.9294379e-01,  3.3128929e-01,  9.7183906e-02, -2.8690431e-02,\n",
            "        9.3807220e-01,  1.3681385e-01,  2.5952438e-01,  3.2883957e-01,\n",
            "        2.2088805e-01,  1.2880915e+00, -3.4332275e-03, -3.5020113e-01,\n",
            "       -4.6575069e-02, -1.1086029e-01, -1.1685885e+00,  7.0213628e+00,\n",
            "       -9.0410395e+00, -1.0824995e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1188258  -0.6966507   1.1159396  -0.689825    1.114745   -0.69043416\n",
            "  1.1178794  -0.6899118 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.226384, dtype=float32), 'agent_0': Array(-5.226384, dtype=float32), 'agent_1': Array(-5.226384, dtype=float32), 'agent_2': Array(-5.226384, dtype=float32), 'agent_3': Array(-5.226384, dtype=float32)}\n",
            "step: 302\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5726923 ,   0.4384021 ,   0.07567756,  -0.02184626,\n",
            "         0.89532083,   0.34418023,   0.9481802 ,   0.57634985,\n",
            "         0.6111    ,   0.5021225 ,   0.37879944,  -0.5484164 ,\n",
            "        -0.36935806,  -0.5975121 ,   1.7762172 ,  -2.6756766 ,\n",
            "         4.0490584 , -10.15857   ], dtype=float32), 'agent_1': Array([ 0.5726923 ,  0.4384021 ,  0.07567756, -0.02184626,  0.89532083,\n",
            "        0.34418023,  0.57634985, -0.79474026,  0.6111    ,  0.5021225 ,\n",
            "        0.37879944, -0.5484164 , -0.36935806, -0.5975121 ,  1.7762172 ,\n",
            "       -2.6756766 ,  2.9528117 , -5.994188  ], dtype=float32), 'agent_2': Array([ 0.5726923 ,  0.4384021 ,  0.07567756, -0.02184626,  0.89532083,\n",
            "        0.34418023,  0.57634985,  0.6111    , -0.8489629 ,  0.5021225 ,\n",
            "        0.37879944, -0.5484164 , -0.36935806, -0.5975121 ,  1.7762172 ,\n",
            "       -2.6756766 ,  1.3246411 , -7.619837  ], dtype=float32), 'agent_3': Array([  0.5726923 ,   0.4384021 ,   0.07567756,  -0.02184626,\n",
            "         0.89532083,   0.34418023,   0.57634985,   0.6111    ,\n",
            "         0.5021225 ,   0.93615586,   0.37879944,  -0.5484164 ,\n",
            "        -0.36935806,  -0.5975121 ,   1.7762172 ,  -2.6756766 ,\n",
            "         5.0882673 , -10.826586  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.17569362 -0.23545708  0.1667361  -0.23240803  0.17141475 -0.23145452\n",
            "  0.17687725 -0.23553345]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2403204, dtype=float32), 'agent_0': Array(-2.2403204, dtype=float32), 'agent_1': Array(-2.2403204, dtype=float32), 'agent_2': Array(-2.2403204, dtype=float32), 'agent_3': Array(-2.2403204, dtype=float32)}\n",
            "step: 303\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5785011 ,  0.42856017,  0.03696427, -0.02135641,  0.90250415,\n",
            "        0.36612946,  0.5290808 ,  0.52364737,  0.5183888 ,  0.5416891 ,\n",
            "        0.21591187, -0.01206398,  0.57457685, -0.82520074,  1.2299249 ,\n",
            "        0.4784828 ,  0.52665627, -7.209269  ], dtype=float32), 'agent_1': Array([ 0.5785011 ,  0.42856017,  0.03696427, -0.02135641,  0.90250415,\n",
            "        0.36612946,  0.52364737, -0.919716  ,  0.5183888 ,  0.5416891 ,\n",
            "        0.21591187, -0.01206398,  0.57457685, -0.82520074,  1.2299249 ,\n",
            "        0.4784828 , -1.7927495 , -1.4638966 ], dtype=float32), 'agent_2': Array([ 0.5785011 ,  0.42856017,  0.03696427, -0.02135641,  0.90250415,\n",
            "        0.36612946,  0.52364737,  0.5183888 , -1.1022916 ,  0.5416891 ,\n",
            "        0.21591187, -0.01206398,  0.57457685, -0.82520074,  1.2299249 ,\n",
            "        0.4784828 , -1.6623082 , -4.1602054 ], dtype=float32), 'agent_3': Array([ 0.5785011 ,  0.42856017,  0.03696427, -0.02135641,  0.90250415,\n",
            "        0.36612946,  0.52364737,  0.5183888 ,  0.5416891 ,  0.4873129 ,\n",
            "        0.21591187, -0.01206398,  0.57457685, -0.82520074,  1.2299249 ,\n",
            "        0.4784828 , -0.00647543, -5.4270625 ], dtype=float32)}\n",
            "ctrl action chosen: [1.5298806  0.18948928 1.5238427  0.19628085 1.5252432  0.19254991\n",
            " 1.5275078  0.19180034]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2377275, dtype=float32), 'agent_0': Array(1.2377275, dtype=float32), 'agent_1': Array(1.2377275, dtype=float32), 'agent_2': Array(1.2377275, dtype=float32), 'agent_3': Array(1.2377275, dtype=float32)}\n",
            "step: 304\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6149847 ,  0.4452104 ,  0.0463397 , -0.02870481,  0.8937654 ,\n",
            "        0.5636522 ,  0.51621616,  0.531453  ,  0.5484286 ,  0.5662316 ,\n",
            "       -0.35624504,  0.30745864,  0.893116  ,  0.06711551, -0.5986359 ,\n",
            "        0.13623679,  2.5303679 ,  0.409545  ], dtype=float32), 'agent_1': Array([ 0.6149847 ,  0.4452104 ,  0.0463397 , -0.02870481,  0.8937654 ,\n",
            "        0.5636522 ,  0.531453  , -0.84717166,  0.5484286 ,  0.5662316 ,\n",
            "       -0.35624504,  0.30745864,  0.893116  ,  0.06711551, -0.5986359 ,\n",
            "        0.13623679,  0.18140766,  2.6067984 ], dtype=float32), 'agent_2': Array([ 0.6149847 ,  0.4452104 ,  0.0463397 , -0.02870481,  0.8937654 ,\n",
            "        0.5636522 ,  0.531453  ,  0.5484286 , -1.1101379 ,  0.5662316 ,\n",
            "       -0.35624504,  0.30745864,  0.893116  ,  0.06711551, -0.5986359 ,\n",
            "        0.13623679,  0.08188766,  2.0881953 ], dtype=float32), 'agent_3': Array([ 0.6149847 ,  0.4452104 ,  0.0463397 , -0.02870481,  0.8937654 ,\n",
            "        0.5636522 ,  0.531453  ,  0.5484286 ,  0.5662316 ,  0.52205366,\n",
            "       -0.35624504,  0.30745864,  0.893116  ,  0.06711551, -0.5986359 ,\n",
            "        0.13623679, -0.9280684 ,  0.3692451 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.06309456 -0.83367     0.05959713 -0.839204    0.0571308  -0.8378617\n",
            "  0.06239193 -0.83947456]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.9308467, dtype=float32), 'agent_0': Array(-3.9308467, dtype=float32), 'agent_1': Array(-3.9308467, dtype=float32), 'agent_2': Array(-3.9308467, dtype=float32), 'agent_3': Array(-3.9308467, dtype=float32)}\n",
            "step: 305\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6389882 ,  0.40928084,  0.02592221, -0.03202187,  0.9114778 ,\n",
            "        0.5398503 ,  0.49043167,  0.46473426,  0.471939  ,  0.42433253,\n",
            "       -0.0269413 , -0.10464191,  0.27781725,  0.04866982,  0.7283854 ,\n",
            "        2.1102214 , -1.6563009 ,  0.39455572], dtype=float32), 'agent_1': Array([ 0.6389882 ,  0.40928084,  0.02592221, -0.03202187,  0.9114778 ,\n",
            "        0.5398503 ,  0.46473426, -1.077502  ,  0.471939  ,  0.42433253,\n",
            "       -0.0269413 , -0.10464191,  0.27781725,  0.04866982,  0.7283854 ,\n",
            "        2.1102214 , -1.5913973 , -7.075125  ], dtype=float32), 'agent_2': Array([ 0.6389882 ,  0.40928084,  0.02592221, -0.03202187,  0.9114778 ,\n",
            "        0.5398503 ,  0.46473426,  0.471939  , -1.2709013 ,  0.42433253,\n",
            "       -0.0269413 , -0.10464191,  0.27781725,  0.04866982,  0.7283854 ,\n",
            "        2.1102214 , -1.965482  , -1.3527236 ], dtype=float32), 'agent_3': Array([ 0.6389882 ,  0.40928084,  0.02592221, -0.03202187,  0.9114778 ,\n",
            "        0.5398503 ,  0.46473426,  0.471939  ,  0.42433253,  0.48935074,\n",
            "       -0.0269413 , -0.10464191,  0.27781725,  0.04866982,  0.7283854 ,\n",
            "        2.1102214 , -3.3893123 ,  0.07922599], dtype=float32)}\n",
            "ctrl action chosen: [-0.16681486 -0.37328658 -0.16084364 -0.3785628  -0.16576006 -0.3756406\n",
            " -0.1651738  -0.3757583 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5095167, dtype=float32), 'agent_0': Array(-0.5095167, dtype=float32), 'agent_1': Array(-0.5095167, dtype=float32), 'agent_2': Array(-0.5095167, dtype=float32), 'agent_3': Array(-0.5095167, dtype=float32)}\n",
            "step: 306\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6505412 ,  0.33776474,  0.02346619, -0.0262742 ,  0.94057107,\n",
            "        0.3793286 ,  0.5219134 ,  0.3269082 ,  0.32824448,  0.21641365,\n",
            "       -0.1203537 , -0.19482374,  0.20151138, -0.07512143,  0.14509282,\n",
            "        2.8199835 , -3.2423403 , -0.22255376], dtype=float32), 'agent_1': Array([ 0.6505412 ,  0.33776474,  0.02346619, -0.0262742 ,  0.94057107,\n",
            "        0.3793286 ,  0.3269082 , -1.2599702 ,  0.32824448,  0.21641365,\n",
            "       -0.1203537 , -0.19482374,  0.20151138, -0.07512143,  0.14509282,\n",
            "        2.8199835 , -2.5324423 , -0.01479045], dtype=float32), 'agent_2': Array([ 0.6505412 ,  0.33776474,  0.02346619, -0.0262742 ,  0.94057107,\n",
            "        0.3793286 ,  0.3269082 ,  0.32824448, -1.2484154 ,  0.21641365,\n",
            "       -0.1203537 , -0.19482374,  0.20151138, -0.07512143,  0.14509282,\n",
            "        2.8199835 , -2.5706558 , -0.07967951], dtype=float32), 'agent_3': Array([ 0.6505412 ,  0.33776474,  0.02346619, -0.0262742 ,  0.94057107,\n",
            "        0.3793286 ,  0.3269082 ,  0.32824448,  0.21641365,  0.5141093 ,\n",
            "       -0.1203537 , -0.19482374,  0.20151138, -0.07512143,  0.14509282,\n",
            "        2.8199835 , -3.7658396 ,  0.17476396], dtype=float32)}\n",
            "ctrl action chosen: [ 0.27236915 -1.5172888   0.27368155 -1.5151424   0.27146092 -1.5165689\n",
            "  0.27266562 -1.5167    ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5190854, dtype=float32), 'agent_0': Array(0.5190854, dtype=float32), 'agent_1': Array(0.5190854, dtype=float32), 'agent_2': Array(0.5190854, dtype=float32), 'agent_3': Array(0.5190854, dtype=float32)}\n",
            "step: 307\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.65192026,  0.36956626,  0.01065642, -0.01584573,  0.9290081 ,\n",
            "        0.4766397 ,  0.47843248,  0.4421432 ,  0.44895598,  0.28318784,\n",
            "       -0.22711754, -0.10082722, -0.08378029,  0.33476293,  0.41092935,\n",
            "       -2.6178958 ,  3.682588  , -0.20270188], dtype=float32), 'agent_1': Array([ 0.65192026,  0.36956626,  0.01065642, -0.01584573,  0.9290081 ,\n",
            "        0.4766397 ,  0.4421432 , -1.273657  ,  0.44895598,  0.28318784,\n",
            "       -0.22711754, -0.10082722, -0.08378029,  0.33476293,  0.41092935,\n",
            "       -2.6178958 ,  3.852     ,  0.8256608 ], dtype=float32), 'agent_2': Array([ 0.65192026,  0.36956626,  0.01065642, -0.01584573,  0.9290081 ,\n",
            "        0.4766397 ,  0.4421432 ,  0.44895598, -1.2592223 ,  0.28318784,\n",
            "       -0.22711754, -0.10082722, -0.08378029,  0.33476293,  0.41092935,\n",
            "       -2.6178958 ,  3.9279723 ,  0.34584337], dtype=float32), 'agent_3': Array([ 0.65192026,  0.36956626,  0.01065642, -0.01584573,  0.9290081 ,\n",
            "        0.4766397 ,  0.4421432 ,  0.44895598,  0.28318784,  0.4792567 ,\n",
            "       -0.22711754, -0.10082722, -0.08378029,  0.33476293,  0.41092935,\n",
            "       -2.6178958 ,  3.0816932 , -0.1902952 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.6246063   0.44440523 -0.62369317  0.4458     -0.6242181   0.44776008\n",
            " -0.624602    0.44478545]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.8919249, dtype=float32), 'agent_0': Array(-3.8919249, dtype=float32), 'agent_1': Array(-3.8919249, dtype=float32), 'agent_2': Array(-3.8919249, dtype=float32), 'agent_3': Array(-3.8919249, dtype=float32)}\n",
            "step: 308\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.645498  ,  0.2542723 ,  0.03084543, -0.01009283,  0.96658796,\n",
            "        0.20590708,  0.62184817,  0.18185914,  0.18278816, -0.01915787,\n",
            "       -0.3566742 , -0.12811422, -0.22352934,  0.6110303 , -0.8515981 ,\n",
            "        7.189483  , -8.539605  ,  3.6540911 ], dtype=float32), 'agent_1': Array([ 0.645498  ,  0.2542723 ,  0.03084543, -0.01009283,  0.96658796,\n",
            "        0.20590708,  0.18185914, -1.0471209 ,  0.18278816, -0.01915787,\n",
            "       -0.3566742 , -0.12811422, -0.22352934,  0.6110303 , -0.8515981 ,\n",
            "        7.189483  , -8.242076  ,  5.4374104 ], dtype=float32), 'agent_2': Array([ 0.645498  ,  0.2542723 ,  0.03084543, -0.01009283,  0.96658796,\n",
            "        0.20590708,  0.18185914,  0.18278816, -1.0624992 , -0.01915787,\n",
            "       -0.3566742 , -0.12811422, -0.22352934,  0.6110303 , -0.8515981 ,\n",
            "        7.189483  , -8.468188  ,  4.850969  ], dtype=float32), 'agent_3': Array([ 0.645498  ,  0.2542723 ,  0.03084543, -0.01009283,  0.96658796,\n",
            "        0.20590708,  0.18185914,  0.18278816, -0.01915787,  0.63479125,\n",
            "       -0.3566742 , -0.12811422, -0.22352934,  0.6110303 , -0.8515981 ,\n",
            "        7.189483  , -9.210863  ,  3.7481732 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.56640786 -0.36394694 -0.56774586 -0.36218327 -0.567069   -0.3639192\n",
            " -0.56506544 -0.36349255]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.532779, dtype=float32), 'agent_0': Array(-0.532779, dtype=float32), 'agent_1': Array(-0.532779, dtype=float32), 'agent_2': Array(-0.532779, dtype=float32), 'agent_3': Array(-0.532779, dtype=float32)}\n",
            "step: 309\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1286151e-01,  4.1793894e-02,  2.6158147e-02, -3.7260582e-03,\n",
            "        9.9877679e-01, -3.1191641e-01,  6.3549751e-01, -3.2630736e-01,\n",
            "       -3.2758892e-01, -5.5889809e-01, -1.3661385e-01, -1.6119480e-01,\n",
            "       -9.7317696e-01,  4.9649265e-01,  4.8285913e-01,  8.2370834e+00,\n",
            "       -1.0133490e+01, -1.0501654e+00], dtype=float32), 'agent_1': Array([ 6.1286151e-01,  4.1793894e-02,  2.6158147e-02, -3.7260582e-03,\n",
            "        9.9877679e-01, -3.1191641e-01, -3.2630736e-01, -9.7944796e-01,\n",
            "       -3.2758892e-01, -5.5889809e-01, -1.3661385e-01, -1.6119480e-01,\n",
            "       -9.7317696e-01,  4.9649265e-01,  4.8285913e-01,  8.2370834e+00,\n",
            "       -9.9463854e+00,  1.4731888e-01], dtype=float32), 'agent_2': Array([ 6.1286151e-01,  4.1793894e-02,  2.6158147e-02, -3.7260582e-03,\n",
            "        9.9877679e-01, -3.1191641e-01, -3.2630736e-01, -3.2758892e-01,\n",
            "       -1.0256318e+00, -5.5889809e-01, -1.3661385e-01, -1.6119480e-01,\n",
            "       -9.7317696e-01,  4.9649265e-01,  4.8285913e-01,  8.2370834e+00,\n",
            "       -9.8703518e+00, -7.4332696e-01], dtype=float32), 'agent_3': Array([ 6.1286151e-01,  4.1793894e-02,  2.6158147e-02, -3.7260582e-03,\n",
            "        9.9877679e-01, -3.1191641e-01, -3.2630736e-01, -3.2758892e-01,\n",
            "       -5.5889809e-01,  6.4447469e-01, -1.3661385e-01, -1.6119480e-01,\n",
            "       -9.7317696e-01,  4.9649265e-01,  4.8285913e-01,  8.2370834e+00,\n",
            "       -9.4306040e+00, -7.7854741e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.29384145 -0.60348207  0.29258385 -0.600228    0.29299265 -0.60161066\n",
            "  0.29360613 -0.5982336 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.09987152, dtype=float32), 'agent_0': Array(-0.09987152, dtype=float32), 'agent_1': Array(-0.09987152, dtype=float32), 'agent_2': Array(-0.09987152, dtype=float32), 'agent_3': Array(-0.09987152, dtype=float32)}\n",
            "step: 310\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5805761e-01,  4.9150195e-02, -2.0621675e-03,  1.4765026e-02,\n",
            "        9.9868017e-01, -3.0749351e-01,  4.8402920e-01, -3.1544000e-01,\n",
            "       -3.0175254e-01, -4.7768050e-01,  1.7175674e-01,  2.2268295e-01,\n",
            "       -8.0045462e-01,  6.4442283e-01,  1.7723728e+00, -1.8688537e+00,\n",
            "        2.4726424e+00, -1.8202310e+00], dtype=float32), 'agent_1': Array([ 5.5805761e-01,  4.9150195e-02, -2.0621675e-03,  1.4765026e-02,\n",
            "        9.9868017e-01, -3.0749351e-01, -3.1544000e-01, -1.1063025e+00,\n",
            "       -3.0175254e-01, -4.7768050e-01,  1.7175674e-01,  2.2268295e-01,\n",
            "       -8.0045462e-01,  6.4442283e-01,  1.7723728e+00, -1.8688537e+00,\n",
            "        2.3051965e+00, -3.9665539e+00], dtype=float32), 'agent_2': Array([ 5.5805761e-01,  4.9150195e-02, -2.0621675e-03,  1.4765026e-02,\n",
            "        9.9868017e-01, -3.0749351e-01, -3.1544000e-01, -3.0175254e-01,\n",
            "       -1.1574066e+00, -4.7768050e-01,  1.7175674e-01,  2.2268295e-01,\n",
            "       -8.0045462e-01,  6.4442283e-01,  1.7723728e+00, -1.8688537e+00,\n",
            "        3.2179012e+00, -3.2092237e+00], dtype=float32), 'agent_3': Array([ 5.5805761e-01,  4.9150195e-02, -2.0621675e-03,  1.4765026e-02,\n",
            "        9.9868017e-01, -3.0749351e-01, -3.1544000e-01, -3.0175254e-01,\n",
            "       -4.7768050e-01,  4.9788269e-01,  1.7175674e-01,  2.2268295e-01,\n",
            "       -8.0045462e-01,  6.4442283e-01,  1.7723728e+00, -1.8688537e+00,\n",
            "        3.7975199e+00, -3.1199396e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.1752214   0.00927216 -1.1744865   0.00691374 -1.1745757   0.00889802\n",
            " -1.1743188   0.00998037]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.1801939, dtype=float32), 'agent_0': Array(0.1801939, dtype=float32), 'agent_1': Array(0.1801939, dtype=float32), 'agent_2': Array(0.1801939, dtype=float32), 'agent_3': Array(0.1801939, dtype=float32)}\n",
            "step: 311\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5595671 , -0.05122143, -0.02834483,  0.01755797,  0.99813056,\n",
            "       -0.5578755 ,  0.50384295, -0.5722984 , -0.51737523, -0.5668107 ,\n",
            "        0.06289482,  0.43786764,  0.43479204,  0.27916655,  1.208333  ,\n",
            "        0.7082553 , -1.0628539 ,  0.40791374], dtype=float32), 'agent_1': Array([ 0.5595671 , -0.05122143, -0.02834483,  0.01755797,  0.99813056,\n",
            "       -0.5578755 , -0.5722984 , -1.1495047 , -0.51737523, -0.5668107 ,\n",
            "        0.06289482,  0.43786764,  0.43479204,  0.27916655,  1.208333  ,\n",
            "        0.7082553 , -0.79076076,  0.11228719], dtype=float32), 'agent_2': Array([ 0.5595671 , -0.05122143, -0.02834483,  0.01755797,  0.99813056,\n",
            "       -0.5578755 , -0.5722984 , -0.51737523, -1.1479561 , -0.5668107 ,\n",
            "        0.06289482,  0.43786764,  0.43479204,  0.27916655,  1.208333  ,\n",
            "        0.7082553 , -1.9540415 ,  1.5520194 ], dtype=float32), 'agent_3': Array([ 0.5595671 , -0.05122143, -0.02834483,  0.01755797,  0.99813056,\n",
            "       -0.5578755 , -0.5722984 , -0.51737523, -0.5668107 ,  0.5154607 ,\n",
            "        0.06289482,  0.43786764,  0.43479204,  0.27916655,  1.208333  ,\n",
            "        0.7082553 ,  1.5704063 ,  0.19301683], dtype=float32)}\n",
            "ctrl action chosen: [0.66489667 0.51697385 0.66453296 0.5191373  0.66329634 0.5180168\n",
            " 0.6653573  0.52245665]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7620392, dtype=float32), 'agent_0': Array(-1.7620392, dtype=float32), 'agent_1': Array(-1.7620392, dtype=float32), 'agent_2': Array(-1.7620392, dtype=float32), 'agent_3': Array(-1.7620392, dtype=float32)}\n",
            "step: 312\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6502092e-01,  6.9262549e-02, -3.9660476e-02,  5.7852222e-03,\n",
            "        9.9679297e-01, -2.6760867e-01,  7.1165067e-01, -2.7519068e-01,\n",
            "       -2.5711206e-01, -1.1289127e-01, -2.0427704e-01,  6.4207315e-01,\n",
            "       -2.3210049e-01, -5.6173682e-01, -2.2220391e-01, -7.6897521e+00,\n",
            "        9.7432070e+00,  6.5104156e+00], dtype=float32), 'agent_1': Array([ 5.6502092e-01,  6.9262549e-02, -3.9660476e-02,  5.7852222e-03,\n",
            "        9.9679297e-01, -2.6760867e-01, -2.7519068e-01, -1.0448301e+00,\n",
            "       -2.5711206e-01, -1.1289127e-01, -2.0427704e-01,  6.4207315e-01,\n",
            "       -2.3210049e-01, -5.6173682e-01, -2.2220391e-01, -7.6897521e+00,\n",
            "        1.0123788e+01,  3.2999673e+00], dtype=float32), 'agent_2': Array([ 5.6502092e-01,  6.9262549e-02, -3.9660476e-02,  5.7852222e-03,\n",
            "        9.9679297e-01, -2.6760867e-01, -2.7519068e-01, -2.5711206e-01,\n",
            "       -9.6916705e-01, -1.1289127e-01, -2.0427704e-01,  6.4207315e-01,\n",
            "       -2.3210049e-01, -5.6173682e-01, -2.2220391e-01, -7.6897521e+00,\n",
            "        8.4261856e+00,  4.2093935e+00], dtype=float32), 'agent_3': Array([ 5.6502092e-01,  6.9262549e-02, -3.9660476e-02,  5.7852222e-03,\n",
            "        9.9679297e-01, -2.6760867e-01, -2.7519068e-01, -2.5711206e-01,\n",
            "       -1.1289127e-01,  6.9190615e-01, -2.0427704e-01,  6.4207315e-01,\n",
            "       -2.3210049e-01, -5.6173682e-01, -2.2220391e-01, -7.6897521e+00,\n",
            "        1.3171607e+01,  5.3913341e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.07512887 -0.49833104 -0.07777797 -0.5026795  -0.07903103 -0.49968147\n",
            " -0.07263643 -0.4967536 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5360415, dtype=float32), 'agent_0': Array(-0.5360415, dtype=float32), 'agent_1': Array(-0.5360415, dtype=float32), 'agent_2': Array(-0.5360415, dtype=float32), 'agent_3': Array(-0.5360415, dtype=float32)}\n",
            "step: 313\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54797447,  0.13130099, -0.07275117,  0.00426128,  0.98866034,\n",
            "       -0.09694523,  0.7228603 , -0.09407071, -0.13480175,  0.18975116,\n",
            "       -0.07200241,  0.3625989 , -0.16467571,  0.0650437 ,  1.6971916 ,\n",
            "       -0.25808597,  0.7161019 , -3.0311234 ], dtype=float32), 'agent_1': Array([ 0.54797447,  0.13130099, -0.07275117,  0.00426128,  0.98866034,\n",
            "       -0.09694523, -0.09407071, -1.0866255 , -0.13480175,  0.18975116,\n",
            "       -0.07200241,  0.3625989 , -0.16467571,  0.0650437 ,  1.6971916 ,\n",
            "       -0.25808597,  0.81524944, -2.130631  ], dtype=float32), 'agent_2': Array([ 0.54797447,  0.13130099, -0.07275117,  0.00426128,  0.98866034,\n",
            "       -0.09694523, -0.09407071, -0.13480175, -0.98434657,  0.18975116,\n",
            "       -0.07200241,  0.3625989 , -0.16467571,  0.0650437 ,  1.6971916 ,\n",
            "       -0.25808597, -0.13254109, -1.2880048 ], dtype=float32), 'agent_3': Array([ 0.54797447,  0.13130099, -0.07275117,  0.00426128,  0.98866034,\n",
            "       -0.09694523, -0.09407071, -0.13480175,  0.18975116,  0.6734872 ,\n",
            "       -0.07200241,  0.3625989 , -0.16467571,  0.0650437 ,  1.6971916 ,\n",
            "       -0.25808597,  3.069769  , -3.195462  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0387174  -0.28563115 -1.0395669  -0.284678   -1.0385402  -0.2828872\n",
            " -1.0372423  -0.28588903]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.40452927, dtype=float32), 'agent_0': Array(0.40452927, dtype=float32), 'agent_1': Array(0.40452927, dtype=float32), 'agent_2': Array(0.40452927, dtype=float32), 'agent_3': Array(0.40452927, dtype=float32)}\n",
            "step: 314\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54715425, -0.06452542, -0.1058526 ,  0.02400021,  0.99199575,\n",
            "       -0.5756471 ,  0.51865286, -0.5656381 , -0.6066716 , -0.21952891,\n",
            "        0.17414093,  0.35353303, -0.27085543,  0.42880353,  1.7570163 ,\n",
            "        2.812911  , -3.0606072 , -5.0732994 ], dtype=float32), 'agent_1': Array([ 0.54715425, -0.06452542, -0.1058526 ,  0.02400021,  0.99199575,\n",
            "       -0.5756471 , -0.5656381 , -1.1996039 , -0.6066716 , -0.21952891,\n",
            "        0.17414093,  0.35353303, -0.27085543,  0.42880353,  1.7570163 ,\n",
            "        2.812911  , -3.3578262 , -3.0469844 ], dtype=float32), 'agent_2': Array([ 0.54715425, -0.06452542, -0.1058526 ,  0.02400021,  0.99199575,\n",
            "       -0.5756471 , -0.5656381 , -0.6066716 , -1.0665411 , -0.21952891,\n",
            "        0.17414093,  0.35353303, -0.27085543,  0.42880353,  1.7570163 ,\n",
            "        2.812911  , -1.4341878 , -3.0630846 ], dtype=float32), 'agent_3': Array([ 0.54715425, -0.06452542, -0.1058526 ,  0.02400021,  0.99199575,\n",
            "       -0.5756471 , -0.5656381 , -0.6066716 , -0.21952891,  0.5402211 ,\n",
            "        0.17414093,  0.35353303, -0.27085543,  0.42880353,  1.7570163 ,\n",
            "        2.812911  , -4.5592203 , -3.3048615 ], dtype=float32)}\n",
            "ctrl action chosen: [0.76512426 0.14317279 0.7659385  0.14595413 0.76494616 0.14770944\n",
            " 0.76866174 0.14664282]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1265616, dtype=float32), 'agent_0': Array(-1.1265616, dtype=float32), 'agent_1': Array(-1.1265616, dtype=float32), 'agent_2': Array(-1.1265616, dtype=float32), 'agent_3': Array(-1.1265616, dtype=float32)}\n",
            "step: 315\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2636319e-01,  6.1765697e-02, -1.2795649e-01,  9.8608602e-03,\n",
            "        9.8980546e-01, -2.5026652e-01,  5.1641434e-01, -2.6066959e-01,\n",
            "       -2.4500626e-01,  9.7747721e-02, -4.0578842e-02,  5.1559806e-01,\n",
            "       -1.5555620e-01, -4.3725604e-01,  3.0699122e-01, -8.2016497e+00,\n",
            "        1.1288567e+01, -1.8883781e-01], dtype=float32), 'agent_1': Array([ 5.2636319e-01,  6.1765697e-02, -1.2795649e-01,  9.8608602e-03,\n",
            "        9.8980546e-01, -2.5026652e-01, -2.6066959e-01, -1.2292289e+00,\n",
            "       -2.4500626e-01,  9.7747721e-02, -4.0578842e-02,  5.1559806e-01,\n",
            "       -1.5555620e-01, -4.3725604e-01,  3.0699122e-01, -8.2016497e+00,\n",
            "        1.0451717e+01,  5.7962120e-01], dtype=float32), 'agent_2': Array([ 5.2636319e-01,  6.1765697e-02, -1.2795649e-01,  9.8608602e-03,\n",
            "        9.8980546e-01, -2.5026652e-01, -2.6066959e-01, -2.4500626e-01,\n",
            "       -1.1469676e+00,  9.7747721e-02, -4.0578842e-02,  5.1559806e-01,\n",
            "       -1.5555620e-01, -4.3725604e-01,  3.0699122e-01, -8.2016497e+00,\n",
            "        1.1878937e+01, -4.4175601e-01], dtype=float32), 'agent_3': Array([ 5.2636319e-01,  6.1765697e-02, -1.2795649e-01,  9.8608602e-03,\n",
            "        9.8980546e-01, -2.5026652e-01, -2.6066959e-01, -2.4500626e-01,\n",
            "        9.7747721e-02,  5.1120347e-01, -4.0578842e-02,  5.1559806e-01,\n",
            "       -1.5555620e-01, -4.3725604e-01,  3.0699122e-01, -8.2016497e+00,\n",
            "        1.0475541e+01,  1.5298952e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.21058244  0.14096263 -0.21294306  0.14337052 -0.21054783  0.14157373\n",
            " -0.21188493  0.14299072]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.1996069, dtype=float32), 'agent_0': Array(-0.1996069, dtype=float32), 'agent_1': Array(-0.1996069, dtype=float32), 'agent_2': Array(-0.1996069, dtype=float32), 'agent_3': Array(-0.1996069, dtype=float32)}\n",
            "step: 316\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5405016 ,  0.09387919, -0.11850043,  0.0045448 ,  0.98849565,\n",
            "       -0.0775592 ,  0.5229772 , -0.15672937, -0.08610906,  0.21255757,\n",
            "       -0.01006126,  0.38235784,  0.3946662 ,  0.17743883, -0.9140458 ,\n",
            "        1.1671447 ,  0.02426612,  0.3551276 ], dtype=float32), 'agent_1': Array([ 0.5405016 ,  0.09387919, -0.11850043,  0.0045448 ,  0.98849565,\n",
            "       -0.0775592 , -0.15672937, -1.1782585 , -0.08610906,  0.21255757,\n",
            "       -0.01006126,  0.38235784,  0.3946662 ,  0.17743883, -0.9140458 ,\n",
            "        1.1671447 , -1.064164  ,  1.8029393 ], dtype=float32), 'agent_2': Array([ 0.5405016 ,  0.09387919, -0.11850043,  0.0045448 ,  0.98849565,\n",
            "       -0.0775592 , -0.15672937, -0.08610906, -1.1157372 ,  0.21255757,\n",
            "       -0.01006126,  0.38235784,  0.3946662 ,  0.17743883, -0.9140458 ,\n",
            "        1.1671447 , -0.13407885,  1.596192  ], dtype=float32), 'agent_3': Array([ 0.5405016 ,  0.09387919, -0.11850043,  0.0045448 ,  0.98849565,\n",
            "       -0.0775592 , -0.15672937, -0.08610906,  0.21255757,  0.5260214 ,\n",
            "       -0.01006126,  0.38235784,  0.3946662 ,  0.17743883, -0.9140458 ,\n",
            "        1.1671447 , -1.0131807 ,  0.46936607], dtype=float32)}\n",
            "ctrl action chosen: [-1.1085181   0.41803452 -1.1087309   0.41741878 -1.110439    0.41838017\n",
            " -1.1088581   0.41732895]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9015227, dtype=float32), 'agent_0': Array(0.9015227, dtype=float32), 'agent_1': Array(0.9015227, dtype=float32), 'agent_2': Array(0.9015227, dtype=float32), 'agent_3': Array(0.9015227, dtype=float32)}\n",
            "step: 317\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5496782 , -0.12084261, -0.07356123,  0.01527756,  0.9898245 ,\n",
            "       -0.5548347 ,  0.6585478 , -0.62735146, -0.5598835 , -0.33698884,\n",
            "       -0.3402233 ,  0.30010343, -0.0767231 , -0.94768924, -1.9620451 ,\n",
            "        3.650143  , -3.744819  ,  4.219305  ], dtype=float32), 'agent_1': Array([ 0.5496782 , -0.12084261, -0.07356123,  0.01527756,  0.9898245 ,\n",
            "       -0.5548347 , -0.62735146, -0.96334857, -0.5598835 , -0.33698884,\n",
            "       -0.3402233 ,  0.30010343, -0.0767231 , -0.94768924, -1.9620451 ,\n",
            "        3.650143  , -0.9248784 ,  5.480229  ], dtype=float32), 'agent_2': Array([ 0.5496782 , -0.12084261, -0.07356123,  0.01527756,  0.9898245 ,\n",
            "       -0.5548347 , -0.62735146, -0.5598835 , -0.91510195, -0.33698884,\n",
            "       -0.3402233 ,  0.30010343, -0.0767231 , -0.94768924, -1.9620451 ,\n",
            "        3.650143  , -3.6463463 ,  5.2900395 ], dtype=float32), 'agent_3': Array([ 0.5496782 , -0.12084261, -0.07356123,  0.01527756,  0.9898245 ,\n",
            "       -0.5548347 , -0.62735146, -0.5598835 , -0.33698884,  0.6830427 ,\n",
            "       -0.3402233 ,  0.30010343, -0.0767231 , -0.94768924, -1.9620451 ,\n",
            "        3.650143  , -7.1153994 ,  4.4598103 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.30807152 -1.8030859   0.3095456  -1.7994851   0.3082227  -1.8022892\n",
            "  0.30751076 -1.8072432 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9226973, dtype=float32), 'agent_0': Array(-1.9226973, dtype=float32), 'agent_1': Array(-1.9226973, dtype=float32), 'agent_2': Array(-1.9226973, dtype=float32), 'agent_3': Array(-1.9226973, dtype=float32)}\n",
            "step: 318\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5327812 , -0.08853108, -0.08475494,  0.02138366,  0.9922306 ,\n",
            "       -0.45066223,  0.4962432 , -0.42222056, -0.4504017 , -0.33915308,\n",
            "        0.10609627,  0.21973848, -0.5500674 ,  0.76738244,  1.5187137 ,\n",
            "       -2.7678318 ,  4.1180506 , -5.2256093 ], dtype=float32), 'agent_1': Array([ 0.5327812 , -0.08853108, -0.08475494,  0.02138366,  0.9922306 ,\n",
            "       -0.45066223, -0.42222056, -1.1150876 , -0.4504017 , -0.33915308,\n",
            "        0.10609627,  0.21973848, -0.5500674 ,  0.76738244,  1.5187137 ,\n",
            "       -2.7678318 ,  6.926966  , -6.618843  ], dtype=float32), 'agent_2': Array([ 0.5327812 , -0.08853108, -0.08475494,  0.02138366,  0.9922306 ,\n",
            "       -0.45066223, -0.42222056, -0.4504017 , -1.0709708 , -0.33915308,\n",
            "        0.10609627,  0.21973848, -0.5500674 ,  0.76738244,  1.5187137 ,\n",
            "       -2.7678318 ,  4.3029075 , -6.756226  ], dtype=float32), 'agent_3': Array([ 0.5327812 , -0.08853108, -0.08475494,  0.02138366,  0.9922306 ,\n",
            "       -0.45066223, -0.42222056, -0.4504017 , -0.33915308,  0.497545  ,\n",
            "        0.10609627,  0.21973848, -0.5500674 ,  0.76738244,  1.5187137 ,\n",
            "       -2.7678318 ,  2.3902483 , -6.03977   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.44033888  1.9950157  -0.43844938  1.9913323  -0.43828598  1.9951149\n",
            " -0.4386146   1.9962372 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.788496, dtype=float32), 'agent_0': Array(-5.788496, dtype=float32), 'agent_1': Array(-5.788496, dtype=float32), 'agent_2': Array(-5.788496, dtype=float32), 'agent_3': Array(-5.788496, dtype=float32)}\n",
            "step: 319\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4968133 , -0.14162017, -0.03432676,  0.00833363,  0.98929065,\n",
            "       -0.55505717,  0.71872616, -0.41474333, -0.5416363 , -0.53233796,\n",
            "       -0.5409241 ,  0.37503242, -0.8022666 , -1.1045476 , -2.7859557 ,\n",
            "        2.3279    , -1.777362  ,  6.929854  ], dtype=float32), 'agent_1': Array([ 0.4968133 , -0.14162017, -0.03432676,  0.00833363,  0.98929065,\n",
            "       -0.55505717, -0.41474333, -0.9433502 , -0.5416363 , -0.53233796,\n",
            "       -0.5409241 ,  0.37503242, -0.8022666 , -1.1045476 , -2.7859557 ,\n",
            "        2.3279    , -0.7544031 ,  7.398473  ], dtype=float32), 'agent_2': Array([ 0.4968133 , -0.14162017, -0.03432676,  0.00833363,  0.98929065,\n",
            "       -0.55505717, -0.41474333, -0.5416363 , -0.905032  , -0.53233796,\n",
            "       -0.5409241 ,  0.37503242, -0.8022666 , -1.1045476 , -2.7859557 ,\n",
            "        2.3279    , -2.3239057 ,  7.1026635 ], dtype=float32), 'agent_3': Array([ 0.4968133 , -0.14162017, -0.03432676,  0.00833363,  0.98929065,\n",
            "       -0.55505717, -0.41474333, -0.5416363 , -0.53233796,  0.71405387,\n",
            "       -0.5409241 ,  0.37503242, -0.8022666 , -1.1045476 , -2.7859557 ,\n",
            "        2.3279    , -3.9459994 ,  6.7390785 ], dtype=float32)}\n",
            "ctrl action chosen: [0.19319156 0.93992823 0.19492431 0.9446852  0.19455303 0.94157875\n",
            " 0.19652548 0.94108325]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.6988993, dtype=float32), 'agent_0': Array(-7.6988993, dtype=float32), 'agent_1': Array(-7.6988993, dtype=float32), 'agent_2': Array(-7.6988993, dtype=float32), 'agent_3': Array(-7.6988993, dtype=float32)}\n",
            "step: 320\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.9665877e-01, -1.1667336e-01,  4.1994795e-02, -7.4635986e-03,\n",
            "        9.9225408e-01, -4.3764213e-01,  1.1060927e+00, -2.5329065e-01,\n",
            "       -4.9801740e-01, -5.2087343e-01, -9.0270042e-01,  2.1024346e-01,\n",
            "        5.5689216e-01, -1.3170977e+00, -4.0958180e+00, -2.1162453e+00,\n",
            "        4.7329578e+00,  7.9849377e+00], dtype=float32), 'agent_1': Array([ 4.9665877e-01, -1.1667336e-01,  4.1994795e-02, -7.4635986e-03,\n",
            "        9.9225408e-01, -4.3764213e-01, -2.5329065e-01, -5.0049925e-01,\n",
            "       -4.9801740e-01, -5.2087343e-01, -9.0270042e-01,  2.1024346e-01,\n",
            "        5.5689216e-01, -1.3170977e+00, -4.0958180e+00, -2.1162453e+00,\n",
            "        3.9639452e+00,  9.8735332e+00], dtype=float32), 'agent_2': Array([ 4.9665877e-01, -1.1667336e-01,  4.1994795e-02, -7.4635986e-03,\n",
            "        9.9225408e-01, -4.3764213e-01, -2.5329065e-01, -4.9801740e-01,\n",
            "       -4.8706126e-01, -5.2087343e-01, -9.0270042e-01,  2.1024346e-01,\n",
            "        5.5689216e-01, -1.3170977e+00, -4.0958180e+00, -2.1162453e+00,\n",
            "        2.6288676e+00,  9.0236120e+00], dtype=float32), 'agent_3': Array([ 4.9665877e-01, -1.1667336e-01,  4.1994795e-02, -7.4635986e-03,\n",
            "        9.9225408e-01, -4.3764213e-01, -2.5329065e-01, -4.9801740e-01,\n",
            "       -5.2087343e-01,  1.0941677e+00, -9.0270042e-01,  2.1024346e-01,\n",
            "        5.5689216e-01, -1.3170977e+00, -4.0958180e+00, -2.1162453e+00,\n",
            "        1.1052207e+00,  7.6636810e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.764596   -0.7322247   0.76226336 -0.73260564  0.7613877  -0.7367204\n",
            "  0.76222783 -0.740038  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6013477, dtype=float32), 'agent_0': Array(-1.6013477, dtype=float32), 'agent_1': Array(-1.6013477, dtype=float32), 'agent_2': Array(-1.6013477, dtype=float32), 'agent_3': Array(-1.6013477, dtype=float32)}\n",
            "step: 321\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3755301e-01,  9.3077727e-02,  6.2994294e-02,  1.0456733e-02,\n",
            "        9.9360901e-01,  1.9380797e-01,  1.0608910e+00,  2.9892966e-01,\n",
            "        4.3958038e-02, -1.0053584e-01, -1.2516975e-01,  1.3887882e-03,\n",
            "        1.0116935e+00,  5.0765181e-01, -2.7467331e-01, -9.9033632e+00,\n",
            "        1.4166654e+01, -3.9413068e+00], dtype=float32), 'agent_1': Array([ 5.3755301e-01,  9.3077727e-02,  6.2994294e-02,  1.0456733e-02,\n",
            "        9.9360901e-01,  1.9380797e-01,  2.9892966e-01, -5.6251854e-01,\n",
            "        4.3958038e-02, -1.0053584e-01, -1.2516975e-01,  1.3887882e-03,\n",
            "        1.0116935e+00,  5.0765181e-01, -2.7467331e-01, -9.9033632e+00,\n",
            "        1.2951140e+01, -2.8124251e+00], dtype=float32), 'agent_2': Array([ 5.3755301e-01,  9.3077727e-02,  6.2994294e-02,  1.0456733e-02,\n",
            "        9.9360901e-01,  1.9380797e-01,  2.9892966e-01,  4.3958038e-02,\n",
            "       -5.4845953e-01, -1.0053584e-01, -1.2516975e-01,  1.3887882e-03,\n",
            "        1.0116935e+00,  5.0765181e-01, -2.7467331e-01, -9.9033632e+00,\n",
            "        1.2841281e+01, -1.9809132e+00], dtype=float32), 'agent_3': Array([ 5.3755301e-01,  9.3077727e-02,  6.2994294e-02,  1.0456733e-02,\n",
            "        9.9360901e-01,  1.9380797e-01,  2.9892966e-01,  4.3958038e-02,\n",
            "       -1.0053584e-01,  1.0456721e+00, -1.2516975e-01,  1.3887882e-03,\n",
            "        1.0116935e+00,  5.0765181e-01, -2.7467331e-01, -9.9033632e+00,\n",
            "        1.0747958e+01, -4.0824680e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.5341817  1.9413621  0.53184026 1.9438019  0.53253233 1.9476092\n",
            " 0.5305482  1.9435042 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5687218, dtype=float32), 'agent_0': Array(-1.5687218, dtype=float32), 'agent_1': Array(-1.5687218, dtype=float32), 'agent_2': Array(-1.5687218, dtype=float32), 'agent_3': Array(-1.5687218, dtype=float32)}\n",
            "step: 322\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5600987 ,  0.22158656,  0.12207451,  0.03871848,  0.9666944 ,\n",
            "        0.58555305,  1.2784351 ,  0.58936405,  0.45701185,  0.22146799,\n",
            "       -0.05340576,  0.22685528,  0.1711011 ,  0.6535363 , -1.468336  ,\n",
            "       -0.02658037, -0.00575847,  1.3117838 ], dtype=float32), 'agent_1': Array([ 0.5600987 ,  0.22158656,  0.12207451,  0.03871848,  0.9666944 ,\n",
            "        0.58555305,  0.58936405, -0.47689402,  0.45701185,  0.22146799,\n",
            "       -0.05340576,  0.22685528,  0.1711011 ,  0.6535363 , -1.468336  ,\n",
            "       -0.02658037, -1.5655396 , -0.76387465], dtype=float32), 'agent_2': Array([ 0.5600987 ,  0.22158656,  0.12207451,  0.03871848,  0.9666944 ,\n",
            "        0.58555305,  0.58936405,  0.45701185, -0.4802291 ,  0.22146799,\n",
            "       -0.05340576,  0.22685528,  0.1711011 ,  0.6535363 , -1.468336  ,\n",
            "       -0.02658037,  2.78156   ,  0.6391516 ], dtype=float32), 'agent_3': Array([ 0.5600987 ,  0.22158656,  0.12207451,  0.03871848,  0.9666944 ,\n",
            "        0.58555305,  0.58936405,  0.45701185,  0.22146799,  1.269083  ,\n",
            "       -0.05340576,  0.22685528,  0.1711011 ,  0.6535363 , -1.468336  ,\n",
            "       -0.02658037,  1.684938  ,  3.1054294 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.0801679  -0.70505106  1.0832063  -0.7054117   1.0823138  -0.6988694\n",
            "  1.0782448  -0.69999415]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.5111017, dtype=float32), 'agent_0': Array(-7.5111017, dtype=float32), 'agent_1': Array(-7.5111017, dtype=float32), 'agent_2': Array(-7.5111017, dtype=float32), 'agent_3': Array(-7.5111017, dtype=float32)}\n",
            "step: 323\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58427465,  0.24297613,  0.09119602,  0.02896372,  0.96530145,\n",
            "        0.5541426 ,  0.9886071 ,  0.5240948 ,  0.58882856,  0.44037566,\n",
            "        1.017046  ,  0.20797253,  0.06338358, -0.7190334 ,  1.2541124 ,\n",
            "       -0.9318276 , -1.4887837 , -6.771101  ], dtype=float32), 'agent_1': Array([ 0.58427465,  0.24297613,  0.09119602,  0.02896372,  0.96530145,\n",
            "        0.5541426 ,  0.5240948 , -0.8105209 ,  0.58882856,  0.44037566,\n",
            "        1.017046  ,  0.20797253,  0.06338358, -0.7190334 ,  1.2541124 ,\n",
            "       -0.9318276 , -0.94821715, -9.138142  ], dtype=float32), 'agent_2': Array([ 0.58427465,  0.24297613,  0.09119602,  0.02896372,  0.96530145,\n",
            "        0.5541426 ,  0.5240948 ,  0.58882856, -0.74237716,  0.44037566,\n",
            "        1.017046  ,  0.20797253,  0.06338358, -0.7190334 ,  1.2541124 ,\n",
            "       -0.9318276 ,  1.4947233 , -6.848928  ], dtype=float32), 'agent_3': Array([ 0.58427465,  0.24297613,  0.09119602,  0.02896372,  0.96530145,\n",
            "        0.5541426 ,  0.5240948 ,  0.58882856,  0.44037566,  1.0541087 ,\n",
            "        1.017046  ,  0.20797253,  0.06338358, -0.7190334 ,  1.2541124 ,\n",
            "       -0.9318276 ,  6.2032146 , -4.984022  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7768352   0.07410193 -0.7751563   0.07196061 -0.7784262   0.07371008\n",
            " -0.7759078   0.07742053]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3852692, dtype=float32), 'agent_0': Array(-1.3852692, dtype=float32), 'agent_1': Array(-1.3852692, dtype=float32), 'agent_2': Array(-1.3852692, dtype=float32), 'agent_3': Array(-1.3852692, dtype=float32)}\n",
            "step: 324\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.9808731e-01,  5.2896380e-02,  8.9065850e-02,  9.0335235e-03,\n",
            "        9.9457908e-01, -3.7318867e-02,  8.5124302e-01, -7.0119388e-02,\n",
            "        1.7310697e-01,  1.9167601e-01,  4.9304962e-01, -4.0225983e-01,\n",
            "        1.0747910e+00, -8.1436835e-02,  2.0853183e-01,  9.5019875e+00,\n",
            "       -1.4045960e+01, -1.6922464e+00], dtype=float32), 'agent_1': Array([ 5.9808731e-01,  5.2896380e-02,  8.9065850e-02,  9.0335235e-03,\n",
            "        9.9457908e-01, -3.7318867e-02, -7.0119388e-02, -9.8964101e-01,\n",
            "        1.7310697e-01,  1.9167601e-01,  4.9304962e-01, -4.0225983e-01,\n",
            "        1.0747910e+00, -8.1436835e-02,  2.0853183e-01,  9.5019875e+00,\n",
            "       -1.4675596e+01, -3.9044327e-01], dtype=float32), 'agent_2': Array([ 5.9808731e-01,  5.2896380e-02,  8.9065850e-02,  9.0335235e-03,\n",
            "        9.9457908e-01, -3.7318867e-02, -7.0119388e-02,  1.7310697e-01,\n",
            "       -8.5046113e-01,  1.9167601e-01,  4.9304962e-01, -4.0225983e-01,\n",
            "        1.0747910e+00, -8.1436835e-02,  2.0853183e-01,  9.5019875e+00,\n",
            "       -1.1332254e+01, -6.7652392e-01], dtype=float32), 'agent_3': Array([ 5.9808731e-01,  5.2896380e-02,  8.9065850e-02,  9.0335235e-03,\n",
            "        9.9457908e-01, -3.7318867e-02, -7.0119388e-02,  1.7310697e-01,\n",
            "        1.9167601e-01,  9.7000039e-01,  4.9304962e-01, -4.0225983e-01,\n",
            "        1.0747910e+00, -8.1436835e-02,  2.0853183e-01,  9.5019875e+00,\n",
            "       -7.6871009e+00, -1.4813975e+00], dtype=float32)}\n",
            "ctrl action chosen: [2.4057946  0.24672604 2.4044645  0.24840277 2.4001305  0.2538759\n",
            " 2.4005167  0.26083624]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.4934839, dtype=float32), 'agent_0': Array(0.4934839, dtype=float32), 'agent_1': Array(0.4934839, dtype=float32), 'agent_2': Array(0.4934839, dtype=float32), 'agent_3': Array(0.4934839, dtype=float32)}\n",
            "step: 325\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6495487 ,  0.18208365,  0.08715182,  0.02547935,  0.97908175,\n",
            "        0.188982  ,  0.8386551 ,  0.09206263,  0.49757418,  0.62483704,\n",
            "        0.11196136, -0.504905  ,  0.7760167 ,  0.29739714, -0.20681226,\n",
            "       -6.111828  ,  7.2362423 ,  0.8472598 ], dtype=float32), 'agent_1': Array([ 0.6495487 ,  0.18208365,  0.08715182,  0.02547935,  0.97908175,\n",
            "        0.188982  ,  0.09206263, -0.9458359 ,  0.49757418,  0.62483704,\n",
            "        0.11196136, -0.504905  ,  0.7760167 ,  0.29739714, -0.20681226,\n",
            "       -6.111828  ,  6.045611  ,  1.284014  ], dtype=float32), 'agent_2': Array([ 0.6495487 ,  0.18208365,  0.08715182,  0.02547935,  0.97908175,\n",
            "        0.188982  ,  0.09206263,  0.49757418, -0.80099005,  0.62483704,\n",
            "        0.11196136, -0.504905  ,  0.7760167 ,  0.29739714, -0.20681226,\n",
            "       -6.111828  ,  8.818323  ,  2.0514147 ], dtype=float32), 'agent_3': Array([ 0.6495487 ,  0.18208365,  0.08715182,  0.02547935,  0.97908175,\n",
            "        0.188982  ,  0.09206263,  0.49757418,  0.62483704,  0.9392742 ,\n",
            "        0.11196136, -0.504905  ,  0.7760167 ,  0.29739714, -0.20681226,\n",
            "       -6.111828  ,  7.168023  ,  0.17572394], dtype=float32)}\n",
            "ctrl action chosen: [1.2126766  0.13912617 1.2100391  0.13892256 1.2146198  0.14509423\n",
            " 1.2118053  0.13804664]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.439751, dtype=float32), 'agent_0': Array(-10.439751, dtype=float32), 'agent_1': Array(-10.439751, dtype=float32), 'agent_2': Array(-10.439751, dtype=float32), 'agent_3': Array(-10.439751, dtype=float32)}\n",
            "step: 326\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6789139 ,  0.23874258,  0.0934292 ,  0.03849574,  0.9658111 ,\n",
            "        0.4389688 ,  0.89548004,  0.30049303,  0.6020182 ,  0.59631914,\n",
            "       -0.7763386 , -0.81477165,  0.48298836,  0.4643136 , -0.53332186,\n",
            "       -1.877325  ,  5.418631  ,  1.9888914 ], dtype=float32), 'agent_1': Array([ 0.6789139 ,  0.23874258,  0.0934292 ,  0.03849574,  0.9658111 ,\n",
            "        0.4389688 ,  0.30049303, -0.8765008 ,  0.6020182 ,  0.59631914,\n",
            "       -0.7763386 , -0.81477165,  0.48298836,  0.4643136 , -0.53332186,\n",
            "       -1.877325  ,  4.800051  ,  1.9982392 ], dtype=float32), 'agent_2': Array([ 0.6789139 ,  0.23874258,  0.0934292 ,  0.03849574,  0.9658111 ,\n",
            "        0.4389688 ,  0.30049303,  0.6020182 , -0.7091199 ,  0.59631914,\n",
            "       -0.7763386 , -0.81477165,  0.48298836,  0.4643136 , -0.53332186,\n",
            "       -1.877325  , -0.29356313,  2.1282372 ], dtype=float32), 'agent_3': Array([ 0.6789139 ,  0.23874258,  0.0934292 ,  0.03849574,  0.9658111 ,\n",
            "        0.4389688 ,  0.30049303,  0.6020182 ,  0.59631914,  1.0045018 ,\n",
            "       -0.7763386 , -0.81477165,  0.48298836,  0.4643136 , -0.53332186,\n",
            "       -1.877325  , -3.3657007 ,  2.1710517 ], dtype=float32)}\n",
            "ctrl action chosen: [0.40636918 0.49094778 0.40497148 0.48933488 0.40172207 0.48693588\n",
            " 0.4082255  0.47867152]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3427575, dtype=float32), 'agent_0': Array(-2.3427575, dtype=float32), 'agent_1': Array(-2.3427575, dtype=float32), 'agent_2': Array(-2.3427575, dtype=float32), 'agent_3': Array(-2.3427575, dtype=float32)}\n",
            "step: 327\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.69077486,  0.24343842,  0.13039076,  0.05162725,  0.9597243 ,\n",
            "        0.59006613,  1.1374859 ,  0.481758  ,  0.48672074,  0.35165158,\n",
            "       -0.9449005 , -0.7973969 , -0.06593466,  0.80861646, -1.5342362 ,\n",
            "        0.14302911,  0.99058473,  5.7121987 ], dtype=float32), 'agent_1': Array([ 0.69077486,  0.24343842,  0.13039076,  0.05162725,  0.9597243 ,\n",
            "        0.59006613,  0.481758  , -0.6268275 ,  0.48672074,  0.35165158,\n",
            "       -0.9449005 , -0.7973969 , -0.06593466,  0.80861646, -1.5342362 ,\n",
            "        0.14302911,  3.9444952 ,  6.204124  ], dtype=float32), 'agent_2': Array([ 0.69077486,  0.24343842,  0.13039076,  0.05162725,  0.9597243 ,\n",
            "        0.59006613,  0.481758  ,  0.48672074, -0.4838789 ,  0.35165158,\n",
            "       -0.9449005 , -0.7973969 , -0.06593466,  0.80861646, -1.5342362 ,\n",
            "        0.14302911, -2.2160351 ,  3.019566  ], dtype=float32), 'agent_3': Array([ 0.69077486,  0.24343842,  0.13039076,  0.05162725,  0.9597243 ,\n",
            "        0.59006613,  0.481758  ,  0.48672074,  0.35165158,  1.2402815 ,\n",
            "       -0.9449005 , -0.7973969 , -0.06593466,  0.80861646, -1.5342362 ,\n",
            "        0.14302911, -4.6506352 ,  4.6063814 ], dtype=float32)}\n",
            "ctrl action chosen: [1.7914131  0.94732815 1.7945195  0.95493    1.7929136  0.94558316\n",
            " 1.795696   0.9390082 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.81485546, dtype=float32), 'agent_0': Array(-0.81485546, dtype=float32), 'agent_1': Array(-0.81485546, dtype=float32), 'agent_2': Array(-0.81485546, dtype=float32), 'agent_3': Array(-0.81485546, dtype=float32)}\n",
            "step: 328\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67154825,  0.26453155,  0.13983576,  0.05930855,  0.95234007,\n",
            "        0.56746924,  1.2772408 ,  0.6101944 ,  0.5282402 ,  0.3254131 ,\n",
            "        0.29382706, -0.8709848 , -0.6520748 , -0.06653861,  0.66131735,\n",
            "       -0.46507072, -2.1547694 , -0.43259868], dtype=float32), 'agent_1': Array([ 0.67154825,  0.26453155,  0.13983576,  0.05930855,  0.95234007,\n",
            "        0.56746924,  0.6101944 , -0.46847537,  0.5282402 ,  0.3254131 ,\n",
            "        0.29382706, -0.8709848 , -0.6520748 , -0.06653861,  0.66131735,\n",
            "       -0.46507072,  0.16855638, -1.0315175 ], dtype=float32), 'agent_2': Array([ 0.67154825,  0.26453155,  0.13983576,  0.05930855,  0.95234007,\n",
            "        0.56746924,  0.6101944 ,  0.5282402 , -0.47526577,  0.3254131 ,\n",
            "        0.29382706, -0.8709848 , -0.6520748 , -0.06653861,  0.66131735,\n",
            "       -0.46507072,  1.3669138 , -0.6902846 ], dtype=float32), 'agent_3': Array([ 0.67154825,  0.26453155,  0.13983576,  0.05930855,  0.95234007,\n",
            "        0.56746924,  0.6101944 ,  0.5282402 ,  0.3254131 ,  1.2717583 ,\n",
            "        0.29382706, -0.8709848 , -0.6520748 , -0.06653861,  0.66131735,\n",
            "       -0.46507072,  0.9757988 , -0.43565258], dtype=float32)}\n",
            "ctrl action chosen: [-1.3224474  -0.15288655 -1.3224199  -0.15160428 -1.3229775  -0.1510841\n",
            " -1.3228726  -0.15023696]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.4928207, dtype=float32), 'agent_0': Array(-7.4928207, dtype=float32), 'agent_1': Array(-7.4928207, dtype=float32), 'agent_2': Array(-7.4928207, dtype=float32), 'agent_3': Array(-7.4928207, dtype=float32)}\n",
            "step: 329\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2754196e-01,  2.8746543e-02,  1.3169539e-01,  2.5899593e-02,\n",
            "        9.9053478e-01, -1.7740415e-01,  1.2110868e+00,  3.6062396e-03,\n",
            "       -4.9562850e-03, -2.3894340e-01,  1.0724068e-01, -6.9603324e-01,\n",
            "       -1.1115670e+00, -1.4653441e-01,  3.4804216e-01,  1.2698352e+01,\n",
            "       -1.8830385e+01, -1.0367253e+00], dtype=float32), 'agent_1': Array([ 6.2754196e-01,  2.8746543e-02,  1.3169539e-01,  2.5899593e-02,\n",
            "        9.9053478e-01, -1.7740415e-01,  3.6062396e-03, -5.3526241e-01,\n",
            "       -4.9562850e-03, -2.3894340e-01,  1.0724068e-01, -6.9603324e-01,\n",
            "       -1.1115670e+00, -1.4653441e-01,  3.4804216e-01,  1.2698352e+01,\n",
            "       -1.7032282e+01, -6.3872749e-01], dtype=float32), 'agent_2': Array([ 6.2754196e-01,  2.8746543e-02,  1.3169539e-01,  2.5899593e-02,\n",
            "        9.9053478e-01, -1.7740415e-01,  3.6062396e-03, -4.9562850e-03,\n",
            "       -6.2376457e-01, -2.3894340e-01,  1.0724068e-01, -6.9603324e-01,\n",
            "       -1.1115670e+00, -1.4653441e-01,  3.4804216e-01,  1.2698352e+01,\n",
            "       -1.4418463e+01, -2.4661362e+00], dtype=float32), 'agent_3': Array([ 6.2754196e-01,  2.8746543e-02,  1.3169539e-01,  2.5899593e-02,\n",
            "        9.9053478e-01, -1.7740415e-01,  3.6062396e-03, -4.9562850e-03,\n",
            "       -2.3894340e-01,  1.1776073e+00,  1.0724068e-01, -6.9603324e-01,\n",
            "       -1.1115670e+00, -1.4653441e-01,  3.4804216e-01,  1.2698352e+01,\n",
            "       -1.4701890e+01, -1.6618239e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.90404016  1.6894878  -0.9055458   1.6948473  -0.90476334  1.6965129\n",
            " -0.90531695  1.6998172 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2996256, dtype=float32), 'agent_0': Array(-2.2996256, dtype=float32), 'agent_1': Array(-2.2996256, dtype=float32), 'agent_2': Array(-2.2996256, dtype=float32), 'agent_3': Array(-2.2996256, dtype=float32)}\n",
            "step: 330\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7240009e-01, -1.3661152e-01,  1.4277653e-01, -6.1861950e-04,\n",
            "        9.8028147e-01, -6.3375396e-01,  1.2575412e+00, -5.3952891e-01,\n",
            "       -4.9449170e-01, -5.8614135e-01,  2.0794868e-01, -3.3090115e-01,\n",
            "       -1.3487101e+00,  3.4133318e-01,  2.7081463e-01,  3.3310320e-02,\n",
            "        1.4166199e+00,  2.6930794e-01], dtype=float32), 'agent_1': Array([ 5.7240009e-01, -1.3661152e-01,  1.4277653e-01, -6.1861950e-04,\n",
            "        9.8028147e-01, -6.3375396e-01, -5.3952891e-01, -4.8891729e-01,\n",
            "       -4.9449170e-01, -5.8614135e-01,  2.0794868e-01, -3.3090115e-01,\n",
            "       -1.3487101e+00,  3.4133318e-01,  2.7081463e-01,  3.3310320e-02,\n",
            "       -3.3586006e+00, -6.4471489e-01], dtype=float32), 'agent_2': Array([ 5.7240009e-01, -1.3661152e-01,  1.4277653e-01, -6.1861950e-04,\n",
            "        9.8028147e-01, -6.3375396e-01, -5.3952891e-01, -4.9449170e-01,\n",
            "       -4.6400583e-01, -5.8614135e-01,  2.0794868e-01, -3.3090115e-01,\n",
            "       -1.3487101e+00,  3.4133318e-01,  2.7081463e-01,  3.3310320e-02,\n",
            "       -3.7987843e+00,  1.0392835e+00], dtype=float32), 'agent_3': Array([ 5.7240009e-01, -1.3661152e-01,  1.4277653e-01, -6.1861950e-04,\n",
            "        9.8028147e-01, -6.3375396e-01, -5.3952891e-01, -4.9449170e-01,\n",
            "       -5.8614135e-01,  1.2583857e+00,  2.0794868e-01, -3.3090115e-01,\n",
            "       -1.3487101e+00,  3.4133318e-01,  2.7081463e-01,  3.3310320e-02,\n",
            "        1.7046889e+00,  2.3685776e-02], dtype=float32)}\n",
            "ctrl action chosen: [-1.3859755  1.282612  -1.389351   1.2773737 -1.3920282  1.277374\n",
            " -1.3880308  1.2875277]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.3179593, dtype=float32), 'agent_0': Array(-6.3179593, dtype=float32), 'agent_1': Array(-6.3179593, dtype=float32), 'agent_2': Array(-6.3179593, dtype=float32), 'agent_3': Array(-6.3179593, dtype=float32)}\n",
            "step: 331\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5098831 , -0.12114258,  0.12557867, -0.0050305 ,  0.9846468 ,\n",
            "       -0.49672955,  1.2637873 , -0.59124875, -0.57382745, -0.50150156,\n",
            "       -0.20561218, -0.41583776, -1.1851668 , -0.32906497,  0.6180282 ,\n",
            "       -0.46255574,  2.0879884 ,  0.1928433 ], dtype=float32), 'agent_1': Array([ 0.5098831 , -0.12114258,  0.12557867, -0.0050305 ,  0.9846468 ,\n",
            "       -0.49672955, -0.59124875, -0.48077646, -0.57382745, -0.50150156,\n",
            "       -0.20561218, -0.41583776, -1.1851668 , -0.32906497,  0.6180282 ,\n",
            "       -0.46255574, -0.256627  ,  0.41516504], dtype=float32), 'agent_2': Array([ 0.5098831 , -0.12114258,  0.12557867, -0.0050305 ,  0.9846468 ,\n",
            "       -0.49672955, -0.59124875, -0.57382745, -0.46521145, -0.50150156,\n",
            "       -0.20561218, -0.41583776, -1.1851668 , -0.32906497,  0.6180282 ,\n",
            "       -0.46255574, -0.95003074,  0.17979185], dtype=float32), 'agent_3': Array([ 0.5098831 , -0.12114258,  0.12557867, -0.0050305 ,  0.9846468 ,\n",
            "       -0.49672955, -0.59124875, -0.57382745, -0.50150156,  1.2781595 ,\n",
            "       -0.20561218, -0.41583776, -1.1851668 , -0.32906497,  0.6180282 ,\n",
            "       -0.46255574,  0.5698977 ,  0.11493966], dtype=float32)}\n",
            "ctrl action chosen: [-0.41504395 -1.1063129  -0.41866484 -1.104409   -0.41913226 -1.1058211\n",
            " -0.41699705 -1.1027383 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.1313553, dtype=float32), 'agent_0': Array(-6.1313553, dtype=float32), 'agent_1': Array(-6.1313553, dtype=float32), 'agent_2': Array(-6.1313553, dtype=float32), 'agent_3': Array(-6.1313553, dtype=float32)}\n",
            "step: 332\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.8992279e-01, -1.0971511e-01,  6.3709140e-02, -7.4205366e-03,\n",
            "        9.9189150e-01, -4.4199139e-01,  9.5630014e-01, -5.5196971e-01,\n",
            "       -5.4159385e-01, -5.0370938e-01,  2.7213097e-01, -7.6714754e-01,\n",
            "        6.8455935e-02,  1.6970944e-01,  3.3011086e+00,  1.2506692e+00,\n",
            "       -2.1705675e+00, -8.6320782e+00], dtype=float32), 'agent_1': Array([ 0.4899228 , -0.10971511,  0.06370914, -0.00742054,  0.9918915 ,\n",
            "       -0.4419914 , -0.5519697 , -0.74463665, -0.54159385, -0.5037094 ,\n",
            "        0.27213097, -0.76714754,  0.06845593,  0.16970944,  3.3011086 ,\n",
            "        1.2506692 , -0.20696166, -6.0726953 ], dtype=float32), 'agent_2': Array([ 0.4899228 , -0.10971511,  0.06370914, -0.00742054,  0.9918915 ,\n",
            "       -0.4419914 , -0.5519697 , -0.54159385, -0.6699198 , -0.5037094 ,\n",
            "        0.27213097, -0.76714754,  0.06845593,  0.16970944,  3.3011086 ,\n",
            "        1.2506692 ,  0.45458072, -4.9436083 ], dtype=float32), 'agent_3': Array([ 4.8992279e-01, -1.0971511e-01,  6.3709140e-02, -7.4205366e-03,\n",
            "        9.9189150e-01, -4.4199139e-01, -5.5196971e-01, -5.4159385e-01,\n",
            "       -5.0370938e-01,  9.9551523e-01,  2.7213097e-01, -7.6714754e-01,\n",
            "        6.8455935e-02,  1.6970944e-01,  3.3011086e+00,  1.2506692e+00,\n",
            "       -2.6494575e+00, -8.1811152e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.7142216   2.6940641  -0.71789414  2.6984515  -0.71955025  2.6987467\n",
            " -0.71371305  2.7009623 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6610925, dtype=float32), 'agent_0': Array(-1.6610925, dtype=float32), 'agent_1': Array(-1.6610925, dtype=float32), 'agent_2': Array(-1.6610925, dtype=float32), 'agent_3': Array(-1.6610925, dtype=float32)}\n",
            "step: 333\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49240908, -0.12031364,  0.04690911, -0.02803273,  0.9912307 ,\n",
            "       -0.5460628 ,  0.9955388 , -0.5448607 , -0.515027  , -0.5658195 ,\n",
            "       -0.60977936, -0.5795479 ,  0.0349462 , -0.8343616 , -0.13266648,\n",
            "       -0.22724536, -1.0475956 ,  4.1728563 ], dtype=float32), 'agent_1': Array([ 0.49240908, -0.12031364,  0.04690911, -0.02803273,  0.9912307 ,\n",
            "       -0.5460628 , -0.5448607 , -0.5663037 , -0.515027  , -0.5658195 ,\n",
            "       -0.60977936, -0.5795479 ,  0.0349462 , -0.8343616 , -0.13266648,\n",
            "       -0.22724536,  0.72370094,  6.726885  ], dtype=float32), 'agent_2': Array([ 0.49240908, -0.12031364,  0.04690911, -0.02803273,  0.9912307 ,\n",
            "       -0.5460628 , -0.5448607 , -0.515027  , -0.4871313 , -0.5658195 ,\n",
            "       -0.60977936, -0.5795479 ,  0.0349462 , -0.8343616 , -0.13266648,\n",
            "       -0.22724536, -0.06081358,  3.8361938 ], dtype=float32), 'agent_3': Array([ 0.49240908, -0.12031364,  0.04690911, -0.02803273,  0.9912307 ,\n",
            "       -0.5460628 , -0.5448607 , -0.515027  , -0.5658195 ,  1.0176901 ,\n",
            "       -0.60977936, -0.5795479 ,  0.0349462 , -0.8343616 , -0.13266648,\n",
            "       -0.22724536,  0.05993631,  3.470257  ], dtype=float32)}\n",
            "ctrl action chosen: [1.2562721  0.03033829 1.2554464  0.03434623 1.2558764  0.03620362\n",
            " 1.2570771  0.0381517 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-14.820395, dtype=float32), 'agent_0': Array(-14.820395, dtype=float32), 'agent_1': Array(-14.820395, dtype=float32), 'agent_2': Array(-14.820395, dtype=float32), 'agent_3': Array(-14.820395, dtype=float32)}\n",
            "step: 334\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.03227234e-01,  1.18067026e-01,  2.08801776e-02, -3.23047340e-02,\n",
            "        9.92260396e-01, -1.59192625e-02,  9.83803451e-01,  7.21715167e-02,\n",
            "        7.46207312e-02, -1.65151444e-03,  2.43473053e-01, -1.16084814e+00,\n",
            "        8.90523195e-01, -1.31101524e-02,  7.84835875e-01, -1.22514420e+01,\n",
            "        1.52142439e+01, -8.09850097e-01], dtype=float32), 'agent_1': Array([ 5.03227234e-01,  1.18067026e-01,  2.08801776e-02, -3.23047340e-02,\n",
            "        9.92260396e-01, -1.59192625e-02,  7.21715167e-02, -5.10089755e-01,\n",
            "        7.46207312e-02, -1.65151444e-03,  2.43473053e-01, -1.16084814e+00,\n",
            "        8.90523195e-01, -1.31101524e-02,  7.84835875e-01, -1.22514420e+01,\n",
            "        1.60422478e+01, -1.15900517e-01], dtype=float32), 'agent_2': Array([ 5.03227234e-01,  1.18067026e-01,  2.08801776e-02, -3.23047340e-02,\n",
            "        9.92260396e-01, -1.59192625e-02,  7.21715167e-02,  7.46207312e-02,\n",
            "       -5.16633332e-01, -1.65151444e-03,  2.43473053e-01, -1.16084814e+00,\n",
            "        8.90523195e-01, -1.31101524e-02,  7.84835875e-01, -1.22514420e+01,\n",
            "        1.51979713e+01,  1.05791855e+00], dtype=float32), 'agent_3': Array([ 5.03227234e-01,  1.18067026e-01,  2.08801776e-02, -3.23047340e-02,\n",
            "        9.92260396e-01, -1.59192625e-02,  7.21715167e-02,  7.46207312e-02,\n",
            "       -1.65151444e-03,  1.05418062e+00,  2.43473053e-01, -1.16084814e+00,\n",
            "        8.90523195e-01, -1.31101524e-02,  7.84835875e-01, -1.22514420e+01,\n",
            "        1.53577213e+01, -2.63545588e-02], dtype=float32)}\n",
            "ctrl action chosen: [-1.137846  -1.311108  -1.1377186 -1.3088969 -1.1368278 -1.3038195\n",
            " -1.1372316 -1.3058374]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3474114, dtype=float32), 'agent_0': Array(-2.3474114, dtype=float32), 'agent_1': Array(-2.3474114, dtype=float32), 'agent_2': Array(-2.3474114, dtype=float32), 'agent_3': Array(-2.3474114, dtype=float32)}\n",
            "step: 335\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7081372e-01, -9.7823739e-03, -3.3068661e-02, -1.9883366e-02,\n",
            "        9.9920738e-01, -2.7956459e-01,  6.8911266e-01, -1.9554436e-01,\n",
            "       -2.0743819e-01, -2.6716292e-01,  8.8195801e-01, -1.2276649e+00,\n",
            "        1.0523200e+00,  4.1407663e-01,  3.0901866e+00,  1.0013384e+01,\n",
            "       -1.2039785e+01, -8.8556395e+00], dtype=float32), 'agent_1': Array([ 5.7081372e-01, -9.7823739e-03, -3.3068661e-02, -1.9883366e-02,\n",
            "        9.9920738e-01, -2.7956459e-01, -1.9554436e-01, -7.9215562e-01,\n",
            "       -2.0743819e-01, -2.6716292e-01,  8.8195801e-01, -1.2276649e+00,\n",
            "        1.0523200e+00,  4.1407663e-01,  3.0901866e+00,  1.0013384e+01,\n",
            "       -1.2004897e+01, -8.8363714e+00], dtype=float32), 'agent_2': Array([ 5.7081372e-01, -9.7823739e-03, -3.3068661e-02, -1.9883366e-02,\n",
            "        9.9920738e-01, -2.7956459e-01, -1.9554436e-01, -2.0743819e-01,\n",
            "       -7.2979176e-01, -2.6716292e-01,  8.8195801e-01, -1.2276649e+00,\n",
            "        1.0523200e+00,  4.1407663e-01,  3.0901866e+00,  1.0013384e+01,\n",
            "       -1.2044603e+01, -7.6236210e+00], dtype=float32), 'agent_3': Array([ 5.7081372e-01, -9.7823739e-03, -3.3068661e-02, -1.9883366e-02,\n",
            "        9.9920738e-01, -2.7956459e-01, -1.9554436e-01, -2.0743819e-01,\n",
            "       -2.6716292e-01,  7.7144110e-01,  8.8195801e-01, -1.2276649e+00,\n",
            "        1.0523200e+00,  4.1407663e-01,  3.0901866e+00,  1.0013384e+01,\n",
            "       -1.1571108e+01, -7.9283957e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.65582013 -0.3510881   0.65654176 -0.3493269   0.65571785 -0.34857655\n",
            "  0.6550867  -0.34344324]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.248453, dtype=float32), 'agent_0': Array(-4.248453, dtype=float32), 'agent_1': Array(-4.248453, dtype=float32), 'agent_2': Array(-4.248453, dtype=float32), 'agent_3': Array(-4.248453, dtype=float32)}\n",
            "step: 336\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60354483,  0.02229833, -0.08923975, -0.00706659,  0.99573547,\n",
            "       -0.18300414,  0.47098663, -0.11944562, -0.09095037, -0.17933652,\n",
            "        0.7818699 , -1.2889266 ,  0.3761649 ,  0.83683026,  1.6268991 ,\n",
            "       -4.502364  ,  6.903503  ,  0.6171906 ], dtype=float32), 'agent_1': Array([ 6.0354483e-01,  2.2298332e-02, -8.9239754e-02, -7.0665926e-03,\n",
            "        9.9573547e-01, -1.8300414e-01, -1.1944562e-01, -1.1577854e+00,\n",
            "       -9.0950370e-02, -1.7933652e-01,  7.8186989e-01, -1.2889266e+00,\n",
            "        3.7616491e-01,  8.3683026e-01,  1.6268991e+00, -4.5023642e+00,\n",
            "        5.7241683e+00, -7.7945123e+00], dtype=float32), 'agent_2': Array([ 6.0354483e-01,  2.2298332e-02, -8.9239754e-02, -7.0665926e-03,\n",
            "        9.9573547e-01, -1.8300414e-01, -1.1944562e-01, -9.0950370e-02,\n",
            "       -1.0767602e+00, -1.7933652e-01,  7.8186989e-01, -1.2889266e+00,\n",
            "        3.7616491e-01,  8.3683026e-01,  1.6268991e+00, -4.5023642e+00,\n",
            "        7.2025709e+00, -6.9120092e+00], dtype=float32), 'agent_3': Array([ 0.60354483,  0.02229833, -0.08923975, -0.00706659,  0.99573547,\n",
            "       -0.18300414, -0.11944562, -0.09095037, -0.17933652,  0.46869415,\n",
            "        0.7818699 , -1.2889266 ,  0.3761649 ,  0.83683026,  1.6268991 ,\n",
            "       -4.502364  ,  5.9882135 , -3.4689455 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.5063595 -1.6827945  1.5072014 -1.6978562  1.5065942 -1.6968601\n",
            "  1.5021181 -1.6923146]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.6907126, dtype=float32), 'agent_0': Array(0.6907126, dtype=float32), 'agent_1': Array(0.6907126, dtype=float32), 'agent_2': Array(0.6907126, dtype=float32), 'agent_3': Array(0.6907126, dtype=float32)}\n",
            "step: 337\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6300724 ,  0.2870384 , -0.10696299, -0.04264736,  0.9509727 ,\n",
            "        0.5500739 ,  0.46434325,  0.550012  ,  0.62276095,  0.50897926,\n",
            "        0.37493706, -0.98353624,  0.56319237,  0.03250873, -0.2857963 ,\n",
            "       -6.444131  ,  9.43479   ,  1.5550084 ], dtype=float32), 'agent_1': Array([ 0.6300724 ,  0.2870384 , -0.10696299, -0.04264736,  0.9509727 ,\n",
            "        0.5500739 ,  0.550012  , -1.2851813 ,  0.62276095,  0.50897926,\n",
            "        0.37493706, -0.98353624,  0.56319237,  0.03250873, -0.2857963 ,\n",
            "       -6.444131  ,  8.564234  ,  1.1498569 ], dtype=float32), 'agent_2': Array([ 0.6300724 ,  0.2870384 , -0.10696299, -0.04264736,  0.9509727 ,\n",
            "        0.5500739 ,  0.550012  ,  0.62276095, -1.3014503 ,  0.50897926,\n",
            "        0.37493706, -0.98353624,  0.56319237,  0.03250873, -0.2857963 ,\n",
            "       -6.444131  ,  6.51548   ,  0.99104   ], dtype=float32), 'agent_3': Array([ 0.6300724 ,  0.2870384 , -0.10696299, -0.04264736,  0.9509727 ,\n",
            "        0.5500739 ,  0.550012  ,  0.62276095,  0.50897926,  0.46963334,\n",
            "        0.37493706, -0.98353624,  0.56319237,  0.03250873, -0.2857963 ,\n",
            "       -6.444131  ,  9.531036  ,  1.4248589 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.9689814   0.11588255 -1.9722284   0.11319554 -1.9736223   0.11525267\n",
            " -1.9687276   0.11552867]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.550421, dtype=float32), 'agent_0': Array(-8.550421, dtype=float32), 'agent_1': Array(-8.550421, dtype=float32), 'agent_2': Array(-8.550421, dtype=float32), 'agent_3': Array(-8.550421, dtype=float32)}\n",
            "step: 338\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.62560135,   0.11102808,  -0.09877229,  -0.01989643,\n",
            "         0.98869663,   0.1902098 ,   0.7073275 ,   0.15335208,\n",
            "         0.16117565,   0.12607434,   0.44765472,  -1.1856437 ,\n",
            "        -0.53503513,   0.23787759,  -0.46876544,  11.472026  ,\n",
            "       -12.829618  ,   5.9112267 ], dtype=float32), 'agent_1': Array([  0.62560135,   0.11102808,  -0.09877229,  -0.01989643,\n",
            "         0.98869663,   0.1902098 ,   0.15335208,  -1.1979548 ,\n",
            "         0.16117565,   0.12607434,   0.44765472,  -1.1856437 ,\n",
            "        -0.53503513,   0.23787759,  -0.46876544,  11.472026  ,\n",
            "       -13.573037  ,   1.6924688 ], dtype=float32), 'agent_2': Array([  0.62560135,   0.11102808,  -0.09877229,  -0.01989643,\n",
            "         0.98869663,   0.1902098 ,   0.15335208,   0.16117565,\n",
            "        -1.2195942 ,   0.12607434,   0.44765472,  -1.1856437 ,\n",
            "        -0.53503513,   0.23787759,  -0.46876544,  11.472026  ,\n",
            "       -15.20314   ,   1.3879229 ], dtype=float32), 'agent_3': Array([  0.62560135,   0.11102808,  -0.09877229,  -0.01989643,\n",
            "         0.98869663,   0.1902098 ,   0.15335208,   0.16117565,\n",
            "         0.12607434,   0.6687187 ,   0.44765472,  -1.1856437 ,\n",
            "        -0.53503513,   0.23787759,  -0.46876544,  11.472026  ,\n",
            "       -13.443252  ,   4.5273137 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.42991927  0.21542898 -0.41984263  0.21496928 -0.42000863  0.21330935\n",
            " -0.42687362  0.21691903]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.404405, dtype=float32), 'agent_0': Array(-6.404405, dtype=float32), 'agent_1': Array(-6.404405, dtype=float32), 'agent_2': Array(-6.404405, dtype=float32), 'agent_3': Array(-6.404405, dtype=float32)}\n",
            "step: 339\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0817891e-01, -1.2086156e-01, -6.7030102e-02,  3.0220777e-03,\n",
            "        9.9039906e-01, -3.3963773e-01,  9.3946397e-01, -4.0397036e-01,\n",
            "       -4.5365518e-01, -4.1536999e-01, -1.2874603e-02, -6.7353249e-01,\n",
            "       -1.2701750e-01, -4.0871021e-01, -1.7829441e+00,  7.8117428e+00,\n",
            "       -9.4514475e+00,  3.1574886e+00], dtype=float32), 'agent_1': Array([ 6.0817891e-01, -1.2086156e-01, -6.7030102e-02,  3.0220777e-03,\n",
            "        9.9039906e-01, -3.3963773e-01, -4.0397036e-01, -9.8711795e-01,\n",
            "       -4.5365518e-01, -4.1536999e-01, -1.2874603e-02, -6.7353249e-01,\n",
            "       -1.2701750e-01, -4.0871021e-01, -1.7829441e+00,  7.8117428e+00,\n",
            "       -9.3704948e+00,  5.2144070e+00], dtype=float32), 'agent_2': Array([ 6.0817891e-01, -1.2086156e-01, -6.7030102e-02,  3.0220777e-03,\n",
            "        9.9039906e-01, -3.3963773e-01, -4.0397036e-01, -4.5365518e-01,\n",
            "       -9.7359759e-01, -4.1536999e-01, -1.2874603e-02, -6.7353249e-01,\n",
            "       -1.2701750e-01, -4.0871021e-01, -1.7829441e+00,  7.8117428e+00,\n",
            "       -1.0162363e+01,  6.4567285e+00], dtype=float32), 'agent_3': Array([ 6.0817891e-01, -1.2086156e-01, -6.7030102e-02,  3.0220777e-03,\n",
            "        9.9039906e-01, -3.3963773e-01, -4.0397036e-01, -4.5365518e-01,\n",
            "       -4.1536999e-01,  8.9023566e-01, -1.2874603e-02, -6.7353249e-01,\n",
            "       -1.2701750e-01, -4.0871021e-01, -1.7829441e+00,  7.8117428e+00,\n",
            "       -9.1794205e+00,  4.0059838e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.9716579  1.4310296  0.9692553  1.4342078  0.96889675 1.4326836\n",
            " 0.97083986 1.4360576 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.73346734, dtype=float32), 'agent_0': Array(0.73346734, dtype=float32), 'agent_1': Array(0.73346734, dtype=float32), 'agent_2': Array(0.73346734, dtype=float32), 'agent_3': Array(0.73346734, dtype=float32)}\n",
            "step: 340\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.9299493e-01,  3.4241524e-02,  1.5360729e-02, -1.3972930e-02,\n",
            "        9.9919784e-01,  3.7494667e-02,  1.2571847e+00,  4.0935362e-03,\n",
            "       -1.0471480e-01, -2.5998276e-02, -4.8575401e-01, -7.7748299e-01,\n",
            "       -3.0382872e-01,  7.0798196e-02, -3.6785524e+00, -1.0644874e+01,\n",
            "        1.3123698e+01,  5.4521832e+00], dtype=float32), 'agent_1': Array([ 5.9299493e-01,  3.4241524e-02,  1.5360729e-02, -1.3972930e-02,\n",
            "        9.9919784e-01,  3.7494667e-02,  4.0935362e-03, -5.0660884e-01,\n",
            "       -1.0471480e-01, -2.5998276e-02, -4.8575401e-01, -7.7748299e-01,\n",
            "       -3.0382872e-01,  7.0798196e-02, -3.6785524e+00, -1.0644874e+01,\n",
            "        1.3893802e+01,  1.0576308e+01], dtype=float32), 'agent_2': Array([ 5.9299493e-01,  3.4241524e-02,  1.5360729e-02, -1.3972930e-02,\n",
            "        9.9919784e-01,  3.7494667e-02,  4.0935362e-03, -1.0471480e-01,\n",
            "       -4.8552841e-01, -2.5998276e-02, -4.8575401e-01, -7.7748299e-01,\n",
            "       -3.0382872e-01,  7.0798196e-02, -3.6785524e+00, -1.0644874e+01,\n",
            "        1.2612354e+01,  9.0512409e+00], dtype=float32), 'agent_3': Array([ 5.9299493e-01,  3.4241524e-02,  1.5360729e-02, -1.3972930e-02,\n",
            "        9.9919784e-01,  3.7494667e-02,  4.0935362e-03, -1.0471480e-01,\n",
            "       -2.5998276e-02,  1.3021015e+00, -4.8575401e-01, -7.7748299e-01,\n",
            "       -3.0382872e-01,  7.0798196e-02, -3.6785524e+00, -1.0644874e+01,\n",
            "        1.3037544e+01,  4.4093995e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.27844033 -2.6127186  -0.27713382 -2.6066372  -0.27987808 -2.6079473\n",
            " -0.2801758  -2.6128662 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.328829, dtype=float32), 'agent_0': Array(-5.328829, dtype=float32), 'agent_1': Array(-5.328829, dtype=float32), 'agent_2': Array(-5.328829, dtype=float32), 'agent_3': Array(-5.328829, dtype=float32)}\n",
            "step: 341\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8632833e-01,  7.6067038e-02, -5.6998716e-03,  2.9877890e-03,\n",
            "        9.9708194e-01,  1.7659500e-01,  1.0429039e+00,  1.3378896e-01,\n",
            "       -4.9953110e-04,  9.0874255e-02,  9.6192360e-01, -8.4037781e-01,\n",
            "        4.4685602e-01,  4.0113127e-01,  9.1573554e-01,  6.9618529e-01,\n",
            "       -6.3779527e-01, -5.9382000e+00], dtype=float32), 'agent_1': Array([ 5.8632833e-01,  7.6067038e-02, -5.6998716e-03,  2.9877890e-03,\n",
            "        9.9708194e-01,  1.7659500e-01,  1.3378896e-01, -6.7482185e-01,\n",
            "       -4.9953110e-04,  9.0874255e-02,  9.6192360e-01, -8.4037781e-01,\n",
            "        4.4685602e-01,  4.0113127e-01,  9.1573554e-01,  6.9618529e-01,\n",
            "       -7.3158753e-01, -5.9883904e+00], dtype=float32), 'agent_2': Array([ 5.8632833e-01,  7.6067038e-02, -5.6998716e-03,  2.9877890e-03,\n",
            "        9.9708194e-01,  1.7659500e-01,  1.3378896e-01, -4.9953110e-04,\n",
            "       -6.3755035e-01,  9.0874255e-02,  9.6192360e-01, -8.4037781e-01,\n",
            "        4.4685602e-01,  4.0113127e-01,  9.1573554e-01,  6.9618529e-01,\n",
            "       -1.1461509e+00, -4.6109104e+00], dtype=float32), 'agent_3': Array([ 5.8632833e-01,  7.6067038e-02, -5.6998716e-03,  2.9877890e-03,\n",
            "        9.9708194e-01,  1.7659500e-01,  1.3378896e-01, -4.9953110e-04,\n",
            "        9.0874255e-02,  1.0354954e+00,  9.6192360e-01, -8.4037781e-01,\n",
            "        4.4685602e-01,  4.0113127e-01,  9.1573554e-01,  6.9618529e-01,\n",
            "       -5.4690522e-01, -7.0779705e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.15662074 -0.04822985  0.15576233 -0.04735609  0.1539489  -0.04621501\n",
            "  0.15732387 -0.04641564]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.366192, dtype=float32), 'agent_0': Array(-12.366192, dtype=float32), 'agent_1': Array(-12.366192, dtype=float32), 'agent_2': Array(-12.366192, dtype=float32), 'agent_3': Array(-12.366192, dtype=float32)}\n",
            "step: 342\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.9008086e-01,  9.7046182e-02, -1.6496723e-03,  1.6552741e-02,\n",
            "        9.9514085e-01,  2.2965860e-01,  9.0268934e-01,  1.7472424e-01,\n",
            "        5.2602764e-02,  1.4660524e-01,  6.4845085e-01, -8.1255436e-01,\n",
            "       -2.3353100e-01,  4.5323780e-01,  1.5099272e-01, -1.0091233e+00,\n",
            "        1.5537375e+00, -3.0072656e+00], dtype=float32), 'agent_1': Array([ 5.9008086e-01,  9.7046182e-02, -1.6496723e-03,  1.6552741e-02,\n",
            "        9.9514085e-01,  2.2965860e-01,  1.7472424e-01, -7.9478848e-01,\n",
            "        5.2602764e-02,  1.4660524e-01,  6.4845085e-01, -8.1255436e-01,\n",
            "       -2.3353100e-01,  4.5323780e-01,  1.5099272e-01, -1.0091233e+00,\n",
            "        1.2391381e+00, -2.6229687e+00], dtype=float32), 'agent_2': Array([ 5.9008086e-01,  9.7046182e-02, -1.6496723e-03,  1.6552741e-02,\n",
            "        9.9514085e-01,  2.2965860e-01,  1.7472424e-01,  5.2602764e-02,\n",
            "       -7.4498165e-01,  1.4660524e-01,  6.4845085e-01, -8.1255436e-01,\n",
            "       -2.3353100e-01,  4.5323780e-01,  1.5099272e-01, -1.0091233e+00,\n",
            "        1.4991773e+00, -2.9610021e+00], dtype=float32), 'agent_3': Array([ 5.9008086e-01,  9.7046182e-02, -1.6496723e-03,  1.6552741e-02,\n",
            "        9.9514085e-01,  2.2965860e-01,  1.7472424e-01,  5.2602764e-02,\n",
            "        1.4660524e-01,  8.2202023e-01,  6.4845085e-01, -8.1255436e-01,\n",
            "       -2.3353100e-01,  4.5323780e-01,  1.5099272e-01, -1.0091233e+00,\n",
            "        1.3165269e+00, -4.1128569e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.4311398  -0.4463319   0.42900187 -0.44575793  0.42951173 -0.44518\n",
            "  0.43269593 -0.44570357]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.6589622, dtype=float32), 'agent_0': Array(1.6589622, dtype=float32), 'agent_1': Array(1.6589622, dtype=float32), 'agent_2': Array(1.6589622, dtype=float32), 'agent_3': Array(1.6589622, dtype=float32)}\n",
            "step: 343\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5590991 ,  0.21226685, -0.03580431,  0.01840414,  0.97638214,\n",
            "        0.53963846,  0.5784344 ,  0.45436385,  0.34966648,  0.42758548,\n",
            "        0.96092224, -0.79858303, -0.9076834 , -0.32305542,  1.6154786 ,\n",
            "       -5.3706164 ,  6.7752347 , -7.798515  ], dtype=float32), 'agent_1': Array([ 0.5590991 ,  0.21226685, -0.03580431,  0.01840414,  0.97638214,\n",
            "        0.53963846,  0.45436385, -1.0838383 ,  0.34966648,  0.42758548,\n",
            "        0.96092224, -0.79858303, -0.9076834 , -0.32305542,  1.6154786 ,\n",
            "       -5.3706164 ,  6.560743  , -6.916936  ], dtype=float32), 'agent_2': Array([ 0.5590991 ,  0.21226685, -0.03580431,  0.01840414,  0.97638214,\n",
            "        0.53963846,  0.45436385,  0.34966648, -1.0611157 ,  0.42758548,\n",
            "        0.96092224, -0.79858303, -0.9076834 , -0.32305542,  1.6154786 ,\n",
            "       -5.3706164 ,  6.863135  , -7.119439  ], dtype=float32), 'agent_3': Array([ 0.5590991 ,  0.21226685, -0.03580431,  0.01840414,  0.97638214,\n",
            "        0.53963846,  0.45436385,  0.34966648,  0.42758548,  0.4873179 ,\n",
            "        0.96092224, -0.79858303, -0.9076834 , -0.32305542,  1.6154786 ,\n",
            "       -5.3706164 ,  6.676496  , -5.978848  ], dtype=float32)}\n",
            "ctrl action chosen: [0.03574209 0.09372717 0.03339041 0.09318255 0.03447206 0.09529517\n",
            " 0.03269119 0.09536313]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0881336, dtype=float32), 'agent_0': Array(1.0881336, dtype=float32), 'agent_1': Array(1.0881336, dtype=float32), 'agent_2': Array(1.0881336, dtype=float32), 'agent_3': Array(1.0881336, dtype=float32)}\n",
            "step: 344\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5322398 ,  0.22823802, -0.03342104,  0.01919106,  0.97284234,\n",
            "        0.53296226,  0.51222616,  0.5250514 ,  0.43520305,  0.5039393 ,\n",
            "        0.685215  , -0.67481995,  0.50860643,  0.37079662, -0.18073545,\n",
            "        0.17955126, -1.3292272 ,  0.7818933 ], dtype=float32), 'agent_1': Array([ 0.5322398 ,  0.22823802, -0.03342104,  0.01919106,  0.97284234,\n",
            "        0.53296226,  0.5250514 , -1.2229805 ,  0.43520305,  0.5039393 ,\n",
            "        0.685215  , -0.67481995,  0.50860643,  0.37079662, -0.18073545,\n",
            "        0.17955126,  0.2884256 , -0.40644494], dtype=float32), 'agent_2': Array([ 0.5322398 ,  0.22823802, -0.03342104,  0.01919106,  0.97284234,\n",
            "        0.53296226,  0.5250514 ,  0.43520305, -1.1723591 ,  0.5039393 ,\n",
            "        0.685215  , -0.67481995,  0.50860643,  0.37079662, -0.18073545,\n",
            "        0.17955126,  0.9374311 ,  0.9470774 ], dtype=float32), 'agent_3': Array([ 0.5322398 ,  0.22823802, -0.03342104,  0.01919106,  0.97284234,\n",
            "        0.53296226,  0.5250514 ,  0.43520305,  0.5039393 ,  0.5204041 ,\n",
            "        0.685215  , -0.67481995,  0.50860643,  0.37079662, -0.18073545,\n",
            "        0.17955126,  0.4634931 ,  0.5575298 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.990301   -0.9435158   1.9922161  -0.9401701   1.989555   -0.93651557\n",
            "  1.9896779  -0.9401313 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.8282138, dtype=float32), 'agent_0': Array(1.8282138, dtype=float32), 'agent_1': Array(1.8282138, dtype=float32), 'agent_2': Array(1.8282138, dtype=float32), 'agent_3': Array(1.8282138, dtype=float32)}\n",
            "step: 345\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5765474 ,  0.24313278, -0.05219552,  0.01031748,  0.9685327 ,\n",
            "        0.5231354 ,  0.4855937 ,  0.550993  ,  0.5681981 ,  0.5619179 ,\n",
            "        0.47240257, -0.4087448 ,  0.5829215 , -0.2455448 , -0.00681398,\n",
            "        0.18542768, -0.11939643,  0.5186352 ], dtype=float32), 'agent_1': Array([ 0.5765474 ,  0.24313278, -0.05219552,  0.01031748,  0.9685327 ,\n",
            "        0.5231354 ,  0.550993  , -1.2701813 ,  0.5681981 ,  0.5619179 ,\n",
            "        0.47240257, -0.4087448 ,  0.5829215 , -0.2455448 , -0.00681398,\n",
            "        0.18542768, -0.33052203,  0.5038282 ], dtype=float32), 'agent_2': Array([ 0.5765474 ,  0.24313278, -0.05219552,  0.01031748,  0.9685327 ,\n",
            "        0.5231354 ,  0.550993  ,  0.5681981 , -1.2572179 ,  0.5619179 ,\n",
            "        0.47240257, -0.4087448 ,  0.5829215 , -0.2455448 , -0.00681398,\n",
            "        0.18542768,  1.1490387 , -0.20354639], dtype=float32), 'agent_3': Array([ 0.5765474 ,  0.24313278, -0.05219552,  0.01031748,  0.9685327 ,\n",
            "        0.5231354 ,  0.550993  ,  0.5681981 ,  0.5619179 ,  0.50053746,\n",
            "        0.47240257, -0.4087448 ,  0.5829215 , -0.2455448 , -0.00681398,\n",
            "        0.18542768,  0.19691032,  0.6156054 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.2950487  -0.8358598  -2.2939322  -0.8350566  -2.2950003  -0.83304065\n",
            " -2.2952313  -0.8357108 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.073906, dtype=float32), 'agent_0': Array(-8.073906, dtype=float32), 'agent_1': Array(-8.073906, dtype=float32), 'agent_2': Array(-8.073906, dtype=float32), 'agent_3': Array(-8.073906, dtype=float32)}\n",
            "step: 346\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8964235e-01,  7.9218326e-03, -5.7225559e-02,  2.2314278e-02,\n",
            "        9.9808043e-01, -8.2689226e-02,  4.9439782e-01, -4.9909778e-02,\n",
            "        6.5978065e-02, -1.2086080e-02,  5.2270889e-01, -6.3569546e-01,\n",
            "        6.6399574e-02, -3.8852572e-02,  6.2631452e-01,  1.2924215e+01,\n",
            "       -1.6187826e+01, -1.9420034e-01], dtype=float32), 'agent_1': Array([ 5.8964235e-01,  7.9218326e-03, -5.7225559e-02,  2.2314278e-02,\n",
            "        9.9808043e-01, -8.2689226e-02, -4.9909778e-02, -1.2580273e+00,\n",
            "        6.5978065e-02, -1.2086080e-02,  5.2270889e-01, -6.3569546e-01,\n",
            "        6.6399574e-02, -3.8852572e-02,  6.2631452e-01,  1.2924215e+01,\n",
            "       -1.6286798e+01,  1.9748880e-01], dtype=float32), 'agent_2': Array([ 5.8964235e-01,  7.9218326e-03, -5.7225559e-02,  2.2314278e-02,\n",
            "        9.9808043e-01, -8.2689226e-02, -4.9909778e-02,  6.5978065e-02,\n",
            "       -1.2732954e+00, -1.2086080e-02,  5.2270889e-01, -6.3569546e-01,\n",
            "        6.6399574e-02, -3.8852572e-02,  6.2631452e-01,  1.2924215e+01,\n",
            "       -1.4875686e+01, -2.3791508e-01], dtype=float32), 'agent_3': Array([ 5.8964235e-01,  7.9218326e-03, -5.7225559e-02,  2.2314278e-02,\n",
            "        9.9808043e-01, -8.2689226e-02, -4.9909778e-02,  6.5978065e-02,\n",
            "       -1.2086080e-02,  4.8513645e-01,  5.2270889e-01, -6.3569546e-01,\n",
            "        6.6399574e-02, -3.8852572e-02,  6.2631452e-01,  1.2924215e+01,\n",
            "       -1.6141644e+01, -6.6727692e-01], dtype=float32)}\n",
            "ctrl action chosen: [-2.2322512  1.1567125 -2.2312262  1.1573067 -2.2334712  1.1595119\n",
            " -2.2310462  1.1581855]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.428119, dtype=float32), 'agent_0': Array(-10.428119, dtype=float32), 'agent_1': Array(-10.428119, dtype=float32), 'agent_2': Array(-10.428119, dtype=float32), 'agent_3': Array(-10.428119, dtype=float32)}\n",
            "step: 347\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58172226, -0.21168779, -0.01526479,  0.02188436,  0.9769731 ,\n",
            "       -0.6011747 ,  0.82215524, -0.585453  , -0.52144164, -0.5751207 ,\n",
            "       -0.17733574, -0.28398037, -0.40699244, -1.2577897 , -1.9017876 ,\n",
            "       -0.4052613 ,  1.9763068 ,  9.140899  ], dtype=float32), 'agent_1': Array([ 0.58172226, -0.21168779, -0.01526479,  0.02188436,  0.9769731 ,\n",
            "       -0.6011747 , -0.585453  , -0.89599186, -0.52144164, -0.5751207 ,\n",
            "       -0.17733574, -0.28398037, -0.40699244, -1.2577897 , -1.9017876 ,\n",
            "       -0.4052613 ,  1.2728807 , 10.156466  ], dtype=float32), 'agent_2': Array([ 0.58172226, -0.21168779, -0.01526479,  0.02188436,  0.9769731 ,\n",
            "       -0.6011747 , -0.585453  , -0.52144164, -0.9472188 , -0.5751207 ,\n",
            "       -0.17733574, -0.28398037, -0.40699244, -1.2577897 , -1.9017876 ,\n",
            "       -0.4052613 , -2.5711842 ,  9.785517  ], dtype=float32), 'agent_3': Array([ 0.58172226, -0.21168779, -0.01526479,  0.02188436,  0.9769731 ,\n",
            "       -0.6011747 , -0.585453  , -0.52144164, -0.5751207 ,  0.7493894 ,\n",
            "       -0.17733574, -0.28398037, -0.40699244, -1.2577897 , -1.9017876 ,\n",
            "       -0.4052613 ,  0.1596584 ,  7.821275  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.308994   -1.6107394   0.30859926 -1.6116331   0.30802557 -1.6214669\n",
            "  0.30928528 -1.6110716 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-11.524376, dtype=float32), 'agent_0': Array(-11.524376, dtype=float32), 'agent_1': Array(-11.524376, dtype=float32), 'agent_2': Array(-11.524376, dtype=float32), 'agent_3': Array(-11.524376, dtype=float32)}\n",
            "step: 348\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55000544, -0.14215377, -0.03815664,  0.02098512,  0.98888624,\n",
            "       -0.34364554,  0.78644437, -0.37784538, -0.43486857, -0.41024557,\n",
            "        0.48627853, -0.35836697, -0.83556175,  0.4809547 ,  1.9828138 ,\n",
            "       -5.26602   ,  8.428446  , -4.0841904 ], dtype=float32), 'agent_1': Array([ 0.55000544, -0.14215377, -0.03815664,  0.02098512,  0.98888624,\n",
            "       -0.34364554, -0.37784538, -0.90704733, -0.43486857, -0.41024557,\n",
            "        0.48627853, -0.35836697, -0.83556175,  0.4809547 ,  1.9828138 ,\n",
            "       -5.26602   ,  7.493831  , -4.001458  ], dtype=float32), 'agent_2': Array([ 0.55000544, -0.14215377, -0.03815664,  0.02098512,  0.98888624,\n",
            "       -0.34364554, -0.37784538, -0.43486857, -0.9675784 , -0.41024557,\n",
            "        0.48627853, -0.35836697, -0.83556175,  0.4809547 ,  1.9828138 ,\n",
            "       -5.26602   ,  4.161934  , -4.2090855 ], dtype=float32), 'agent_3': Array([ 0.55000544, -0.14215377, -0.03815664,  0.02098512,  0.98888624,\n",
            "       -0.34364554, -0.37784538, -0.43486857, -0.41024557,  0.70771146,\n",
            "        0.48627853, -0.35836697, -0.83556175,  0.4809547 ,  1.9828138 ,\n",
            "       -5.26602   ,  6.7622333 , -4.205659  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.03905242 -0.01719128  0.03810664 -0.01480222  0.03331435 -0.01312438\n",
            "  0.0363359  -0.01307477]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.094137, dtype=float32), 'agent_0': Array(-4.094137, dtype=float32), 'agent_1': Array(-4.094137, dtype=float32), 'agent_2': Array(-4.094137, dtype=float32), 'agent_3': Array(-4.094137, dtype=float32)}\n",
            "step: 349\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5247583 , -0.07865668, -0.04480882,  0.01466538,  0.9957863 ,\n",
            "       -0.13245533,  0.746383  , -0.19976796, -0.35016805, -0.23007603,\n",
            "        0.49071312, -0.45530796, -0.74715614, -0.0128147 ,  0.10355734,\n",
            "       -0.9970575 ,  2.0823662 , -0.760462  ], dtype=float32), 'agent_1': Array([ 0.5247583 , -0.07865668, -0.04480882,  0.01466538,  0.9957863 ,\n",
            "       -0.13245533, -0.19976796, -0.9374166 , -0.35016805, -0.23007603,\n",
            "        0.49071312, -0.45530796, -0.74715614, -0.0128147 ,  0.10355734,\n",
            "       -0.9970575 ,  1.6357402 , -0.6279395 ], dtype=float32), 'agent_2': Array([ 0.5247583 , -0.07865668, -0.04480882,  0.01466538,  0.9957863 ,\n",
            "       -0.13245533, -0.19976796, -0.35016805, -0.99310863, -0.23007603,\n",
            "        0.49071312, -0.45530796, -0.74715614, -0.0128147 ,  0.10355734,\n",
            "       -0.9970575 ,  0.238975  , -0.28242818], dtype=float32), 'agent_3': Array([ 0.5247583 , -0.07865668, -0.04480882,  0.01466538,  0.9957863 ,\n",
            "       -0.13245533, -0.19976796, -0.35016805, -0.23007603,  0.6480912 ,\n",
            "        0.49071312, -0.45530796, -0.74715614, -0.0128147 ,  0.10355734,\n",
            "       -0.9970575 ,  1.8484206 , -1.3923515 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.2596894  -3.0668173  -0.2614658  -3.0662885  -0.26225471 -3.0647519\n",
            " -0.26183343 -3.0657709 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.4914525, dtype=float32), 'agent_0': Array(1.4914525, dtype=float32), 'agent_1': Array(1.4914525, dtype=float32), 'agent_2': Array(1.4914525, dtype=float32), 'agent_3': Array(1.4914525, dtype=float32)}\n",
            "step: 350\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48971328, -0.12807511, -0.10828963,  0.01748173,  0.9856798 ,\n",
            "       -0.20927985,  0.43050367, -0.3124037 , -0.5098192 , -0.34378612,\n",
            "        1.0984898 , -0.3768444 , -0.61585903, -0.11090463,  2.3214364 ,\n",
            "        2.7381763 , -2.6547394 , -2.1022563 ], dtype=float32), 'agent_1': Array([ 0.48971328, -0.12807511, -0.10828963,  0.01748173,  0.9856798 ,\n",
            "       -0.20927985, -0.3124037 , -1.2800483 , -0.5098192 , -0.34378612,\n",
            "        1.0984898 , -0.3768444 , -0.61585903, -0.11090463,  2.3214364 ,\n",
            "        2.7381763 , -3.5262878 , -5.0473623 ], dtype=float32), 'agent_2': Array([ 0.48971328, -0.12807511, -0.10828963,  0.01748173,  0.9856798 ,\n",
            "       -0.20927985, -0.3124037 , -0.5098192 , -1.2871318 , -0.34378612,\n",
            "        1.0984898 , -0.3768444 , -0.61585903, -0.11090463,  2.3214364 ,\n",
            "        2.7381763 , -3.9894454 , -3.63584   ], dtype=float32), 'agent_3': Array([ 0.48971328, -0.12807511, -0.10828963,  0.01748173,  0.9856798 ,\n",
            "       -0.20927985, -0.3124037 , -0.5098192 , -0.34378612,  0.44139796,\n",
            "        1.0984898 , -0.3768444 , -0.61585903, -0.11090463,  2.3214364 ,\n",
            "        2.7381763 , -3.42252   ,  0.67571765], dtype=float32)}\n",
            "ctrl action chosen: [1.196088   0.19738853 1.1965423  0.19385502 1.1982392  0.19308542\n",
            " 1.1966064  0.20225365]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-17.030262, dtype=float32), 'agent_0': Array(-17.030262, dtype=float32), 'agent_1': Array(-17.030262, dtype=float32), 'agent_2': Array(-17.030262, dtype=float32), 'agent_3': Array(-17.030262, dtype=float32)}\n",
            "step: 351\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.8512632e-01,  7.4846260e-02, -9.6507154e-02, -1.4932876e-02,\n",
            "        9.9240184e-01,  3.2820725e-01,  5.3646141e-01,  1.8978134e-01,\n",
            "       -4.1900445e-02,  1.6510934e-01,  9.3030930e-02, -4.6634674e-02,\n",
            "        6.2538981e-01, -7.1387690e-01,  3.8750809e-01, -1.1505119e+01,\n",
            "        1.5286116e+01,  2.2023956e-01], dtype=float32), 'agent_1': Array([  0.48512632,   0.07484626,  -0.09650715,  -0.01493288,\n",
            "         0.99240184,   0.32820725,   0.18978134,  -1.1957535 ,\n",
            "        -0.04190044,   0.16510934,   0.09303093,  -0.04663467,\n",
            "         0.6253898 ,  -0.7138769 ,   0.3875081 , -11.505119  ,\n",
            "        14.728127  ,   0.55366623], dtype=float32), 'agent_2': Array([  0.48512632,   0.07484626,  -0.09650715,  -0.01493288,\n",
            "         0.99240184,   0.32820725,   0.18978134,  -0.04190044,\n",
            "        -1.1505513 ,   0.16510934,   0.09303093,  -0.04663467,\n",
            "         0.6253898 ,  -0.7138769 ,   0.3875081 , -11.505119  ,\n",
            "        13.715666  ,   1.8719941 ], dtype=float32), 'agent_3': Array([  0.48512632,   0.07484626,  -0.09650715,  -0.01493288,\n",
            "         0.99240184,   0.32820725,   0.18978134,  -0.04190044,\n",
            "         0.16510934,   0.5491829 ,   0.09303093,  -0.04663467,\n",
            "         0.6253898 ,  -0.7138769 ,   0.3875081 , -11.505119  ,\n",
            "        14.566578  ,   1.5994779 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.332429    0.12603365 -0.33489814  0.12592493 -0.33330747  0.1327787\n",
            " -0.3323951   0.13117814]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5632522, dtype=float32), 'agent_0': Array(-1.5632522, dtype=float32), 'agent_1': Array(-1.5632522, dtype=float32), 'agent_2': Array(-1.5632522, dtype=float32), 'agent_3': Array(-1.5632522, dtype=float32)}\n",
            "step: 352\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5156973 ,  0.09612609, -0.09452945, -0.03057878,  0.9903984 ,\n",
            "        0.48348945,  0.5613751 ,  0.3150104 ,  0.01509188,  0.26753366,\n",
            "       -0.10528564, -0.22380352,  0.5554557 , -0.1543616 , -0.5751444 ,\n",
            "        1.9139736 , -0.7680452 ,  0.41904575], dtype=float32), 'agent_1': Array([ 0.5156973 ,  0.09612609, -0.09452945, -0.03057878,  0.9903984 ,\n",
            "        0.48348945,  0.3150104 , -1.126518  ,  0.01509188,  0.26753366,\n",
            "       -0.10528564, -0.22380352,  0.5554557 , -0.1543616 , -0.5751444 ,\n",
            "        1.9139736 , -1.2785397 ,  2.5024104 ], dtype=float32), 'agent_2': Array([ 0.5156973 ,  0.09612609, -0.09452945, -0.03057878,  0.9903984 ,\n",
            "        0.48348945,  0.3150104 ,  0.01509188, -1.0803779 ,  0.26753366,\n",
            "       -0.10528564, -0.22380352,  0.5554557 , -0.1543616 , -0.5751444 ,\n",
            "        1.9139736 , -2.485427  ,  2.168998  ], dtype=float32), 'agent_3': Array([ 0.5156973 ,  0.09612609, -0.09452945, -0.03057878,  0.9903984 ,\n",
            "        0.48348945,  0.3150104 ,  0.01509188,  0.26753366,  0.62781096,\n",
            "       -0.10528564, -0.22380352,  0.5554557 , -0.1543616 , -0.5751444 ,\n",
            "        1.9139736 , -1.8533382 ,  1.4998248 ], dtype=float32)}\n",
            "ctrl action chosen: [0.3214346  0.12490054 0.32382128 0.12386672 0.32253662 0.12173948\n",
            " 0.3223772  0.12359076]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.77501416, dtype=float32), 'agent_0': Array(0.77501416, dtype=float32), 'agent_1': Array(0.77501416, dtype=float32), 'agent_2': Array(0.77501416, dtype=float32), 'agent_3': Array(0.77501416, dtype=float32)}\n",
            "step: 353\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53494847,  0.11284289, -0.07668318, -0.03595474,  0.9899967 ,\n",
            "        0.5555552 ,  0.5932439 ,  0.41177353,  0.06654469,  0.34757876,\n",
            "       -0.06289482, -0.30977726,  0.18564463, -0.05750627, -0.7707484 ,\n",
            "       -0.49456182,  0.6394347 ,  1.0682603 ], dtype=float32), 'agent_1': Array([ 0.53494847,  0.11284289, -0.07668318, -0.03595474,  0.9899967 ,\n",
            "        0.5555552 ,  0.41177353, -1.0068552 ,  0.06654469,  0.34757876,\n",
            "       -0.06289482, -0.30977726,  0.18564463, -0.05750627, -0.7707484 ,\n",
            "       -0.49456182,  2.1519413 ,  2.1989033 ], dtype=float32), 'agent_2': Array([ 0.53494847,  0.11284289, -0.07668318, -0.03595474,  0.9899967 ,\n",
            "        0.5555552 ,  0.41177353,  0.06654469, -0.9168496 ,  0.34757876,\n",
            "       -0.06289482, -0.30977726,  0.18564463, -0.05750627, -0.7707484 ,\n",
            "       -0.49456182,  1.398937  ,  3.4914336 ], dtype=float32), 'agent_3': Array([ 0.53494847,  0.11284289, -0.07668318, -0.03595474,  0.9899967 ,\n",
            "        0.5555552 ,  0.41177353,  0.06654469,  0.34757876,  0.71973   ,\n",
            "       -0.06289482, -0.30977726,  0.18564463, -0.05750627, -0.7707484 ,\n",
            "       -0.49456182,  1.9736791 ,  2.1998029 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.06836572  2.1694841  -0.06683274  2.1712563  -0.0705406   2.1721559\n",
            " -0.06751928  2.1704094 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.640596, dtype=float32), 'agent_0': Array(0.640596, dtype=float32), 'agent_1': Array(0.640596, dtype=float32), 'agent_2': Array(0.640596, dtype=float32), 'agent_3': Array(0.640596, dtype=float32)}\n",
            "step: 354\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.541517  ,  0.09211431, -0.01152109, -0.02450208,  0.99538034,\n",
            "        0.5013216 ,  0.9040788 ,  0.43685797,  0.05020275,  0.3507981 ,\n",
            "       -0.41980743, -0.3321886 ,  0.28455257,  1.0022824 , -3.599165  ,\n",
            "        1.1880043 , -1.7749038 ,  7.5514455 ], dtype=float32), 'agent_1': Array([ 0.541517  ,  0.09211431, -0.01152109, -0.02450208,  0.99538034,\n",
            "        0.5013216 ,  0.43685797, -0.6092229 ,  0.05020275,  0.3507981 ,\n",
            "       -0.41980743, -0.3321886 ,  0.28455257,  1.0022824 , -3.599165  ,\n",
            "        1.1880043 ,  0.06828253, 10.796152  ], dtype=float32), 'agent_2': Array([ 0.541517  ,  0.09211431, -0.01152109, -0.02450208,  0.99538034,\n",
            "        0.5013216 ,  0.43685797,  0.05020275, -0.48946017,  0.3507981 ,\n",
            "       -0.41980743, -0.3321886 ,  0.28455257,  1.0022824 , -3.599165  ,\n",
            "        1.1880043 , -0.8534466 ,  9.52808   ], dtype=float32), 'agent_3': Array([ 0.541517  ,  0.09211431, -0.01152109, -0.02450208,  0.99538034,\n",
            "        0.5013216 ,  0.43685797,  0.05020275,  0.3507981 ,  1.0780252 ,\n",
            "       -0.41980743, -0.3321886 ,  0.28455257,  1.0022824 , -3.599165  ,\n",
            "        1.1880043 , -0.8259729 ,  8.628672  ], dtype=float32)}\n",
            "ctrl action chosen: [1.1556622  0.93151885 1.1555964  0.93333596 1.1545699  0.9324812\n",
            " 1.1559112  0.93334305]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.692594, dtype=float32), 'agent_0': Array(-8.692594, dtype=float32), 'agent_1': Array(-8.692594, dtype=float32), 'agent_2': Array(-8.692594, dtype=float32), 'agent_3': Array(-8.692594, dtype=float32)}\n",
            "step: 355\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56633466,  0.14204137,  0.03060893, -0.01242281,  0.9893093 ,\n",
            "        0.57852894,  1.2448984 ,  0.5811105 ,  0.30497444,  0.5439136 ,\n",
            "        0.43940544, -0.8163214 ,  1.0911226 ,  1.3664078 , -0.03435445,\n",
            "       -0.30371583, -0.2363347 ,  5.113927  ], dtype=float32), 'agent_1': Array([ 0.56633466,  0.14204137,  0.03060893, -0.01242281,  0.9893093 ,\n",
            "        0.57852894,  0.5811105 , -0.4577973 ,  0.30497444,  0.5439136 ,\n",
            "        0.43940544, -0.8163214 ,  1.0911226 ,  1.3664078 , -0.03435445,\n",
            "       -0.30371583,  0.03285073, -1.347943  ], dtype=float32), 'agent_2': Array([ 0.56633466,  0.14204137,  0.03060893, -0.01242281,  0.9893093 ,\n",
            "        0.57852894,  0.5811105 ,  0.30497444, -0.45672292,  0.5439136 ,\n",
            "        0.43940544, -0.8163214 ,  1.0911226 ,  1.3664078 , -0.03435445,\n",
            "       -0.30371583,  4.594963  , -0.44765893], dtype=float32), 'agent_3': Array([ 0.56633466,  0.14204137,  0.03060893, -0.01242281,  0.9893093 ,\n",
            "        0.57852894,  0.5811105 ,  0.30497444,  0.5439136 ,  1.2699988 ,\n",
            "        0.43940544, -0.8163214 ,  1.0911226 ,  1.3664078 , -0.03435445,\n",
            "       -0.30371583,  1.8035536 , -1.5031257 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.4500072  1.3426725 -1.4433788  1.3480074 -1.4438355  1.3531964\n",
            " -1.4459276  1.3504977]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.4126778, dtype=float32), 'agent_0': Array(-3.4126778, dtype=float32), 'agent_1': Array(-3.4126778, dtype=float32), 'agent_2': Array(-3.4126778, dtype=float32), 'agent_3': Array(-3.4126778, dtype=float32)}\n",
            "step: 356\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2718177e-01, -9.3372993e-02,  5.1163942e-02, -1.2285725e-02,\n",
            "        9.9423981e-01, -4.6622168e-02,  1.2932743e+00, -1.4052896e-02,\n",
            "       -9.8919705e-02,  5.9204835e-02,  3.1051636e-01, -4.5835972e-01,\n",
            "        7.7697039e-01, -7.2597995e-02, -7.4856955e-01,  1.3236574e+01,\n",
            "       -1.7728586e+01, -1.9204723e-02], dtype=float32), 'agent_1': Array([ 6.2718177e-01, -9.3372993e-02,  5.1163942e-02, -1.2285725e-02,\n",
            "        9.9423981e-01, -4.6622168e-02, -1.4052896e-02, -4.8795027e-01,\n",
            "       -9.8919705e-02,  5.9204835e-02,  3.1051636e-01, -4.5835972e-01,\n",
            "        7.7697039e-01, -7.2597995e-02, -7.4856955e-01,  1.3236574e+01,\n",
            "       -1.7319382e+01, -6.6130418e-01], dtype=float32), 'agent_2': Array([ 6.2718177e-01, -9.3372993e-02,  5.1163942e-02, -1.2285725e-02,\n",
            "        9.9423981e-01, -4.6622168e-02, -1.4052896e-02, -9.8919705e-02,\n",
            "       -5.0572836e-01,  5.9204835e-02,  3.1051636e-01, -4.5835972e-01,\n",
            "        7.7697039e-01, -7.2597995e-02, -7.4856955e-01,  1.3236574e+01,\n",
            "       -1.2822048e+01, -1.0307643e+00], dtype=float32), 'agent_3': Array([ 6.2718177e-01, -9.3372993e-02,  5.1163942e-02, -1.2285725e-02,\n",
            "        9.9423981e-01, -4.6622168e-02, -1.4052896e-02, -9.8919705e-02,\n",
            "        5.9204835e-02,  1.2787442e+00,  3.1051636e-01, -4.5835972e-01,\n",
            "        7.7697039e-01, -7.2597995e-02, -7.4856955e-01,  1.3236574e+01,\n",
            "       -1.4431136e+01, -3.2644832e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.5412711  -0.21962225 -0.54019755 -0.21718723 -0.54401815 -0.21149653\n",
            " -0.5429529  -0.21082076]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.4836054, dtype=float32), 'agent_0': Array(-6.4836054, dtype=float32), 'agent_1': Array(-6.4836054, dtype=float32), 'agent_2': Array(-6.4836054, dtype=float32), 'agent_3': Array(-6.4836054, dtype=float32)}\n",
            "step: 357\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63505936, -0.31095955,  0.04485753, -0.01687525,  0.94921404,\n",
            "       -0.6117395 ,  1.1579628 , -0.58577794, -0.51858425, -0.4371805 ,\n",
            "        0.1914978 , -0.50246716, -0.1429677 ,  0.3585356 , -0.06353737,\n",
            "        1.4730018 ,  0.24143052, -3.6267443 ], dtype=float32), 'agent_1': Array([ 0.63505936, -0.31095955,  0.04485753, -0.01687525,  0.94921404,\n",
            "       -0.6117395 , -0.58577794, -0.663401  , -0.51858425, -0.4371805 ,\n",
            "        0.1914978 , -0.50246716, -0.1429677 ,  0.3585356 , -0.06353737,\n",
            "        1.4730018 , -1.04878   , -3.932778  ], dtype=float32), 'agent_2': Array([ 0.63505936, -0.31095955,  0.04485753, -0.01687525,  0.94921404,\n",
            "       -0.6117395 , -0.58577794, -0.51858425, -0.7159011 , -0.4371805 ,\n",
            "        0.1914978 , -0.50246716, -0.1429677 ,  0.3585356 , -0.06353737,\n",
            "        1.4730018 , -0.6752856 , -3.9614966 ], dtype=float32), 'agent_3': Array([ 0.63505936, -0.31095955,  0.04485753, -0.01687525,  0.94921404,\n",
            "       -0.6117395 , -0.58577794, -0.51858425, -0.4371805 ,  1.1101663 ,\n",
            "        0.1914978 , -0.50246716, -0.1429677 ,  0.3585356 , -0.06353737,\n",
            "        1.4730018 , -2.5550644 , -4.602333  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9808199   1.3101101  -0.98349184  1.3108131  -0.9831098   1.3108284\n",
            " -0.9816771   1.3116981 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.69844764, dtype=float32), 'agent_0': Array(0.69844764, dtype=float32), 'agent_1': Array(0.69844764, dtype=float32), 'agent_2': Array(0.69844764, dtype=float32), 'agent_3': Array(0.69844764, dtype=float32)}\n",
            "step: 358\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.62504065, -0.3300904 ,  0.09543188, -0.01944063,  0.93891174,\n",
            "       -0.53115594,  1.2597988 , -0.5453749 , -0.54174674, -0.5631735 ,\n",
            "       -0.5981922 , -0.65796375, -0.39337873, -1.2386708 , -2.7356143 ,\n",
            "        0.45973828,  2.3408196 ,  2.6474297 ], dtype=float32), 'agent_1': Array([ 0.62504065, -0.3300904 ,  0.09543188, -0.01944063,  0.93891174,\n",
            "       -0.53115594, -0.5453749 , -0.5051009 , -0.54174674, -0.5631735 ,\n",
            "       -0.5981922 , -0.65796375, -0.39337873, -1.2386708 , -2.7356143 ,\n",
            "        0.45973828,  1.7246889 ,  5.466545  ], dtype=float32), 'agent_2': Array([ 0.62504065, -0.3300904 ,  0.09543188, -0.01944063,  0.93891174,\n",
            "       -0.53115594, -0.5453749 , -0.54174674, -0.5064409 , -0.5631735 ,\n",
            "       -0.5981922 , -0.65796375, -0.39337873, -1.2386708 , -2.7356143 ,\n",
            "        0.45973828, -0.60186875,  6.453675  ], dtype=float32), 'agent_3': Array([ 0.62504065, -0.3300904 ,  0.09543188, -0.01944063,  0.93891174,\n",
            "       -0.53115594, -0.5453749 , -0.54174674, -0.5631735 ,  1.2287977 ,\n",
            "       -0.5981922 , -0.65796375, -0.39337873, -1.2386708 , -2.7356143 ,\n",
            "        0.45973828, -1.7646048 ,  5.7201552 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9498512   0.27991128 -0.95443004  0.279413   -0.95553637  0.27191418\n",
            " -0.95252514  0.2719008 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.743314, dtype=float32), 'agent_0': Array(-4.743314, dtype=float32), 'agent_1': Array(-4.743314, dtype=float32), 'agent_2': Array(-4.743314, dtype=float32), 'agent_3': Array(-4.743314, dtype=float32)}\n",
            "step: 359\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58586353, -0.34798232,  0.11711268, -0.01836318,  0.9299762 ,\n",
            "       -0.5083812 ,  1.2392812 , -0.52997744, -0.5630532 , -0.5897119 ,\n",
            "        0.16908646, -0.46875477, -1.0083079 , -0.3357624 , -1.0075903 ,\n",
            "        1.0370818 , -1.5075483 , -0.00311632], dtype=float32), 'agent_1': Array([ 0.58586353, -0.34798232,  0.11711268, -0.01836318,  0.9299762 ,\n",
            "       -0.5083812 , -0.52997744, -0.4996655 , -0.5630532 , -0.5897119 ,\n",
            "        0.16908646, -0.46875477, -1.0083079 , -0.3357624 , -1.0075903 ,\n",
            "        1.0370818 , -0.73189306,  0.17818707], dtype=float32), 'agent_2': Array([ 0.58586353, -0.34798232,  0.11711268, -0.01836318,  0.9299762 ,\n",
            "       -0.5083812 , -0.52997744, -0.5630532 , -0.5007853 , -0.5897119 ,\n",
            "        0.16908646, -0.46875477, -1.0083079 , -0.3357624 , -1.0075903 ,\n",
            "        1.0370818 , -0.12813881,  0.42099896], dtype=float32), 'agent_3': Array([ 0.58586353, -0.34798232,  0.11711268, -0.01836318,  0.9299762 ,\n",
            "       -0.5083812 , -0.52997744, -0.5630532 , -0.5897119 ,  1.2441053 ,\n",
            "        0.16908646, -0.46875477, -1.0083079 , -0.3357624 , -1.0075903 ,\n",
            "        1.0370818 ,  0.9331877 ,  0.03436822], dtype=float32)}\n",
            "ctrl action chosen: [1.0333736  0.15032417 1.0323442  0.15390296 1.0331222  0.15576257\n",
            " 1.0336145  0.1599649 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0445012, dtype=float32), 'agent_0': Array(-1.0445012, dtype=float32), 'agent_1': Array(-1.0445012, dtype=float32), 'agent_2': Array(-1.0445012, dtype=float32), 'agent_3': Array(-1.0445012, dtype=float32)}\n",
            "step: 360\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2984256e-01, -1.3778478e-01,  1.4059526e-01,  1.8391946e-02,\n",
            "        9.8026025e-01,  1.4040970e-02,  1.2287475e+00,  2.7400224e-02,\n",
            "        2.8230099e-02,  6.3358940e-02,  6.9236755e-02, -2.2008419e-01,\n",
            "       -8.5092783e-01,  5.3963417e-01, -7.0187634e-01, -1.2071567e+01,\n",
            "        1.4286425e+01, -3.3284378e-01], dtype=float32), 'agent_1': Array([ 5.2984256e-01, -1.3778478e-01,  1.4059526e-01,  1.8391946e-02,\n",
            "        9.8026025e-01,  1.4040970e-02,  2.7400224e-02, -5.0709885e-01,\n",
            "        2.8230099e-02,  6.3358940e-02,  6.9236755e-02, -2.2008419e-01,\n",
            "       -8.5092783e-01,  5.3963417e-01, -7.0187634e-01, -1.2071567e+01,\n",
            "        1.5357626e+01,  4.3310538e-01], dtype=float32), 'agent_2': Array([ 5.2984256e-01, -1.3778478e-01,  1.4059526e-01,  1.8391946e-02,\n",
            "        9.8026025e-01,  1.4040970e-02,  2.7400224e-02,  2.8230099e-02,\n",
            "       -5.0981569e-01,  6.3358940e-02,  6.9236755e-02, -2.2008419e-01,\n",
            "       -8.5092783e-01,  5.3963417e-01, -7.0187634e-01, -1.2071567e+01,\n",
            "        1.6239290e+01,  9.6049309e-01], dtype=float32), 'agent_3': Array([ 5.2984256e-01, -1.3778478e-01,  1.4059526e-01,  1.8391946e-02,\n",
            "        9.8026025e-01,  1.4040970e-02,  2.7400224e-02,  2.8230099e-02,\n",
            "        6.3358940e-02,  1.2293897e+00,  6.9236755e-02, -2.2008419e-01,\n",
            "       -8.5092783e-01,  5.3963417e-01, -7.0187634e-01, -1.2071567e+01,\n",
            "        1.7681519e+01, -3.8093725e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.38283417 -0.25188634  0.3828362  -0.24839611  0.38460732 -0.24519548\n",
            "  0.3871842  -0.24769136]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0475891, dtype=float32), 'agent_0': Array(-1.0475891, dtype=float32), 'agent_1': Array(-1.0475891, dtype=float32), 'agent_2': Array(-1.0475891, dtype=float32), 'agent_3': Array(-1.0475891, dtype=float32)}\n",
            "step: 361\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5332376 ,  0.02982238,  0.11180577,  0.03912833,  0.9925116 ,\n",
            "        0.4600143 ,  1.0655284 ,  0.52634454,  0.5542104 ,  0.59589195,\n",
            "        0.0474453 ,  0.17955303, -0.01188517, -0.61804986,  1.210461  ,\n",
            "       -1.5717518 ,  3.5491304 , -4.698808  ], dtype=float32), 'agent_1': Array([ 0.5332376 ,  0.02982238,  0.11180577,  0.03912833,  0.9925116 ,\n",
            "        0.4600143 ,  0.52634454, -0.54852426,  0.5542104 ,  0.59589195,\n",
            "        0.0474453 ,  0.17955303, -0.01188517, -0.61804986,  1.210461  ,\n",
            "       -1.5717518 ,  4.1008177 , -1.0399189 ], dtype=float32), 'agent_2': Array([ 0.5332376 ,  0.02982238,  0.11180577,  0.03912833,  0.9925116 ,\n",
            "        0.4600143 ,  0.52634454,  0.5542104 , -0.5554743 ,  0.59589195,\n",
            "        0.0474453 ,  0.17955303, -0.01188517, -0.61804986,  1.210461  ,\n",
            "       -1.5717518 ,  3.62079   , -1.663219  ], dtype=float32), 'agent_3': Array([ 0.5332376 ,  0.02982238,  0.11180577,  0.03912833,  0.9925116 ,\n",
            "        0.4600143 ,  0.52634454,  0.5542104 ,  0.59589195,  1.069073  ,\n",
            "        0.0474453 ,  0.17955303, -0.01188517, -0.61804986,  1.210461  ,\n",
            "       -1.5717518 ,  2.241016  , -4.4361978 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.96281683 -0.89407307 -0.9672414  -0.89099073 -0.96704906 -0.88992006\n",
            " -0.96424675 -0.893057  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.580395, dtype=float32), 'agent_0': Array(0.580395, dtype=float32), 'agent_1': Array(0.580395, dtype=float32), 'agent_2': Array(0.580395, dtype=float32), 'agent_3': Array(0.580395, dtype=float32)}\n",
            "step: 362\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3566521e-01, -1.9124982e-01,  5.0222728e-02, -2.8880201e-03,\n",
            "        9.8025143e-01, -4.0450979e-02,  6.4564258e-01,  4.8003953e-02,\n",
            "        9.8845109e-02,  1.0352777e-01,  3.0384064e-01, -1.7976761e-02,\n",
            "        1.6127825e-01, -2.2201701e-01,  3.7002022e+00,  1.2682874e+01,\n",
            "       -1.4779356e+01, -1.0398787e+01], dtype=float32), 'agent_1': Array([ 5.3566521e-01, -1.9124982e-01,  5.0222728e-02, -2.8880201e-03,\n",
            "        9.8025143e-01, -4.0450979e-02,  4.8003953e-02, -8.1064540e-01,\n",
            "        9.8845109e-02,  1.0352777e-01,  3.0384064e-01, -1.7976761e-02,\n",
            "        1.6127825e-01, -2.2201701e-01,  3.7002022e+00,  1.2682874e+01,\n",
            "       -1.4953410e+01, -7.0141993e+00], dtype=float32), 'agent_2': Array([ 5.3566521e-01, -1.9124982e-01,  5.0222728e-02, -2.8880201e-03,\n",
            "        9.8025143e-01, -4.0450979e-02,  4.8003953e-02,  9.8845109e-02,\n",
            "       -8.7327075e-01,  1.0352777e-01,  3.0384064e-01, -1.7976761e-02,\n",
            "        1.6127825e-01, -2.2201701e-01,  3.7002022e+00,  1.2682874e+01,\n",
            "       -1.3948683e+01, -8.5180683e+00], dtype=float32), 'agent_3': Array([ 5.3566521e-01, -1.9124982e-01,  5.0222728e-02, -2.8880201e-03,\n",
            "        9.8025143e-01, -4.0450979e-02,  4.8003953e-02,  9.8845109e-02,\n",
            "        1.0352777e-01,  6.8136454e-01,  3.0384064e-01, -1.7976761e-02,\n",
            "        1.6127825e-01, -2.2201701e-01,  3.7002022e+00,  1.2682874e+01,\n",
            "       -1.5214589e+01, -9.5561562e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5035233  -0.5786036   0.50331426 -0.5729798   0.50181645 -0.5753923\n",
            "  0.5037031  -0.57477605]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2626014, dtype=float32), 'agent_0': Array(-2.2626014, dtype=float32), 'agent_1': Array(-2.2626014, dtype=float32), 'agent_2': Array(-2.2626014, dtype=float32), 'agent_3': Array(-2.2626014, dtype=float32)}\n",
            "step: 363\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4912764e-01, -2.0461354e-01, -1.8415408e-02, -4.8284256e-03,\n",
            "        9.7865772e-01, -2.5494369e-02,  4.6651009e-01, -1.9055227e-02,\n",
            "        1.3491906e-01,  7.3149458e-02,  8.8453293e-02, -1.5554428e-01,\n",
            "        5.9914589e-01,  4.4474930e-01,  1.4728210e+00, -3.1367481e+00,\n",
            "        5.4133005e+00,  1.1540790e+00], dtype=float32), 'agent_1': Array([ 5.4912764e-01, -2.0461354e-01, -1.8415408e-02, -4.8284256e-03,\n",
            "        9.7865772e-01, -2.5494369e-02, -1.9055227e-02, -1.1142329e+00,\n",
            "        1.3491906e-01,  7.3149458e-02,  8.8453293e-02, -1.5554428e-01,\n",
            "        5.9914589e-01,  4.4474930e-01,  1.4728210e+00, -3.1367481e+00,\n",
            "        2.8744702e+00, -5.5699544e+00], dtype=float32), 'agent_2': Array([ 5.4912764e-01, -2.0461354e-01, -1.8415408e-02, -4.8284256e-03,\n",
            "        9.7865772e-01, -2.5494369e-02, -1.9055227e-02,  1.3491906e-01,\n",
            "       -1.2042745e+00,  7.3149458e-02,  8.8453293e-02, -1.5554428e-01,\n",
            "        5.9914589e-01,  4.4474930e-01,  1.4728210e+00, -3.1367481e+00,\n",
            "        5.6746302e+00, -4.5784335e+00], dtype=float32), 'agent_3': Array([ 0.54912764, -0.20461354, -0.01841541, -0.00482843,  0.9786577 ,\n",
            "       -0.02549437, -0.01905523,  0.13491906,  0.07314946,  0.4503773 ,\n",
            "        0.08845329, -0.15554428,  0.5991459 ,  0.4447493 ,  1.472821  ,\n",
            "       -3.136748  ,  4.288009  ,  0.9775955 ], dtype=float32)}\n",
            "ctrl action chosen: [0.9825525  0.3991753  0.98012    0.38718608 0.97953486 0.38840353\n",
            " 0.9805482  0.3994368 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.02072525, dtype=float32), 'agent_0': Array(0.02072525, dtype=float32), 'agent_1': Array(0.02072525, dtype=float32), 'agent_2': Array(0.02072525, dtype=float32), 'agent_3': Array(0.02072525, dtype=float32)}\n",
            "step: 364\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0662007e-01, -1.2074514e-02, -4.1829556e-02, -1.8025935e-02,\n",
            "        9.9888921e-01,  5.4905915e-01,  5.6494397e-01,  4.5321709e-01,\n",
            "        6.3811725e-01,  5.7817632e-01, -3.9043427e-01,  3.0994415e-03,\n",
            "        8.8722706e-01, -4.7110027e-01,  9.6454877e-01, -1.0394154e+00,\n",
            "        4.0314779e+00,  2.9362156e+00], dtype=float32), 'agent_1': Array([ 6.0662007e-01, -1.2074514e-02, -4.1829556e-02, -1.8025935e-02,\n",
            "        9.9888921e-01,  5.4905915e-01,  4.5321709e-01, -1.1381545e+00,\n",
            "        6.3811725e-01,  5.7817632e-01, -3.9043427e-01,  3.0994415e-03,\n",
            "        8.8722706e-01, -4.7110027e-01,  9.6454877e-01, -1.0394154e+00,\n",
            "        3.9477193e+00,  5.4626185e-02], dtype=float32), 'agent_2': Array([ 0.6066201 , -0.01207451, -0.04182956, -0.01802593,  0.9988892 ,\n",
            "        0.54905915,  0.4532171 ,  0.63811725, -1.1838665 ,  0.5781763 ,\n",
            "       -0.39043427,  0.00309944,  0.88722706, -0.47110027,  0.96454877,\n",
            "       -1.0394154 , -1.0354507 ,  0.8272137 ], dtype=float32), 'agent_3': Array([ 6.0662007e-01, -1.2074514e-02, -4.1829556e-02, -1.8025935e-02,\n",
            "        9.9888921e-01,  5.4905915e-01,  4.5321709e-01,  6.3811725e-01,\n",
            "        5.7817632e-01,  5.7540590e-01, -3.9043427e-01,  3.0994415e-03,\n",
            "        8.8722706e-01, -4.7110027e-01,  9.6454877e-01, -1.0394154e+00,\n",
            "        1.5569396e+00,  3.7047021e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.34606054  1.3206006  -0.347559    1.315578   -0.34769553  1.3152422\n",
            " -0.34990278  1.3171021 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3324118, dtype=float32), 'agent_0': Array(-1.3324118, dtype=float32), 'agent_1': Array(-1.3324118, dtype=float32), 'agent_2': Array(-1.3324118, dtype=float32), 'agent_3': Array(-1.3324118, dtype=float32)}\n",
            "step: 365\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1778468e-01, -9.3350723e-02, -2.7489807e-02,  1.3360876e-03,\n",
            "        9.9525285e-01,  4.7538289e-01,  1.0602114e+00,  3.4637183e-01,\n",
            "        3.6804527e-01,  4.0915531e-01, -7.5011253e-01, -3.7534237e-01,\n",
            "       -1.7679930e-01,  1.0559325e+00, -1.6376618e+00,  5.0759788e+00,\n",
            "       -3.6574736e+00,  1.2927776e+01], dtype=float32), 'agent_1': Array([ 6.1778468e-01, -9.3350723e-02, -2.7489807e-02,  1.3360876e-03,\n",
            "        9.9525285e-01,  4.7538289e-01,  3.4637183e-01, -9.0943712e-01,\n",
            "        3.6804527e-01,  4.0915531e-01, -7.5011253e-01, -3.7534237e-01,\n",
            "       -1.7679930e-01,  1.0559325e+00, -1.6376618e+00,  5.0759788e+00,\n",
            "       -4.3040056e+00,  8.3492069e+00], dtype=float32), 'agent_2': Array([ 6.1778468e-01, -9.3350723e-02, -2.7489807e-02,  1.3360876e-03,\n",
            "        9.9525285e-01,  4.7538289e-01,  3.4637183e-01,  3.6804527e-01,\n",
            "       -9.2550546e-01,  4.0915531e-01, -7.5011253e-01, -3.7534237e-01,\n",
            "       -1.7679930e-01,  1.0559325e+00, -1.6376618e+00,  5.0759788e+00,\n",
            "       -8.8972473e+00,  9.0292606e+00], dtype=float32), 'agent_3': Array([ 6.1778468e-01, -9.3350723e-02, -2.7489807e-02,  1.3360876e-03,\n",
            "        9.9525285e-01,  4.7538289e-01,  3.4637183e-01,  3.6804527e-01,\n",
            "        4.0915531e-01,  1.1130759e+00, -7.5011253e-01, -3.7534237e-01,\n",
            "       -1.7679930e-01,  1.0559325e+00, -1.6376618e+00,  5.0759788e+00,\n",
            "       -6.1408625e+00,  1.1954651e+01], dtype=float32)}\n",
            "ctrl action chosen: [0.34939033 1.0529958  0.35123137 1.0623995  0.35285312 1.0560311\n",
            " 0.3492672  1.0559939 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.2799861, dtype=float32), 'agent_0': Array(-3.2799861, dtype=float32), 'agent_1': Array(-3.2799861, dtype=float32), 'agent_2': Array(-3.2799861, dtype=float32), 'agent_3': Array(-3.2799861, dtype=float32)}\n",
            "step: 366\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.62461656, -0.10104287,  0.00740653,  0.01142252,  0.9947889 ,\n",
            "        0.5697484 ,  1.3143046 ,  0.40915218,  0.27505332,  0.3930511 ,\n",
            "       -0.5109787 ,  0.25408268, -0.12602806, -0.8008865 ,  0.13991824,\n",
            "       -0.8656328 ,  1.7406908 , -1.005534  ], dtype=float32), 'agent_1': Array([ 0.62461656, -0.10104287,  0.00740653,  0.01142252,  0.9947889 ,\n",
            "        0.5697484 ,  0.40915218, -0.42161602,  0.27505332,  0.3930511 ,\n",
            "       -0.5109787 ,  0.25408268, -0.12602806, -0.8008865 ,  0.13991824,\n",
            "       -0.8656328 ,  2.597843  ,  2.732083  ], dtype=float32), 'agent_2': Array([ 0.62461656, -0.10104287,  0.00740653,  0.01142252,  0.9947889 ,\n",
            "        0.5697484 ,  0.40915218,  0.27505332, -0.42664152,  0.3930511 ,\n",
            "       -0.5109787 ,  0.25408268, -0.12602806, -0.8008865 ,  0.13991824,\n",
            "       -0.8656328 ,  0.8043663 ,  2.123081  ], dtype=float32), 'agent_3': Array([ 0.62461656, -0.10104287,  0.00740653,  0.01142252,  0.9947889 ,\n",
            "        0.5697484 ,  0.40915218,  0.27505332,  0.3930511 ,  1.2984247 ,\n",
            "       -0.5109787 ,  0.25408268, -0.12602806, -0.8008865 ,  0.13991824,\n",
            "       -0.8656328 ,  1.4115499 , -0.87032866], dtype=float32)}\n",
            "ctrl action chosen: [-0.47911352  0.4408089  -0.48207518  0.4473063  -0.48376507  0.4450137\n",
            " -0.48006704  0.44353876]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3506787, dtype=float32), 'agent_0': Array(-2.3506787, dtype=float32), 'agent_1': Array(-2.3506787, dtype=float32), 'agent_2': Array(-2.3506787, dtype=float32), 'agent_3': Array(-2.3506787, dtype=float32)}\n",
            "step: 367\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.4364177e-01, -2.0090921e-01, -2.2072166e-02, -1.3037924e-02,\n",
            "        9.7927445e-01,  3.7024966e-01,  1.2300011e+00,  2.2757150e-01,\n",
            "        4.5515825e-03,  1.5391678e-01, -2.5124550e-01,  7.7917576e-01,\n",
            "        8.5340738e-01, -5.3078890e-01,  4.6886745e-01,  5.9468570e+00,\n",
            "       -7.0498185e+00, -1.2381163e+00], dtype=float32), 'agent_1': Array([ 6.4364177e-01, -2.0090921e-01, -2.2072166e-02, -1.3037924e-02,\n",
            "        9.7927445e-01,  3.7024966e-01,  2.2757150e-01, -4.8098469e-01,\n",
            "        4.5515825e-03,  1.5391678e-01, -2.5124550e-01,  7.7917576e-01,\n",
            "        8.5340738e-01, -5.3078890e-01,  4.6886745e-01,  5.9468570e+00,\n",
            "       -6.3318863e+00, -1.0447127e-01], dtype=float32), 'agent_2': Array([ 6.4364177e-01, -2.0090921e-01, -2.2072166e-02, -1.3037924e-02,\n",
            "        9.7927445e-01,  3.7024966e-01,  2.2757150e-01,  4.5515825e-03,\n",
            "       -4.8507202e-01,  1.5391678e-01, -2.5124550e-01,  7.7917576e-01,\n",
            "        8.5340738e-01, -5.3078890e-01,  4.6886745e-01,  5.9468570e+00,\n",
            "       -7.5724568e+00,  3.1504929e-01], dtype=float32), 'agent_3': Array([ 6.4364177e-01, -2.0090921e-01, -2.2072166e-02, -1.3037924e-02,\n",
            "        9.7927445e-01,  3.7024966e-01,  2.2757150e-01,  4.5515825e-03,\n",
            "        1.5391678e-01,  1.2171555e+00, -2.5124550e-01,  7.7917576e-01,\n",
            "        8.5340738e-01, -5.3078890e-01,  4.6886745e-01,  5.9468570e+00,\n",
            "       -6.8620534e+00, -7.0488226e-01], dtype=float32)}\n",
            "ctrl action chosen: [-1.0030943  1.2768675 -1.0035462  1.2799798 -1.0034599  1.2779628\n",
            " -1.0019435  1.2822807]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.03258073, dtype=float32), 'agent_0': Array(0.03258073, dtype=float32), 'agent_1': Array(0.03258073, dtype=float32), 'agent_2': Array(0.03258073, dtype=float32), 'agent_3': Array(0.03258073, dtype=float32)}\n",
            "step: 368\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6771894 ,  -0.46177107,  -0.03773973,  -0.02107718,\n",
            "         0.8859453 ,  -0.3098759 ,   1.2441351 ,  -0.42053327,\n",
            "        -0.6516095 ,  -0.52310365,  -0.07266998,   0.7311344 ,\n",
            "         0.4746914 ,   0.03211797,   1.0087525 ,   7.6671658 ,\n",
            "       -10.64986   ,   0.5300242 ], dtype=float32), 'agent_1': Array([  0.6771894 ,  -0.46177107,  -0.03773973,  -0.02107718,\n",
            "         0.8859453 ,  -0.3098759 ,  -0.42053327,  -0.50007397,\n",
            "        -0.6516095 ,  -0.52310365,  -0.07266998,   0.7311344 ,\n",
            "         0.4746914 ,   0.03211797,   1.0087525 ,   7.6671658 ,\n",
            "       -10.212902  ,  -0.7002602 ], dtype=float32), 'agent_2': Array([ 0.6771894 , -0.46177107, -0.03773973, -0.02107718,  0.8859453 ,\n",
            "       -0.3098759 , -0.42053327, -0.6516095 , -0.49062094, -0.52310365,\n",
            "       -0.07266998,  0.7311344 ,  0.4746914 ,  0.03211797,  1.0087525 ,\n",
            "        7.6671658 , -5.6593056 , -0.8241525 ], dtype=float32), 'agent_3': Array([  0.6771894 ,  -0.46177107,  -0.03773973,  -0.02107718,\n",
            "         0.8859453 ,  -0.3098759 ,  -0.42053327,  -0.6516095 ,\n",
            "        -0.52310365,   1.2553322 ,  -0.07266998,   0.7311344 ,\n",
            "         0.4746914 ,   0.03211797,   1.0087525 ,   7.6671658 ,\n",
            "       -10.327433  ,   0.22912918], dtype=float32)}\n",
            "ctrl action chosen: [1.1533643  0.9821998  1.1538239  0.9842624  1.1523181  0.99118644\n",
            " 1.1549996  0.9893535 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.556073, dtype=float32), 'agent_0': Array(-4.556073, dtype=float32), 'agent_1': Array(-4.556073, dtype=float32), 'agent_2': Array(-4.556073, dtype=float32), 'agent_3': Array(-4.556073, dtype=float32)}\n",
            "step: 369\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.68312824,  -0.3171398 ,  -0.04940926,  -0.04062991,\n",
            "         0.94621897,   0.03491842,   1.274066  ,  -0.04124597,\n",
            "        -0.1540975 ,  -0.17529869,   0.33006668,   0.3795147 ,\n",
            "         0.11003017,   0.01927873,   0.55906844, -10.477856  ,\n",
            "        12.513907  ,   0.23341689], dtype=float32), 'agent_1': Array([  0.68312824,  -0.3171398 ,  -0.04940926,  -0.04062991,\n",
            "         0.94621897,   0.03491842,  -0.04124597,  -0.4964367 ,\n",
            "        -0.1540975 ,  -0.17529869,   0.33006668,   0.3795147 ,\n",
            "         0.11003017,   0.01927873,   0.55906844, -10.477856  ,\n",
            "        13.209528  ,   0.5952062 ], dtype=float32), 'agent_2': Array([  0.68312824,  -0.3171398 ,  -0.04940926,  -0.04062991,\n",
            "         0.94621897,   0.03491842,  -0.04124597,  -0.1540975 ,\n",
            "        -0.4940785 ,  -0.17529869,   0.33006668,   0.3795147 ,\n",
            "         0.11003017,   0.01927873,   0.55906844, -10.477856  ,\n",
            "        16.377815  ,   0.5642667 ], dtype=float32), 'agent_3': Array([  0.68312824,  -0.3171398 ,  -0.04940926,  -0.04062991,\n",
            "         0.94621897,   0.03491842,  -0.04124597,  -0.1540975 ,\n",
            "        -0.17529869,   1.2746067 ,   0.33006668,   0.3795147 ,\n",
            "         0.11003017,   0.01927873,   0.55906844, -10.477856  ,\n",
            "        12.391607  ,  -0.04694643], dtype=float32)}\n",
            "ctrl action chosen: [ 0.14777808 -0.11944053  0.14760682 -0.11751138  0.1512477  -0.11705192\n",
            "  0.14745884 -0.1163803 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.4401608, dtype=float32), 'agent_0': Array(-3.4401608, dtype=float32), 'agent_1': Array(-3.4401608, dtype=float32), 'agent_2': Array(-3.4401608, dtype=float32), 'agent_3': Array(-3.4401608, dtype=float32)}\n",
            "step: 370\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.69406056, -0.17791462, -0.06926452, -0.04993935,  0.9803341 ,\n",
            "        0.41211587,  1.2079494 ,  0.31855938,  0.35325167,  0.17272721,\n",
            "        0.5923748 ,  0.76978207,  0.32721758,  0.24953641,  0.66298085,\n",
            "       -3.9010694 ,  5.546905  , -1.338747  ], dtype=float32), 'agent_1': Array([ 0.69406056, -0.17791462, -0.06926452, -0.04993935,  0.9803341 ,\n",
            "        0.41211587,  0.31855938, -0.54885536,  0.35325167,  0.17272721,\n",
            "        0.5923748 ,  0.76978207,  0.32721758,  0.24953641,  0.66298085,\n",
            "       -3.9010694 ,  4.711229  , -0.2820586 ], dtype=float32), 'agent_2': Array([ 0.69406056, -0.17791462, -0.06926452, -0.04993935,  0.9803341 ,\n",
            "        0.41211587,  0.31855938,  0.35325167, -0.51591974,  0.17272721,\n",
            "        0.5923748 ,  0.76978207,  0.32721758,  0.24953641,  0.66298085,\n",
            "       -3.9010694 ,  7.339928  ,  0.16807169], dtype=float32), 'agent_3': Array([ 0.69406056, -0.17791462, -0.06926452, -0.04993935,  0.9803341 ,\n",
            "        0.41211587,  0.31855938,  0.35325167,  0.17272721,  1.1706412 ,\n",
            "        0.5923748 ,  0.76978207,  0.32721758,  0.24953641,  0.66298085,\n",
            "       -3.9010694 ,  4.8803887 , -2.0835986 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.3682318  -0.3636238   1.3659286  -0.36063495  1.3706038  -0.3568969\n",
            "  1.3667245  -0.3628291 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.613961, dtype=float32), 'agent_0': Array(1.613961, dtype=float32), 'agent_1': Array(1.613961, dtype=float32), 'agent_2': Array(1.613961, dtype=float32), 'agent_3': Array(1.613961, dtype=float32)}\n",
            "step: 371\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.70564514, -0.0979204 , -0.09572791, -0.06984885,  0.9881138 ,\n",
            "        0.5681038 ,  0.98762846,  0.5562415 ,  0.60414934,  0.46543077,\n",
            "        0.53162575,  1.0022163 ,  0.04587173, -0.84649044,  1.6755921 ,\n",
            "        0.05936046, -0.7021187 , -5.3577805 ], dtype=float32), 'agent_1': Array([ 0.70564514, -0.0979204 , -0.09572791, -0.06984885,  0.9881138 ,\n",
            "        0.5681038 ,  0.5562415 , -0.66047597,  0.60414934,  0.46543077,\n",
            "        0.53162575,  1.0022163 ,  0.04587173, -0.84649044,  1.6755921 ,\n",
            "        0.05936046,  1.0210031 , -3.7484474 ], dtype=float32), 'agent_2': Array([ 0.70564514, -0.0979204 , -0.09572791, -0.06984885,  0.9881138 ,\n",
            "        0.5681038 ,  0.5562415 ,  0.60414934, -0.62819016,  0.46543077,\n",
            "        0.53162575,  1.0022163 ,  0.04587173, -0.84649044,  1.6755921 ,\n",
            "        0.05936046,  0.05512862, -4.1841264 ], dtype=float32), 'agent_3': Array([ 0.70564514, -0.0979204 , -0.09572791, -0.06984885,  0.9881138 ,\n",
            "        0.5681038 ,  0.5562415 ,  0.60414934,  0.46543077,  0.96678895,\n",
            "        0.53162575,  1.0022163 ,  0.04587173, -0.84649044,  1.6755921 ,\n",
            "        0.05936046,  3.6097867 , -4.7661467 ], dtype=float32)}\n",
            "ctrl action chosen: [0.34011132 0.00693299 0.3377432  0.00767674 0.33638677 0.00879209\n",
            " 0.34185877 0.0085886 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.4125524, dtype=float32), 'agent_0': Array(-2.4125524, dtype=float32), 'agent_1': Array(-2.4125524, dtype=float32), 'agent_2': Array(-2.4125524, dtype=float32), 'agent_3': Array(-2.4125524, dtype=float32)}\n",
            "step: 372\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.69081056, -0.12454382, -0.1269227 , -0.08464274,  0.9804159 ,\n",
            "        0.47371492,  0.8240195 ,  0.5259128 ,  0.4944264 ,  0.5610791 ,\n",
            "        0.30498505,  1.0124207 , -0.55851936, -0.4890321 ,  1.1057737 ,\n",
            "        1.3928914 , -1.8109268 , -2.7744255 ], dtype=float32), 'agent_1': Array([ 0.69081056, -0.12454382, -0.1269227 , -0.08464274,  0.9804159 ,\n",
            "        0.47371492,  0.5259128 , -0.78126854,  0.4944264 ,  0.5610791 ,\n",
            "        0.30498505,  1.0124207 , -0.55851936, -0.4890321 ,  1.1057737 ,\n",
            "        1.3928914 , -0.8832676 , -1.8196946 ], dtype=float32), 'agent_2': Array([ 0.69081056, -0.12454382, -0.1269227 , -0.08464274,  0.9804159 ,\n",
            "        0.47371492,  0.5259128 ,  0.4944264 , -0.78415316,  0.5610791 ,\n",
            "        0.30498505,  1.0124207 , -0.55851936, -0.4890321 ,  1.1057737 ,\n",
            "        1.3928914 , -2.5433378 , -2.5495682 ], dtype=float32), 'agent_3': Array([ 0.69081056, -0.12454382, -0.1269227 , -0.08464274,  0.9804159 ,\n",
            "        0.47371492,  0.5259128 ,  0.4944264 ,  0.5610791 ,  0.8152801 ,\n",
            "        0.30498505,  1.0124207 , -0.55851936, -0.4890321 ,  1.1057737 ,\n",
            "        1.3928914 ,  0.82844007, -2.6296134 ], dtype=float32)}\n",
            "ctrl action chosen: [0.919501   0.51959246 0.9179727  0.522199   0.92095506 0.5179313\n",
            " 0.9204371  0.52258474]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1230459, dtype=float32), 'agent_0': Array(1.1230459, dtype=float32), 'agent_1': Array(1.1230459, dtype=float32), 'agent_2': Array(1.1230459, dtype=float32), 'agent_3': Array(1.1230459, dtype=float32)}\n",
            "step: 373\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6547481 , -0.12305097, -0.12824747, -0.07922247,  0.9808848 ,\n",
            "        0.5451872 ,  0.8393895 ,  0.555091  ,  0.5252653 ,  0.5795497 ,\n",
            "        0.04410744,  0.4103899 , -0.6496072 ,  0.7190631 , -0.69020903,\n",
            "        0.4704291 ,  0.9793214 ,  1.6169451 ], dtype=float32), 'agent_1': Array([ 0.6547481 , -0.12305097, -0.12824747, -0.07922247,  0.9808848 ,\n",
            "        0.5451872 ,  0.555091  , -0.6927498 ,  0.5252653 ,  0.5795497 ,\n",
            "        0.04410744,  0.4103899 , -0.6496072 ,  0.7190631 , -0.69020903,\n",
            "        0.4704291 ,  0.09395109,  3.6175408 ], dtype=float32), 'agent_2': Array([ 0.6547481 , -0.12305097, -0.12824747, -0.07922247,  0.9808848 ,\n",
            "        0.5451872 ,  0.555091  ,  0.5252653 , -0.70835465,  0.5795497 ,\n",
            "        0.04410744,  0.4103899 , -0.6496072 ,  0.7190631 , -0.69020903,\n",
            "        0.4704291 ,  0.9602282 ,  3.7298203 ], dtype=float32), 'agent_3': Array([ 0.6547481 , -0.12305097, -0.12824747, -0.07922247,  0.9808848 ,\n",
            "        0.5451872 ,  0.555091  ,  0.5252653 ,  0.5795497 ,  0.85993564,\n",
            "        0.04410744,  0.4103899 , -0.6496072 ,  0.7190631 , -0.69020903,\n",
            "        0.4704291 , -1.4456711 ,  2.4566252 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.0849943  -0.76645565 -2.0860796  -0.7696436  -2.0884254  -0.76586884\n",
            " -2.0872965  -0.77365446]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0786808, dtype=float32), 'agent_0': Array(-1.0786808, dtype=float32), 'agent_1': Array(-1.0786808, dtype=float32), 'agent_2': Array(-1.0786808, dtype=float32), 'agent_3': Array(-1.0786808, dtype=float32)}\n",
            "step: 374\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.4646739e-01, -3.5713544e-01, -1.6191642e-01, -5.0552499e-02,\n",
            "        9.1852152e-01,  1.9474939e-02,  6.1089498e-01, -2.0895781e-02,\n",
            "        1.7950221e-04, -7.9323322e-02,  6.4988136e-01,  6.1306953e-01,\n",
            "        1.6660690e-01, -1.2931159e-01,  1.2914525e+00,  1.3233452e+01,\n",
            "       -1.5356055e+01, -6.6739593e+00], dtype=float32), 'agent_1': Array([ 6.4646739e-01, -3.5713544e-01, -1.6191642e-01, -5.0552499e-02,\n",
            "        9.1852152e-01,  1.9474939e-02, -2.0895781e-02, -8.2491922e-01,\n",
            "        1.7950221e-04, -7.9323322e-02,  6.4988136e-01,  6.1306953e-01,\n",
            "        1.6660690e-01, -1.2931159e-01,  1.2914525e+00,  1.3233452e+01,\n",
            "       -1.6004179e+01, -4.6579680e+00], dtype=float32), 'agent_2': Array([ 6.4646739e-01, -3.5713544e-01, -1.6191642e-01, -5.0552499e-02,\n",
            "        9.1852152e-01,  1.9474939e-02, -2.0895781e-02,  1.7950221e-04,\n",
            "       -8.4721434e-01, -7.9323322e-02,  6.4988136e-01,  6.1306953e-01,\n",
            "        1.6660690e-01, -1.2931159e-01,  1.2914525e+00,  1.3233452e+01,\n",
            "       -1.4574793e+01, -5.3588943e+00], dtype=float32), 'agent_3': Array([ 6.4646739e-01, -3.5713544e-01, -1.6191642e-01, -5.0552499e-02,\n",
            "        9.1852152e-01,  1.9474939e-02, -2.0895781e-02,  1.7950221e-04,\n",
            "       -7.9323322e-02,  6.8809009e-01,  6.4988136e-01,  6.1306953e-01,\n",
            "        1.6660690e-01, -1.2931159e-01,  1.2914525e+00,  1.3233452e+01,\n",
            "       -1.7807673e+01, -5.0241308e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.3048692 -0.6410454  1.3089695 -0.6403901  1.3047397 -0.6383663\n",
            "  1.3089807 -0.6406123]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.658516, dtype=float32), 'agent_0': Array(-8.658516, dtype=float32), 'agent_1': Array(-8.658516, dtype=float32), 'agent_2': Array(-8.658516, dtype=float32), 'agent_3': Array(-8.658516, dtype=float32)}\n",
            "step: 375\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63809043, -0.26667982, -0.18020867, -0.0704824 ,  0.9441604 ,\n",
            "        0.28096712,  0.47528446,  0.21147482,  0.30502576,  0.08560459,\n",
            "        0.7180214 ,  0.5321741 , -0.44510365,  0.30192864,  0.53271437,\n",
            "       -8.926741  , 12.257967  ,  0.34393546], dtype=float32), 'agent_1': Array([ 0.63809043, -0.26667982, -0.18020867, -0.0704824 ,  0.9441604 ,\n",
            "        0.28096712,  0.21147482, -1.1151175 ,  0.30502576,  0.08560459,\n",
            "        0.7180214 ,  0.5321741 , -0.44510365,  0.30192864,  0.53271437,\n",
            "       -8.926741  , 11.246066  , -7.3210645 ], dtype=float32), 'agent_2': Array([ 0.63809043, -0.26667982, -0.18020867, -0.0704824 ,  0.9441604 ,\n",
            "        0.28096712,  0.21147482,  0.30502576, -1.1489198 ,  0.08560459,\n",
            "        0.7180214 ,  0.5321741 , -0.44510365,  0.30192864,  0.53271437,\n",
            "       -8.926741  , 12.79862   , -6.471804  ], dtype=float32), 'agent_3': Array([ 0.63809043, -0.26667982, -0.18020867, -0.0704824 ,  0.9441604 ,\n",
            "        0.28096712,  0.21147482,  0.30502576,  0.08560459,  0.46287552,\n",
            "        0.7180214 ,  0.5321741 , -0.44510365,  0.30192864,  0.53271437,\n",
            "       -8.926741  , 10.29298   , -0.9074949 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.43116698 -0.01942223  0.4332461  -0.03974828  0.43333778 -0.03788033\n",
            "  0.42846453 -0.02233598]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.45081, dtype=float32), 'agent_0': Array(-2.45081, dtype=float32), 'agent_1': Array(-2.45081, dtype=float32), 'agent_2': Array(-2.45081, dtype=float32), 'agent_3': Array(-2.45081, dtype=float32)}\n",
            "step: 376\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.62252605, -0.166383  , -0.16431631, -0.08649687,  0.9684189 ,\n",
            "        0.575867  ,  0.51425374,  0.5306109 ,  0.58804995,  0.36589018,\n",
            "        0.39811134,  0.39167404, -0.35290718,  0.39001212, -0.5999134 ,\n",
            "        0.7185835 , -1.1773639 ,  1.0926741 ], dtype=float32), 'agent_1': Array([ 0.62252605, -0.166383  , -0.16431631, -0.08649687,  0.9684189 ,\n",
            "        0.575867  ,  0.5306109 , -1.2521522 ,  0.58804995,  0.36589018,\n",
            "        0.39811134,  0.39167404, -0.35290718,  0.39001212, -0.5999134 ,\n",
            "        0.7185835 ,  1.244575  ,  0.03695359], dtype=float32), 'agent_2': Array([ 0.62252605, -0.166383  , -0.16431631, -0.08649687,  0.9684189 ,\n",
            "        0.575867  ,  0.5306109 ,  0.58804995, -1.259866  ,  0.36589018,\n",
            "        0.39811134,  0.39167404, -0.35290718,  0.39001212, -0.5999134 ,\n",
            "        0.7185835 , -1.8389158 , -0.02899901], dtype=float32), 'agent_3': Array([ 0.62252605, -0.166383  , -0.16431631, -0.08649687,  0.9684189 ,\n",
            "        0.575867  ,  0.5306109 ,  0.58804995,  0.36589018,  0.51376027,\n",
            "        0.39811134,  0.39167404, -0.35290718,  0.39001212, -0.5999134 ,\n",
            "        0.7185835 ,  0.6705945 ,  0.7989406 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.26339418  0.76474833 -0.2581404   0.77022785 -0.26133165  0.76435894\n",
            " -0.26170582  0.76946115]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0951965, dtype=float32), 'agent_0': Array(1.0951965, dtype=float32), 'agent_1': Array(1.0951965, dtype=float32), 'agent_2': Array(1.0951965, dtype=float32), 'agent_3': Array(1.0951965, dtype=float32)}\n",
            "step: 377\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5997792 , -0.2477884 , -0.12897176, -0.04442545,  0.959163  ,\n",
            "        0.37941608,  0.8135621 ,  0.42429137,  0.32493418,  0.17678377,\n",
            "        0.08630753,  0.19433498,  0.3338337 ,  0.8250746 , -3.247398  ,\n",
            "        4.6570854 , -5.20486   ,  6.9048557 ], dtype=float32), 'agent_1': Array([ 0.5997792 , -0.2477884 , -0.12897176, -0.04442545,  0.959163  ,\n",
            "        0.37941608,  0.42429137, -1.121691  ,  0.32493418,  0.17678377,\n",
            "        0.08630753,  0.19433498,  0.3338337 ,  0.8250746 , -3.247398  ,\n",
            "        4.6570854 , -3.7244773 ,  5.6404433 ], dtype=float32), 'agent_2': Array([ 0.5997792 , -0.2477884 , -0.12897176, -0.04442545,  0.959163  ,\n",
            "        0.37941608,  0.42429137,  0.32493418, -1.108955  ,  0.17678377,\n",
            "        0.08630753,  0.19433498,  0.3338337 ,  0.8250746 , -3.247398  ,\n",
            "        4.6570854 , -7.4683175 ,  6.2722497 ], dtype=float32), 'agent_3': Array([ 0.5997792 , -0.2477884 , -0.12897176, -0.04442545,  0.959163  ,\n",
            "        0.37941608,  0.42429137,  0.32493418,  0.17678377,  0.7492045 ,\n",
            "        0.08630753,  0.19433498,  0.3338337 ,  0.8250746 , -3.247398  ,\n",
            "        4.6570854 , -6.2144985 ,  5.1664276 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8710353  -0.5211464  -0.86915046 -0.51717186 -0.8674165  -0.52070403\n",
            " -0.8685977  -0.51823705]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.04346371, dtype=float32), 'agent_0': Array(0.04346371, dtype=float32), 'agent_1': Array(0.04346371, dtype=float32), 'agent_2': Array(0.04346371, dtype=float32), 'agent_3': Array(0.04346371, dtype=float32)}\n",
            "step: 378\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0780823e-01, -4.7720340e-01, -9.7386785e-02, -6.4347154e-03,\n",
            "        8.7335634e-01, -1.9253302e-01,  8.1300169e-01, -1.1698473e-01,\n",
            "       -3.3470324e-01, -4.9688736e-01,  2.7656555e-01,  6.3912868e-01,\n",
            "        5.6982040e-03, -4.7819790e-01, -7.0119929e-01,  1.1423050e+01,\n",
            "       -1.3837961e+01, -2.2747111e+00], dtype=float32), 'agent_1': Array([ 6.0780823e-01, -4.7720340e-01, -9.7386785e-02, -6.4347154e-03,\n",
            "        8.7335634e-01, -1.9253302e-01, -1.1698473e-01, -1.0391318e+00,\n",
            "       -3.3470324e-01, -4.9688736e-01,  2.7656555e-01,  6.3912868e-01,\n",
            "        5.6982040e-03, -4.7819790e-01, -7.0119929e-01,  1.1423050e+01,\n",
            "       -1.3193987e+01, -4.4242799e-01], dtype=float32), 'agent_2': Array([ 6.0780823e-01, -4.7720340e-01, -9.7386785e-02, -6.4347154e-03,\n",
            "        8.7335634e-01, -1.9253302e-01, -1.1698473e-01, -3.3470324e-01,\n",
            "       -1.0100039e+00, -4.9688736e-01,  2.7656555e-01,  6.3912868e-01,\n",
            "        5.6982040e-03, -4.7819790e-01, -7.0119929e-01,  1.1423050e+01,\n",
            "       -1.4900593e+01, -4.0710765e-01], dtype=float32), 'agent_3': Array([ 6.0780823e-01, -4.7720340e-01, -9.7386785e-02, -6.4347154e-03,\n",
            "        8.7335634e-01, -1.9253302e-01, -1.1698473e-01, -3.3470324e-01,\n",
            "       -4.9688736e-01,  6.6614789e-01,  2.7656555e-01,  6.3912868e-01,\n",
            "        5.6982040e-03, -4.7819790e-01, -7.0119929e-01,  1.1423050e+01,\n",
            "       -1.5308317e+01, -3.4746153e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.7418411  -0.81649095  0.74042094 -0.8133409   0.74030983 -0.81507325\n",
            "  0.74464214 -0.81457186]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.83739233, dtype=float32), 'agent_0': Array(-0.83739233, dtype=float32), 'agent_1': Array(-0.83739233, dtype=float32), 'agent_2': Array(-0.83739233, dtype=float32), 'agent_3': Array(-0.83739233, dtype=float32)}\n",
            "step: 379\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5871552 , -0.42597407, -0.0919422 , -0.02253101,  0.8997695 ,\n",
            "       -0.05195192,  0.5574442 ,  0.0571748 , -0.2351988 , -0.37991437,\n",
            "        0.4488945 ,  0.9103298 , -0.7454872 , -0.9539376 ,  0.51873344,\n",
            "       -6.4089103 ,  8.255292  , -7.394424  ], dtype=float32), 'agent_1': Array([ 0.5871552 , -0.42597407, -0.0919422 , -0.02253101,  0.8997695 ,\n",
            "       -0.05195192,  0.0571748 , -1.2489928 , -0.2351988 , -0.37991437,\n",
            "        0.4488945 ,  0.9103298 , -0.7454872 , -0.9539376 ,  0.51873344,\n",
            "       -6.4089103 ,  8.620696  , -5.0869837 ], dtype=float32), 'agent_2': Array([ 0.5871552 , -0.42597407, -0.0919422 , -0.02253101,  0.8997695 ,\n",
            "       -0.05195192,  0.0571748 , -0.2351988 , -1.2331368 , -0.37991437,\n",
            "        0.4488945 ,  0.9103298 , -0.7454872 , -0.9539376 ,  0.51873344,\n",
            "       -6.4089103 ,  7.4678183 , -6.6214056 ], dtype=float32), 'agent_3': Array([ 0.5871552 , -0.42597407, -0.0919422 , -0.02253101,  0.8997695 ,\n",
            "       -0.05195192,  0.0571748 , -0.2351988 , -0.37991437,  0.47180167,\n",
            "        0.4488945 ,  0.9103298 , -0.7454872 , -0.9539376 ,  0.51873344,\n",
            "       -6.4089103 ,  7.8386855 , -0.8412785 ], dtype=float32)}\n",
            "ctrl action chosen: [0.03224079 0.49172637 0.0281017  0.4928081  0.02982912 0.49407896\n",
            " 0.02627824 0.5070572 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0318346, dtype=float32), 'agent_0': Array(-1.0318346, dtype=float32), 'agent_1': Array(-1.0318346, dtype=float32), 'agent_2': Array(-1.0318346, dtype=float32), 'agent_3': Array(-1.0318346, dtype=float32)}\n",
            "step: 380\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.548664  , -0.3448728 , -0.03869687, -0.03086201,  0.93734354,\n",
            "        0.18618768,  0.5219303 ,  0.3215549 , -0.03646628, -0.1573581 ,\n",
            "        0.25997162,  0.555706  , -0.8135319 , -0.20624949, -1.7903248 ,\n",
            "       -2.7999692 ,  3.4174697 ,  0.6579562 ], dtype=float32), 'agent_1': Array([ 0.548664  , -0.3448728 , -0.03869687, -0.03086201,  0.93734354,\n",
            "        0.18618768,  0.3215549 , -1.1675738 , -0.03646628, -0.1573581 ,\n",
            "        0.25997162,  0.555706  , -0.8135319 , -0.20624949, -1.7903248 ,\n",
            "       -2.7999692 ,  4.1863046 ,  2.2717083 ], dtype=float32), 'agent_2': Array([ 0.548664  , -0.3448728 , -0.03869687, -0.03086201,  0.93734354,\n",
            "        0.18618768,  0.3215549 , -0.03646628, -1.1989305 , -0.1573581 ,\n",
            "        0.25997162,  0.555706  , -0.8135319 , -0.20624949, -1.7903248 ,\n",
            "       -2.7999692 ,  2.585774  ,  1.6255387 ], dtype=float32), 'agent_3': Array([ 0.548664  , -0.3448728 , -0.03869687, -0.03086201,  0.93734354,\n",
            "        0.18618768,  0.3215549 , -0.03646628, -0.1573581 ,  0.56001395,\n",
            "        0.25997162,  0.555706  , -0.8135319 , -0.20624949, -1.7903248 ,\n",
            "       -2.7999692 ,  3.1125538 ,  1.502381  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8094322  -0.5507803  -0.8086573  -0.5486352  -0.80918825 -0.5469025\n",
            " -0.8090903  -0.54829496]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7221419, dtype=float32), 'agent_0': Array(0.7221419, dtype=float32), 'agent_1': Array(0.7221419, dtype=float32), 'agent_2': Array(0.7221419, dtype=float32), 'agent_3': Array(0.7221419, dtype=float32)}\n",
            "step: 381\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5474494 ,  -0.49440688,  -0.04203352,  -0.02532654,\n",
            "         0.8678443 ,  -0.21429004,   0.5010555 ,  -0.04461512,\n",
            "        -0.49450642,  -0.5732723 ,   0.1552105 ,   0.4146576 ,\n",
            "        -0.20745993,  -0.4373595 ,  -0.92655015,   8.270007  ,\n",
            "       -10.608835  ,   0.87983686], dtype=float32), 'agent_1': Array([ 0.5474494 , -0.49440688, -0.04203352, -0.02532654,  0.8678443 ,\n",
            "       -0.21429004, -0.04461512, -1.2473903 , -0.49450642, -0.5732723 ,\n",
            "        0.1552105 ,  0.4146576 , -0.20745993, -0.4373595 , -0.92655015,\n",
            "        8.270007  , -9.791105  ,  0.97996247], dtype=float32), 'agent_2': Array([  0.5474494 ,  -0.49440688,  -0.04203352,  -0.02532654,\n",
            "         0.8678443 ,  -0.21429004,  -0.04461512,  -0.49450642,\n",
            "        -1.2433275 ,  -0.5732723 ,   0.1552105 ,   0.4146576 ,\n",
            "        -0.20745993,  -0.4373595 ,  -0.92655015,   8.270007  ,\n",
            "       -11.64511   ,   0.81012446], dtype=float32), 'agent_3': Array([ 0.5474494 , -0.49440688, -0.04203352, -0.02532654,  0.8678443 ,\n",
            "       -0.21429004, -0.04461512, -0.49450642, -0.5732723 ,  0.50298053,\n",
            "        0.1552105 ,  0.4146576 , -0.20745993, -0.4373595 , -0.92655015,\n",
            "        8.270007  , -9.359037  ,  0.72345483], dtype=float32)}\n",
            "ctrl action chosen: [0.02684851 1.1795284  0.0275586  1.1808523  0.02818371 1.1788397\n",
            " 0.02778577 1.1828612 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6514425, dtype=float32), 'agent_0': Array(-0.6514425, dtype=float32), 'agent_1': Array(-0.6514425, dtype=float32), 'agent_2': Array(-0.6514425, dtype=float32), 'agent_3': Array(-0.6514425, dtype=float32)}\n",
            "step: 382\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5482361 , -0.4979798 ,  0.03870739, -0.01411075,  0.86620945,\n",
            "       -0.2824894 ,  0.89983904, -0.09205794, -0.54089206, -0.51965535,\n",
            "       -0.55794716,  0.09794235,  0.36278963, -1.2724422 , -3.5232036 ,\n",
            "       -0.65168864, -0.21691076, 10.910921  ], dtype=float32), 'agent_1': Array([ 0.5482361 , -0.4979798 ,  0.03870739, -0.01411075,  0.86620945,\n",
            "       -0.2824894 , -0.09205794, -0.8367848 , -0.54089206, -0.51965535,\n",
            "       -0.55794716,  0.09794235,  0.36278963, -1.2724422 , -3.5232036 ,\n",
            "       -0.65168864,  0.26901358, 10.266633  ], dtype=float32), 'agent_2': Array([ 0.5482361 , -0.4979798 ,  0.03870739, -0.01411075,  0.86620945,\n",
            "       -0.2824894 , -0.09205794, -0.54089206, -0.85086006, -0.51965535,\n",
            "       -0.55794716,  0.09794235,  0.36278963, -1.2724422 , -3.5232036 ,\n",
            "       -0.65168864,  0.68470603, 10.449035  ], dtype=float32), 'agent_3': Array([ 0.5482361 , -0.4979798 ,  0.03870739, -0.01411075,  0.86620945,\n",
            "       -0.2824894 , -0.09205794, -0.54089206, -0.51965535,  0.87990266,\n",
            "       -0.55794716,  0.09794235,  0.36278963, -1.2724422 , -3.5232036 ,\n",
            "       -0.65168864,  2.1018715 ,  9.968141  ], dtype=float32)}\n",
            "ctrl action chosen: [0.18838456 0.88765436 0.18865032 0.8931583  0.18824106 0.89469135\n",
            " 0.18933812 0.90111357]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9301577, dtype=float32), 'agent_0': Array(-1.9301577, dtype=float32), 'agent_1': Array(-1.9301577, dtype=float32), 'agent_2': Array(-1.9301577, dtype=float32), 'agent_3': Array(-1.9301577, dtype=float32)}\n",
            "step: 383\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5475779 , -0.43325487,  0.11627947,  0.00801999,  0.8937029 ,\n",
            "       -0.1377463 ,  1.3245064 ,  0.06530139, -0.3815002 , -0.2914757 ,\n",
            "       -0.55389404,  0.3960371 , -0.40102005, -0.3499503 , -0.608509  ,\n",
            "       -3.1737006 ,  3.8620713 ,  0.5097667 ], dtype=float32), 'agent_1': Array([ 0.5475779 , -0.43325487,  0.11627947,  0.00801999,  0.8937029 ,\n",
            "       -0.1377463 ,  0.06530139, -0.42486697, -0.3815002 , -0.2914757 ,\n",
            "       -0.55389404,  0.3960371 , -0.40102005, -0.3499503 , -0.608509  ,\n",
            "       -3.1737006 ,  3.2036834 ,  0.4414971 ], dtype=float32), 'agent_2': Array([ 0.5475779 , -0.43325487,  0.11627947,  0.00801999,  0.8937029 ,\n",
            "       -0.1377463 ,  0.06530139, -0.3815002 , -0.42980483, -0.2914757 ,\n",
            "       -0.55389404,  0.3960371 , -0.40102005, -0.3499503 , -0.608509  ,\n",
            "       -3.1737006 ,  3.8267825 ,  0.9384579 ], dtype=float32), 'agent_3': Array([ 0.5475779 , -0.43325487,  0.11627947,  0.00801999,  0.8937029 ,\n",
            "       -0.1377463 ,  0.06530139, -0.3815002 , -0.2914757 ,  1.3188173 ,\n",
            "       -0.55389404,  0.3960371 , -0.40102005, -0.3499503 , -0.608509  ,\n",
            "       -3.1737006 ,  4.124484  ,  2.1189756 ], dtype=float32)}\n",
            "ctrl action chosen: [0.12916349 0.04416214 0.12550601 0.04481322 0.12667568 0.04638963\n",
            " 0.1279218  0.05083396]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4063349, dtype=float32), 'agent_0': Array(-1.4063349, dtype=float32), 'agent_1': Array(-1.4063349, dtype=float32), 'agent_2': Array(-1.4063349, dtype=float32), 'agent_3': Array(-1.4063349, dtype=float32)}\n",
            "step: 384\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5347397 , -0.3857581 ,  0.09944125,  0.01103863,  0.9171588 ,\n",
            "       -0.01403477,  1.2368637 ,  0.16410258, -0.23904862, -0.11884984,\n",
            "       -0.28219223,  0.5737424 , -0.16822815,  0.19275738, -1.0671921 ,\n",
            "       -2.0907464 ,  2.2253177 , -0.13322297], dtype=float32), 'agent_1': Array([ 0.5347397 , -0.3857581 ,  0.09944125,  0.01103863,  0.9171588 ,\n",
            "       -0.01403477,  0.16410258, -0.5220236 , -0.23904862, -0.11884984,\n",
            "       -0.28219223,  0.5737424 , -0.16822815,  0.19275738, -1.0671921 ,\n",
            "       -2.0907464 ,  1.8605134 ,  0.14317307], dtype=float32), 'agent_2': Array([ 0.5347397 , -0.3857581 ,  0.09944125,  0.01103863,  0.9171588 ,\n",
            "       -0.01403477,  0.16410258, -0.23904862, -0.50624305, -0.11884984,\n",
            "       -0.28219223,  0.5737424 , -0.16822815,  0.19275738, -1.0671921 ,\n",
            "       -2.0907464 ,  2.921362  ,  0.35082948], dtype=float32), 'agent_3': Array([ 0.5347397 , -0.3857581 ,  0.09944125,  0.01103863,  0.9171588 ,\n",
            "       -0.01403477,  0.16410258, -0.23904862, -0.11884984,  1.2385335 ,\n",
            "       -0.28219223,  0.5737424 , -0.16822815,  0.19275738, -1.0671921 ,\n",
            "       -2.0907464 ,  3.5288377 , -0.26398104], dtype=float32)}\n",
            "ctrl action chosen: [ 0.31106916 -1.2758017   0.30792236 -1.274775    0.30918518 -1.2736889\n",
            "  0.30975366 -1.2741951 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7626721, dtype=float32), 'agent_0': Array(0.7626721, dtype=float32), 'agent_1': Array(0.7626721, dtype=float32), 'agent_2': Array(0.7626721, dtype=float32), 'agent_3': Array(0.7626721, dtype=float32)}\n",
            "step: 385\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3945071e-01, -2.9279870e-01,  4.6707764e-02,  3.9984090e-03,\n",
            "        9.5502424e-01,  2.1377851e-01,  8.4794647e-01,  3.5691753e-01,\n",
            "        2.0194573e-02,  1.5826893e-01,  5.2142143e-01,  1.2584209e+00,\n",
            "        6.5793991e-01, -4.7941482e-01,  4.4710021e+00, -4.4283552e+00,\n",
            "        5.5124822e+00, -1.2250439e+01], dtype=float32), 'agent_1': Array([ 5.3945071e-01, -2.9279870e-01,  4.6707764e-02,  3.9984090e-03,\n",
            "        9.5502424e-01,  2.1377851e-01,  3.5691753e-01, -7.6765138e-01,\n",
            "        2.0194573e-02,  1.5826893e-01,  5.2142143e-01,  1.2584209e+00,\n",
            "        6.5793991e-01, -4.7941482e-01,  4.4710021e+00, -4.4283552e+00,\n",
            "        4.0793276e+00, -7.1560030e+00], dtype=float32), 'agent_2': Array([ 5.3945071e-01, -2.9279870e-01,  4.6707764e-02,  3.9984090e-03,\n",
            "        9.5502424e-01,  2.1377851e-01,  3.5691753e-01,  2.0194573e-02,\n",
            "       -8.0174834e-01,  1.5826893e-01,  5.2142143e-01,  1.2584209e+00,\n",
            "        6.5793991e-01, -4.7941482e-01,  4.4710021e+00, -4.4283552e+00,\n",
            "        6.2136960e+00, -8.9999113e+00], dtype=float32), 'agent_3': Array([ 5.3945071e-01, -2.9279870e-01,  4.6707764e-02,  3.9984090e-03,\n",
            "        9.5502424e-01,  2.1377851e-01,  3.5691753e-01,  2.0194573e-02,\n",
            "        1.5826893e-01,  8.8133448e-01,  5.2142143e-01,  1.2584209e+00,\n",
            "        6.5793991e-01, -4.7941482e-01,  4.4710021e+00, -4.4283552e+00,\n",
            "        5.5777426e+00, -1.1976177e+01], dtype=float32)}\n",
            "ctrl action chosen: [0.87833303 0.31537506 0.86937565 0.3214194  0.8723568  0.31958967\n",
            " 0.8778903  0.31556275]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3400278, dtype=float32), 'agent_0': Array(-2.3400278, dtype=float32), 'agent_1': Array(-2.3400278, dtype=float32), 'agent_2': Array(-2.3400278, dtype=float32), 'agent_3': Array(-2.3400278, dtype=float32)}\n",
            "step: 386\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5522534 , -0.14775416, -0.00477686, -0.01939003,  0.9888225 ,\n",
            "        0.58954394,  0.53092873,  0.5832149 ,  0.4937551 ,  0.55116725,\n",
            "        0.35185814,  1.2302876 ,  0.09124279, -0.44500652,  1.3676057 ,\n",
            "       -0.98197913,  0.59335274, -3.6042342 ], dtype=float32), 'agent_1': Array([ 0.5522534 , -0.14775416, -0.00477686, -0.01939003,  0.9888225 ,\n",
            "        0.58954394,  0.5832149 , -0.8379599 ,  0.4937551 ,  0.55116725,\n",
            "        0.35185814,  1.2302876 ,  0.09124279, -0.44500652,  1.3676057 ,\n",
            "       -0.98197913, -2.033368  ,  0.2517377 ], dtype=float32), 'agent_2': Array([ 5.5225343e-01, -1.4775416e-01, -4.7768559e-03, -1.9390034e-02,\n",
            "        9.8882252e-01,  5.8954394e-01,  5.8321488e-01,  4.9375510e-01,\n",
            "       -9.8403704e-01,  5.5116725e-01,  3.5185814e-01,  1.2302876e+00,\n",
            "        9.1242790e-02, -4.4500652e-01,  1.3676057e+00, -9.8197913e-01,\n",
            "        5.2621288e+00, -9.1553086e-01], dtype=float32), 'agent_3': Array([ 0.5522534 , -0.14775416, -0.00477686, -0.01939003,  0.9888225 ,\n",
            "        0.58954394,  0.5832149 ,  0.4937551 ,  0.55116725,  0.5520104 ,\n",
            "        0.35185814,  1.2302876 ,  0.09124279, -0.44500652,  1.3676057 ,\n",
            "       -0.98197913,  2.0579643 , -3.825221  ], dtype=float32)}\n",
            "ctrl action chosen: [0.00435592 1.5941842  0.00418732 1.5957754  0.00685946 1.6025221\n",
            " 0.00586592 1.5934553 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.40983653, dtype=float32), 'agent_0': Array(-0.40983653, dtype=float32), 'agent_1': Array(-0.40983653, dtype=float32), 'agent_2': Array(-0.40983653, dtype=float32), 'agent_3': Array(-0.40983653, dtype=float32)}\n",
            "step: 387\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5041701e-01, -1.8076922e-01, -6.5723336e-03, -6.9442783e-03,\n",
            "        9.8347902e-01,  4.7865260e-01,  6.7810202e-01,  3.7777629e-01,\n",
            "        5.4064059e-01,  5.0736636e-01,  2.5777817e-01,  9.2037916e-01,\n",
            "       -2.3876429e-01,  9.9068618e-01, -1.0033627e+00,  2.2373567e+00,\n",
            "       -3.5492637e+00,  6.7192016e+00], dtype=float32), 'agent_1': Array([ 5.5041701e-01, -1.8076922e-01, -6.5723336e-03, -6.9442783e-03,\n",
            "        9.8347902e-01,  4.7865260e-01,  3.7777629e-01, -5.7616460e-01,\n",
            "        5.4064059e-01,  5.0736636e-01,  2.5777817e-01,  9.2037916e-01,\n",
            "       -2.3876429e-01,  9.9068618e-01, -1.0033627e+00,  2.2373567e+00,\n",
            "       -5.5025339e+00,  8.1720381e+00], dtype=float32), 'agent_2': Array([ 5.5041701e-01, -1.8076922e-01, -6.5723336e-03, -6.9442783e-03,\n",
            "        9.8347902e-01,  4.7865260e-01,  3.7777629e-01,  5.4064059e-01,\n",
            "       -7.4400443e-01,  5.0736636e-01,  2.5777817e-01,  9.2037916e-01,\n",
            "       -2.3876429e-01,  9.9068618e-01, -1.0033627e+00,  2.2373567e+00,\n",
            "       -7.6070255e-01,  7.9002495e+00], dtype=float32), 'agent_3': Array([ 5.5041701e-01, -1.8076922e-01, -6.5723336e-03, -6.9442783e-03,\n",
            "        9.8347902e-01,  4.7865260e-01,  3.7777629e-01,  5.4064059e-01,\n",
            "        5.0736636e-01,  7.0209426e-01,  2.5777817e-01,  9.2037916e-01,\n",
            "       -2.3876429e-01,  9.9068618e-01, -1.0033627e+00,  2.2373567e+00,\n",
            "       -1.7786278e+00,  6.6903377e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.2296036  -0.14545825  1.230482   -0.14887667  1.2300997  -0.1413449\n",
            "  1.2300382  -0.14199078]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.7522163, dtype=float32), 'agent_0': Array(-3.7522163, dtype=float32), 'agent_1': Array(-3.7522163, dtype=float32), 'agent_2': Array(-3.7522163, dtype=float32), 'agent_3': Array(-3.7522163, dtype=float32)}\n",
            "step: 388\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2021027e-01, -1.5824750e-01, -1.9414362e-02,  3.2130082e-03,\n",
            "        9.8720342e-01,  5.5150616e-01,  8.2869071e-01,  4.2783782e-01,\n",
            "        5.8718508e-01,  5.6831741e-01, -4.7683716e-05,  6.5205097e-01,\n",
            "       -7.0227385e-01,  6.0547704e-01,  8.8596433e-01, -6.5546638e-01,\n",
            "        1.3441486e+00,  2.5385125e+00], dtype=float32), 'agent_1': Array([ 5.2021027e-01, -1.5824750e-01, -1.9414362e-02,  3.2130082e-03,\n",
            "        9.8720342e-01,  5.5150616e-01,  4.2783782e-01, -5.0141472e-01,\n",
            "        5.8718508e-01,  5.6831741e-01, -4.7683716e-05,  6.5205097e-01,\n",
            "       -7.0227385e-01,  6.0547704e-01,  8.8596433e-01, -6.5546638e-01,\n",
            "        2.4022117e+00, -2.3963673e-01], dtype=float32), 'agent_2': Array([ 5.2021027e-01, -1.5824750e-01, -1.9414362e-02,  3.2130082e-03,\n",
            "        9.8720342e-01,  5.5150616e-01,  4.2783782e-01,  5.8718508e-01,\n",
            "       -5.4102850e-01,  5.6831741e-01, -4.7683716e-05,  6.5205097e-01,\n",
            "       -7.0227385e-01,  6.0547704e-01,  8.8596433e-01, -6.5546638e-01,\n",
            "       -4.4756967e-01,  3.5847518e+00], dtype=float32), 'agent_3': Array([ 5.2021027e-01, -1.5824750e-01, -1.9414362e-02,  3.2130082e-03,\n",
            "        9.8720342e-01,  5.5150616e-01,  4.2783782e-01,  5.8718508e-01,\n",
            "        5.6831741e-01,  8.1900543e-01, -4.7683716e-05,  6.5205097e-01,\n",
            "       -7.0227385e-01,  6.0547704e-01,  8.8596433e-01, -6.5546638e-01,\n",
            "        5.7661724e-01, -2.7130195e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.7322935   0.5862648  -0.72880244  0.5875207  -0.7328158   0.58620274\n",
            " -0.73176074  0.58645844]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8932979, dtype=float32), 'agent_0': Array(-1.8932979, dtype=float32), 'agent_1': Array(-1.8932979, dtype=float32), 'agent_2': Array(-1.8932979, dtype=float32), 'agent_3': Array(-1.8932979, dtype=float32)}\n",
            "step: 389\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3476566e-01, -3.2496259e-01,  2.7092305e-04,  2.4728823e-02,\n",
            "        9.4540352e-01,  1.5483561e-01,  1.0639321e+00,  6.4889133e-02,\n",
            "        9.2700981e-02,  1.5317535e-01, -2.6102066e-01,  3.5337210e-01,\n",
            "        5.5850744e-01,  1.1422046e-01, -8.0576432e-01,  9.6382742e+00,\n",
            "       -1.1781086e+01,  5.0643654e+00], dtype=float32), 'agent_1': Array([ 5.3476566e-01, -3.2496259e-01,  2.7092305e-04,  2.4728823e-02,\n",
            "        9.4540352e-01,  1.5483561e-01,  6.4889133e-02, -4.8782000e-01,\n",
            "        9.2700981e-02,  1.5317535e-01, -2.6102066e-01,  3.5337210e-01,\n",
            "        5.5850744e-01,  1.1422046e-01, -8.0576432e-01,  9.6382742e+00,\n",
            "       -1.0154969e+01, -9.8943400e-01], dtype=float32), 'agent_2': Array([ 5.3476566e-01, -3.2496259e-01,  2.7092305e-04,  2.4728823e-02,\n",
            "        9.4540352e-01,  1.5483561e-01,  6.4889133e-02,  9.2700981e-02,\n",
            "       -4.7610065e-01,  1.5317535e-01, -2.6102066e-01,  3.5337210e-01,\n",
            "        5.5850744e-01,  1.1422046e-01, -8.0576432e-01,  9.6382742e+00,\n",
            "       -1.3888034e+01, -8.3440012e-01], dtype=float32), 'agent_3': Array([ 5.3476566e-01, -3.2496259e-01,  2.7092305e-04,  2.4728823e-02,\n",
            "        9.4540352e-01,  1.5483561e-01,  6.4889133e-02,  9.2700981e-02,\n",
            "        1.5317535e-01,  9.8739147e-01, -2.6102066e-01,  3.5337210e-01,\n",
            "        5.5850744e-01,  1.1422046e-01, -8.0576432e-01,  9.6382742e+00,\n",
            "       -1.2062408e+01,  4.1031690e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.88859916 -1.1473182   0.89855    -1.1451267   0.9003856  -1.1489109\n",
            "  0.8909468  -1.1441009 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1216795, dtype=float32), 'agent_0': Array(-1.1216795, dtype=float32), 'agent_1': Array(-1.1216795, dtype=float32), 'agent_2': Array(-1.1216795, dtype=float32), 'agent_3': Array(-1.1216795, dtype=float32)}\n",
            "step: 390\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.64426482e-01, -2.18735173e-01, -4.44562882e-02,  1.67908298e-03,\n",
            "        9.74769592e-01,  4.27028835e-01,  8.46363485e-01,  3.94461900e-01,\n",
            "        2.90160984e-01,  4.07003522e-01,  2.14862823e-01,  7.36486912e-01,\n",
            "        1.12986565e-01, -6.72426581e-01,  2.92485452e+00, -8.94608688e+00,\n",
            "        1.11141901e+01, -6.84909916e+00], dtype=float32), 'agent_1': Array([ 5.64426482e-01, -2.18735173e-01, -4.44562882e-02,  1.67908298e-03,\n",
            "        9.74769592e-01,  4.27028835e-01,  3.94461900e-01, -8.98247957e-01,\n",
            "        2.90160984e-01,  4.07003522e-01,  2.14862823e-01,  7.36486912e-01,\n",
            "        1.12986565e-01, -6.72426581e-01,  2.92485452e+00, -8.94608688e+00,\n",
            "        1.21951046e+01, -1.22590160e+01], dtype=float32), 'agent_2': Array([ 5.64426482e-01, -2.18735173e-01, -4.44562882e-02,  1.67908298e-03,\n",
            "        9.74769592e-01,  4.27028835e-01,  3.94461900e-01,  2.90160984e-01,\n",
            "       -8.50789011e-01,  4.07003522e-01,  2.14862823e-01,  7.36486912e-01,\n",
            "        1.12986565e-01, -6.72426581e-01,  2.92485452e+00, -8.94608688e+00,\n",
            "        1.00866404e+01, -1.16679707e+01], dtype=float32), 'agent_3': Array([ 5.64426482e-01, -2.18735173e-01, -4.44562882e-02,  1.67908298e-03,\n",
            "        9.74769592e-01,  4.27028835e-01,  3.94461900e-01,  2.90160984e-01,\n",
            "        4.07003522e-01,  7.22343147e-01,  2.14862823e-01,  7.36486912e-01,\n",
            "        1.12986565e-01, -6.72426581e-01,  2.92485452e+00, -8.94608688e+00,\n",
            "        1.12066536e+01, -8.26449871e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1426805 -1.448331   1.1473064 -1.4544942  1.1454281 -1.4486794\n",
            "  1.1428576 -1.4494231]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.2115684, dtype=float32), 'agent_0': Array(-3.2115684, dtype=float32), 'agent_1': Array(-3.2115684, dtype=float32), 'agent_2': Array(-3.2115684, dtype=float32), 'agent_3': Array(-3.2115684, dtype=float32)}\n",
            "step: 391\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5386287 , -0.15009297, -0.08856732, -0.04688099,  0.98358023,\n",
            "        0.56676966,  0.44277427,  0.57183367,  0.5507506 ,  0.564689  ,\n",
            "        0.11258125,  0.6444454 , -0.6852746 , -0.9940478 , -0.6253988 ,\n",
            "        0.42856854, -1.1246783 , -4.7561517 ], dtype=float32), 'agent_1': Array([ 0.5386287 , -0.15009297, -0.08856732, -0.04688099,  0.98358023,\n",
            "        0.56676966,  0.57183367, -1.3307582 ,  0.5507506 ,  0.564689  ,\n",
            "        0.11258125,  0.6444454 , -0.6852746 , -0.9940478 , -0.6253988 ,\n",
            "        0.42856854, -1.0918692 ,  1.3350427 ], dtype=float32), 'agent_2': Array([ 0.5386287 , -0.15009297, -0.08856732, -0.04688099,  0.98358023,\n",
            "        0.56676966,  0.57183367,  0.5507506 , -1.341799  ,  0.564689  ,\n",
            "        0.11258125,  0.6444454 , -0.6852746 , -0.9940478 , -0.6253988 ,\n",
            "        0.42856854,  1.6845274 , -0.632161  ], dtype=float32), 'agent_3': Array([ 0.5386287 , -0.15009297, -0.08856732, -0.04688099,  0.98358023,\n",
            "        0.56676966,  0.57183367,  0.5507506 ,  0.564689  ,  0.444056  ,\n",
            "        0.11258125,  0.6444454 , -0.6852746 , -0.9940478 , -0.6253988 ,\n",
            "        0.42856854, -1.2340535 ,  1.0200253 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8146025   0.7985677  -0.8211623   0.80299705 -0.81740487  0.8054678\n",
            " -0.82053053  0.801638  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.4955173, dtype=float32), 'agent_0': Array(-5.4955173, dtype=float32), 'agent_1': Array(-5.4955173, dtype=float32), 'agent_2': Array(-5.4955173, dtype=float32), 'agent_3': Array(-5.4955173, dtype=float32)}\n",
            "step: 392\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.49558699e-01, -3.44415039e-01, -6.59525767e-02, -7.96105992e-03,\n",
            "        9.36464190e-01,  1.58723518e-02,  6.51595235e-01,  4.52218428e-02,\n",
            "        1.46380395e-01,  5.68007585e-03, -9.70363617e-02, -6.88385963e-01,\n",
            "        7.35545158e-01,  2.67424524e-01, -1.19899549e-01,  1.06095705e+01,\n",
            "       -1.41261702e+01,  4.50595856e+00], dtype=float32), 'agent_1': Array([ 5.49558699e-01, -3.44415039e-01, -6.59525767e-02, -7.96105992e-03,\n",
            "        9.36464190e-01,  1.58723518e-02,  4.52218428e-02, -1.13879573e+00,\n",
            "        1.46380395e-01,  5.68007585e-03, -9.70363617e-02, -6.88385963e-01,\n",
            "        7.35545158e-01,  2.67424524e-01, -1.19899549e-01,  1.06095705e+01,\n",
            "       -1.39315767e+01,  3.40533471e+00], dtype=float32), 'agent_2': Array([ 5.49558699e-01, -3.44415039e-01, -6.59525767e-02, -7.96105992e-03,\n",
            "        9.36464190e-01,  1.58723518e-02,  4.52218428e-02,  1.46380395e-01,\n",
            "       -1.15931249e+00,  5.68007585e-03, -9.70363617e-02, -6.88385963e-01,\n",
            "        7.35545158e-01,  2.67424524e-01, -1.19899549e-01,  1.06095705e+01,\n",
            "       -1.22315540e+01,  3.56305575e+00], dtype=float32), 'agent_3': Array([ 5.49558699e-01, -3.44415039e-01, -6.59525767e-02, -7.96105992e-03,\n",
            "        9.36464190e-01,  1.58723518e-02,  4.52218428e-02,  1.46380395e-01,\n",
            "        5.68007585e-03,  6.68669641e-01, -9.70363617e-02, -6.88385963e-01,\n",
            "        7.35545158e-01,  2.67424524e-01, -1.19899549e-01,  1.06095705e+01,\n",
            "       -1.47203560e+01,  4.23247433e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.0057959  -1.2756366  -0.00367022 -1.2743282  -0.00752626 -1.2718085\n",
            " -0.00449745 -1.2743324 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7722182, dtype=float32), 'agent_0': Array(-1.7722182, dtype=float32), 'agent_1': Array(-1.7722182, dtype=float32), 'agent_2': Array(-1.7722182, dtype=float32), 'agent_3': Array(-1.7722182, dtype=float32)}\n",
            "step: 393\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.69269538e-01, -4.29669678e-01, -1.03700384e-01, -3.61970463e-03,\n",
            "        8.97004604e-01, -2.79336035e-01,  4.84424502e-01, -2.25649238e-01,\n",
            "       -7.08112717e-02, -3.10204804e-01,  1.75952911e-02, -3.76629829e-01,\n",
            "        3.99017334e-01,  4.34449285e-01,  1.04075944e+00,  1.84523582e+00,\n",
            "       -3.79247093e+00, -2.38233829e+00], dtype=float32), 'agent_1': Array([ 0.56926954, -0.42966968, -0.10370038, -0.0036197 ,  0.8970046 ,\n",
            "       -0.27933604, -0.22564924, -1.2461205 , -0.07081127, -0.3102048 ,\n",
            "        0.01759529, -0.37662983,  0.39901733,  0.4344493 ,  1.0407594 ,\n",
            "        1.8452358 , -2.9437768 , -1.037555  ], dtype=float32), 'agent_2': Array([ 0.56926954, -0.42966968, -0.10370038, -0.0036197 ,  0.8970046 ,\n",
            "       -0.27933604, -0.22564924, -0.07081127, -1.241256  , -0.3102048 ,\n",
            "        0.01759529, -0.37662983,  0.39901733,  0.4344493 ,  1.0407594 ,\n",
            "        1.8452358 , -1.8345195 , -0.93642986], dtype=float32), 'agent_3': Array([ 5.69269538e-01, -4.29669678e-01, -1.03700384e-01, -3.61970463e-03,\n",
            "        8.97004604e-01, -2.79336035e-01, -2.25649238e-01, -7.08112717e-02,\n",
            "       -3.10204804e-01,  5.04272699e-01,  1.75952911e-02, -3.76629829e-01,\n",
            "        3.99017334e-01,  4.34449285e-01,  1.04075944e+00,  1.84523582e+00,\n",
            "       -3.31094408e+00, -3.73287749e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.61699384  1.5852222  -0.6186693   1.5887668  -0.6209583   1.5898786\n",
            " -0.61802524  1.58772   ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.1710505, dtype=float32), 'agent_0': Array(-2.1710505, dtype=float32), 'agent_1': Array(-2.1710505, dtype=float32), 'agent_2': Array(-2.1710505, dtype=float32), 'agent_3': Array(-2.1710505, dtype=float32)}\n",
            "step: 394\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57279634, -0.5185593 , -0.04951171,  0.01338281,  0.8535021 ,\n",
            "       -0.5725052 ,  0.8335654 , -0.5291595 , -0.3193646 , -0.5754194 ,\n",
            "       -0.6186962 , -0.5899906 , -0.13611317, -0.8792003 , -2.3307672 ,\n",
            "       -0.08812112, -0.3822034 ,  9.1653    ], dtype=float32), 'agent_1': Array([ 0.57279634, -0.5185593 , -0.04951171,  0.01338281,  0.8535021 ,\n",
            "       -0.5725052 , -0.5291595 , -0.88778275, -0.3193646 , -0.5754194 ,\n",
            "       -0.6186962 , -0.5899906 , -0.13611317, -0.8792003 , -2.3307672 ,\n",
            "       -0.08812112, -1.4193761 ,  8.991048  ], dtype=float32), 'agent_2': Array([ 0.57279634, -0.5185593 , -0.04951171,  0.01338281,  0.8535021 ,\n",
            "       -0.5725052 , -0.5291595 , -0.3193646 , -0.9274482 , -0.5754194 ,\n",
            "       -0.6186962 , -0.5899906 , -0.13611317, -0.8792003 , -2.3307672 ,\n",
            "       -0.08812112, -2.1664789 ,  7.9540353 ], dtype=float32), 'agent_3': Array([ 0.57279634, -0.5185593 , -0.04951171,  0.01338281,  0.8535021 ,\n",
            "       -0.5725052 , -0.5291595 , -0.3193646 , -0.5754194 ,  0.78610784,\n",
            "       -0.6186962 , -0.5899906 , -0.13611317, -0.8792003 , -2.3307672 ,\n",
            "       -0.08812112,  0.8709037 ,  7.103373  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.10272042 -0.5228923  -0.10239826 -0.52119863 -0.10295757 -0.5212706\n",
            " -0.10332601 -0.5110666 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.218227, dtype=float32), 'agent_0': Array(-5.218227, dtype=float32), 'agent_1': Array(-5.218227, dtype=float32), 'agent_2': Array(-5.218227, dtype=float32), 'agent_3': Array(-5.218227, dtype=float32)}\n",
            "step: 395\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55383337, -0.4986471 , -0.05736991,  0.01507208,  0.86477315,\n",
            "       -0.5148989 ,  0.8705885 , -0.5365853 , -0.35838795, -0.5043059 ,\n",
            "       -0.11992455, -0.15439987, -0.5376339 ,  0.36898014,  1.041474  ,\n",
            "       -0.84966546,  1.4323186 , -2.7919917 ], dtype=float32), 'agent_1': Array([ 0.55383337, -0.4986471 , -0.05736991,  0.01507208,  0.86477315,\n",
            "       -0.5148989 , -0.5365853 , -0.87323457, -0.35838795, -0.5043059 ,\n",
            "       -0.11992455, -0.15439987, -0.5376339 ,  0.36898014,  1.041474  ,\n",
            "       -0.84966546,  0.18810962, -2.2286115 ], dtype=float32), 'agent_2': Array([ 0.55383337, -0.4986471 , -0.05736991,  0.01507208,  0.86477315,\n",
            "       -0.5148989 , -0.5365853 , -0.35838795, -0.91530985, -0.5043059 ,\n",
            "       -0.11992455, -0.15439987, -0.5376339 ,  0.36898014,  1.041474  ,\n",
            "       -0.84966546, -0.9208148 , -2.0365784 ], dtype=float32), 'agent_3': Array([ 0.55383337, -0.4986471 , -0.05736991,  0.01507208,  0.86477315,\n",
            "       -0.5148989 , -0.5365853 , -0.35838795, -0.5043059 ,  0.7452837 ,\n",
            "       -0.11992455, -0.15439987, -0.5376339 ,  0.36898014,  1.041474  ,\n",
            "       -0.84966546,  1.7757539 , -3.4098234 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.13528235 -2.680758   -0.13651672 -2.6778178  -0.13587551 -2.6767266\n",
            " -0.13676398 -2.6762645 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.15198845, dtype=float32), 'agent_0': Array(0.15198845, dtype=float32), 'agent_1': Array(0.15198845, dtype=float32), 'agent_2': Array(0.15198845, dtype=float32), 'agent_3': Array(0.15198845, dtype=float32)}\n",
            "step: 396\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.67321599e-01, -4.88271773e-01, -9.27522257e-02,  9.96030401e-03,\n",
            "        8.67691457e-01, -4.80629563e-01,  5.67551076e-01, -5.43068528e-01,\n",
            "       -4.29858983e-01, -4.72241729e-01,  4.91809845e-01,  1.31726265e-02,\n",
            "       -1.01959705e-01,  5.82551181e-01,  1.73403466e+00, -5.74316271e-03,\n",
            "       -3.26097071e-01, -8.10698318e+00], dtype=float32), 'agent_1': Array([ 5.67321599e-01, -4.88271773e-01, -9.27522257e-02,  9.96030401e-03,\n",
            "        8.67691457e-01, -4.80629563e-01, -5.43068528e-01, -1.13864160e+00,\n",
            "       -4.29858983e-01, -4.72241729e-01,  4.91809845e-01,  1.31726265e-02,\n",
            "       -1.01959705e-01,  5.82551181e-01,  1.73403466e+00, -5.74316271e-03,\n",
            "       -1.30738601e-01, -7.57131004e+00], dtype=float32), 'agent_2': Array([ 5.67321599e-01, -4.88271773e-01, -9.27522257e-02,  9.96030401e-03,\n",
            "        8.67691457e-01, -4.80629563e-01, -5.43068528e-01, -4.29858983e-01,\n",
            "       -1.19308150e+00, -4.72241729e-01,  4.91809845e-01,  1.31726265e-02,\n",
            "       -1.01959705e-01,  5.82551181e-01,  1.73403466e+00, -5.74316271e-03,\n",
            "       -1.82429755e+00, -7.94957972e+00], dtype=float32), 'agent_3': Array([ 0.5673216 , -0.48827177, -0.09275223,  0.0099603 ,  0.86769146,\n",
            "       -0.48062956, -0.5430685 , -0.42985898, -0.47224173,  0.4596777 ,\n",
            "        0.49180984,  0.01317263, -0.10195971,  0.5825512 ,  1.7340347 ,\n",
            "       -0.00574316, -0.18026105, -3.2001655 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.09121744 -0.78911597  0.0905934  -0.78711617  0.08998089 -0.7899414\n",
            "  0.0834304  -0.77877676]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.87853, dtype=float32), 'agent_0': Array(-12.87853, dtype=float32), 'agent_1': Array(-12.87853, dtype=float32), 'agent_2': Array(-12.87853, dtype=float32), 'agent_3': Array(-12.87853, dtype=float32)}\n",
            "step: 397\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55709046, -0.45794824, -0.09287781,  0.00336524,  0.8841074 ,\n",
            "       -0.39919636,  0.4634811 , -0.48068705, -0.42455438, -0.40551805,\n",
            "        0.19192696, -0.24871826, -0.06693602, -0.24451897, -0.7134261 ,\n",
            "       -1.6322926 ,  1.9651409 ,  0.4462456 ], dtype=float32), 'agent_1': Array([ 0.55709046, -0.45794824, -0.09287781,  0.00336524,  0.8841074 ,\n",
            "       -0.39919636, -0.48068705, -1.2864277 , -0.42455438, -0.40551805,\n",
            "        0.19192696, -0.24871826, -0.06693602, -0.24451897, -0.7134261 ,\n",
            "       -1.6322926 ,  1.7877703 , -0.03483076], dtype=float32), 'agent_2': Array([ 0.55709046, -0.45794824, -0.09287781,  0.00336524,  0.8841074 ,\n",
            "       -0.39919636, -0.48068705, -0.42455438, -1.2773324 , -0.40551805,\n",
            "        0.19192696, -0.24871826, -0.06693602, -0.24451897, -0.7134261 ,\n",
            "       -1.6322926 ,  0.32278997,  0.6524313 ], dtype=float32), 'agent_3': Array([ 0.55709046, -0.45794824, -0.09287781,  0.00336524,  0.8841074 ,\n",
            "       -0.39919636, -0.48068705, -0.42455438, -0.40551805,  0.4684298 ,\n",
            "        0.19192696, -0.24871826, -0.06693602, -0.24451897, -0.7134261 ,\n",
            "       -1.6322926 ,  1.5330645 ,  0.542876  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3118096  -1.3340971  -0.3129162  -1.3359284  -0.3123968  -1.3339263\n",
            " -0.31215903 -1.3337585 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.0809716, dtype=float32), 'agent_0': Array(0.0809716, dtype=float32), 'agent_1': Array(0.0809716, dtype=float32), 'agent_2': Array(0.0809716, dtype=float32), 'agent_3': Array(0.0809716, dtype=float32)}\n",
            "step: 398\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4365522e-01, -4.8413673e-01, -8.8911459e-02,  1.1145363e-03,\n",
            "        8.7046272e-01, -4.8190758e-01,  4.7812617e-01, -5.4039991e-01,\n",
            "       -5.5623180e-01, -5.1920724e-01,  2.4242401e-01, -2.5479794e-01,\n",
            "       -5.6777000e-01, -2.6710898e-01, -3.4607258e-01,  1.7862234e-01,\n",
            "       -1.1362743e+00,  1.0813682e+00], dtype=float32), 'agent_1': Array([ 5.4365522e-01, -4.8413673e-01, -8.8911459e-02,  1.1145363e-03,\n",
            "        8.7046272e-01, -4.8190758e-01, -5.4039991e-01, -1.2725686e+00,\n",
            "       -5.5623180e-01, -5.1920724e-01,  2.4242401e-01, -2.5479794e-01,\n",
            "       -5.6777000e-01, -2.6710898e-01, -3.4607258e-01,  1.7862234e-01,\n",
            "        2.3424965e-01,  1.1890661e+00], dtype=float32), 'agent_2': Array([ 5.4365522e-01, -4.8413673e-01, -8.8911459e-02,  1.1145363e-03,\n",
            "        8.7046272e-01, -4.8190758e-01, -5.4039991e-01, -5.5623180e-01,\n",
            "       -1.2585752e+00, -5.1920724e-01,  2.4242401e-01, -2.5479794e-01,\n",
            "       -5.6777000e-01, -2.6710898e-01, -3.4607258e-01,  1.7862234e-01,\n",
            "       -6.1466122e-01,  1.1125531e+00], dtype=float32), 'agent_3': Array([ 5.4365522e-01, -4.8413673e-01, -8.8911459e-02,  1.1145363e-03,\n",
            "        8.7046272e-01, -4.8190758e-01, -5.4039991e-01, -5.5623180e-01,\n",
            "       -5.1920724e-01,  4.9732611e-01,  2.4242401e-01, -2.5479794e-01,\n",
            "       -5.6777000e-01, -2.6710898e-01, -3.4607258e-01,  1.7862234e-01,\n",
            "       -1.6772057e+00,  5.1646578e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.03553144 -0.8068088  -0.0341683  -0.8024019  -0.03320216 -0.80377346\n",
            " -0.03475387 -0.8051145 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.5548532, dtype=float32), 'agent_0': Array(-2.5548532, dtype=float32), 'agent_1': Array(-2.5548532, dtype=float32), 'agent_2': Array(-2.5548532, dtype=float32), 'agent_3': Array(-2.5548532, dtype=float32)}\n",
            "step: 399\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5012362 , -0.47011048, -0.08046176, -0.00414087,  0.8789225 ,\n",
            "       -0.48553255,  0.5102973 , -0.5010538 , -0.5163145 , -0.53098124,\n",
            "        0.21886826, -0.20387173, -0.8459449 , -0.30828014,  0.19402917,\n",
            "       -0.7415365 , -0.10742527, -0.2089365 ], dtype=float32), 'agent_1': Array([ 0.5012362 , -0.47011048, -0.08046176, -0.00414087,  0.8789225 ,\n",
            "       -0.48553255, -0.5010538 , -1.2274652 , -0.5163145 , -0.53098124,\n",
            "        0.21886826, -0.20387173, -0.8459449 , -0.30828014,  0.19402917,\n",
            "       -0.7415365 ,  0.8945795 ,  0.08382234], dtype=float32), 'agent_2': Array([ 0.5012362 , -0.47011048, -0.08046176, -0.00414087,  0.8789225 ,\n",
            "       -0.48553255, -0.5010538 , -0.5163145 , -1.2349977 , -0.53098124,\n",
            "        0.21886826, -0.20387173, -0.8459449 , -0.30828014,  0.19402917,\n",
            "       -0.7415365 ,  1.2495716 , -0.19110504], dtype=float32), 'agent_3': Array([ 0.5012362 , -0.47011048, -0.08046176, -0.00414087,  0.8789225 ,\n",
            "       -0.48553255, -0.5010538 , -0.5163145 , -0.53098124,  0.50077564,\n",
            "        0.21886826, -0.20387173, -0.8459449 , -0.30828014,  0.19402917,\n",
            "       -0.7415365 ,  0.1550461 , -0.56774944], dtype=float32)}\n",
            "ctrl action chosen: [-0.29050004 -1.0665717  -0.28877535 -1.0640209  -0.28803217 -1.0639623\n",
            " -0.29028037 -1.0643272 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.02840734, dtype=float32), 'agent_0': Array(-0.02840734, dtype=float32), 'agent_1': Array(-0.02840734, dtype=float32), 'agent_2': Array(-0.02840734, dtype=float32), 'agent_3': Array(-0.02840734, dtype=float32)}\n",
            "step: 400\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49210072, -0.47025302, -0.09500396, -0.01942311,  0.87718827,\n",
            "       -0.53962326,  0.47200358, -0.5343417 , -0.49818292, -0.53623754,\n",
            "       -0.10118484, -0.21871328,  0.2670586 , -0.13069001,  1.0028654 ,\n",
            "       -0.4025039 , -0.30169088, -0.43503985], dtype=float32), 'agent_1': Array([ 0.49210072, -0.47025302, -0.09500396, -0.01942311,  0.87718827,\n",
            "       -0.53962326, -0.5343417 , -1.2501214 , -0.49818292, -0.53623754,\n",
            "       -0.10118484, -0.21871328,  0.2670586 , -0.13069001,  1.0028654 ,\n",
            "       -0.4025039 , -0.4801242 , -0.3908701 ], dtype=float32), 'agent_2': Array([ 0.49210072, -0.47025302, -0.09500396, -0.01942311,  0.87718827,\n",
            "       -0.53962326, -0.5343417 , -0.49818292, -1.251457  , -0.53623754,\n",
            "       -0.10118484, -0.21871328,  0.2670586 , -0.13069001,  1.0028654 ,\n",
            "       -0.4025039 ,  0.5009359 , -0.13332497], dtype=float32), 'agent_3': Array([ 0.49210072, -0.47025302, -0.09500396, -0.01942311,  0.87718827,\n",
            "       -0.53962326, -0.5343417 , -0.49818292, -0.53623754,  0.4712241 ,\n",
            "       -0.10118484, -0.21871328,  0.2670586 , -0.13069001,  1.0028654 ,\n",
            "       -0.4025039 ,  0.4213563 , -0.11610673], dtype=float32)}\n",
            "ctrl action chosen: [-0.215339   -0.1466805  -0.21517216 -0.14431022 -0.21342328 -0.14340067\n",
            " -0.21536471 -0.1421516 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4158683, dtype=float32), 'agent_0': Array(-1.4158683, dtype=float32), 'agent_1': Array(-1.4158683, dtype=float32), 'agent_2': Array(-1.4158683, dtype=float32), 'agent_3': Array(-1.4158683, dtype=float32)}\n",
            "step: 401\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5092827 , -0.45996132, -0.10666338, -0.03161445,  0.8809421 ,\n",
            "       -0.5320156 ,  0.50837475, -0.5389476 , -0.4955746 , -0.5176585 ,\n",
            "       -0.13971329, -0.4585147 ,  0.4042387 ,  0.21835425,  1.0293447 ,\n",
            "       -0.27141625,  0.36572447, -0.38647   ], dtype=float32), 'agent_1': Array([ 0.5092827 , -0.45996132, -0.10666338, -0.03161445,  0.8809421 ,\n",
            "       -0.5320156 , -0.5389476 , -1.2245167 , -0.4955746 , -0.5176585 ,\n",
            "       -0.13971329, -0.4585147 ,  0.4042387 ,  0.21835425,  1.0293447 ,\n",
            "       -0.27141625,  0.10066921, -0.52277845], dtype=float32), 'agent_2': Array([ 0.5092827 , -0.45996132, -0.10666338, -0.03161445,  0.8809421 ,\n",
            "       -0.5320156 , -0.5389476 , -0.4955746 , -1.2243729 , -0.5176585 ,\n",
            "       -0.13971329, -0.4585147 ,  0.4042387 ,  0.21835425,  1.0293447 ,\n",
            "       -0.27141625, -0.67547154, -0.6760451 ], dtype=float32), 'agent_3': Array([ 0.5092827 , -0.45996132, -0.10666338, -0.03161445,  0.8809421 ,\n",
            "       -0.5320156 , -0.5389476 , -0.4955746 , -0.5176585 ,  0.5196717 ,\n",
            "       -0.13971329, -0.4585147 ,  0.4042387 ,  0.21835425,  1.0293447 ,\n",
            "       -0.27141625, -0.09368553,  0.03865692], dtype=float32)}\n",
            "ctrl action chosen: [ 0.17017421 -0.4572678   0.17046955 -0.4559957   0.17014207 -0.4551839\n",
            "  0.17043613 -0.45172024]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.62449205, dtype=float32), 'agent_0': Array(0.62449205, dtype=float32), 'agent_1': Array(0.62449205, dtype=float32), 'agent_2': Array(0.62449205, dtype=float32), 'agent_3': Array(0.62449205, dtype=float32)}\n",
            "step: 402\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5296409 , -0.4174921 , -0.12110466, -0.03645136,  0.89983624,\n",
            "       -0.4059067 ,  0.49804184, -0.4358887 , -0.42640233, -0.42119437,\n",
            "       -0.15072823, -0.09809732,  0.4258871 ,  0.273669  ,  0.0756216 ,\n",
            "       -2.1906106 ,  2.9944391 ,  0.19646148], dtype=float32), 'agent_1': Array([ 0.5296409 , -0.4174921 , -0.12110466, -0.03645136,  0.89983624,\n",
            "       -0.4059067 , -0.4358887 , -1.2449532 , -0.42640233, -0.42119437,\n",
            "       -0.15072823, -0.09809732,  0.4258871 ,  0.273669  ,  0.0756216 ,\n",
            "       -2.1906106 ,  2.6105847 ,  0.0783418 ], dtype=float32), 'agent_2': Array([ 0.5296409 , -0.4174921 , -0.12110466, -0.03645136,  0.89983624,\n",
            "       -0.4059067 , -0.4358887 , -0.42640233, -1.2393107 , -0.42119437,\n",
            "       -0.15072823, -0.09809732,  0.4258871 ,  0.273669  ,  0.0756216 ,\n",
            "       -2.1906106 ,  1.8516339 ,  0.3489591 ], dtype=float32), 'agent_3': Array([ 0.5296409 , -0.4174921 , -0.12110466, -0.03645136,  0.89983624,\n",
            "       -0.4059067 , -0.4358887 , -0.42640233, -0.42119437,  0.512165  ,\n",
            "       -0.15072823, -0.09809732,  0.4258871 ,  0.273669  ,  0.0756216 ,\n",
            "       -2.1906106 ,  2.406235  ,  0.14604606], dtype=float32)}\n",
            "ctrl action chosen: [0.60253257 0.23402275 0.6006234  0.23377863 0.6010011  0.2363338\n",
            " 0.60031545 0.23639584]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.39777613, dtype=float32), 'agent_0': Array(0.39777613, dtype=float32), 'agent_1': Array(0.39777613, dtype=float32), 'agent_2': Array(0.39777613, dtype=float32), 'agent_3': Array(0.39777613, dtype=float32)}\n",
            "step: 403\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55060554, -0.26017097, -0.10462824, -0.0460127 ,  0.9587736 ,\n",
            "        0.01652659,  0.5751209 , -0.03162752, -0.05057357, -0.01430067,\n",
            "       -0.09717941,  0.27457476,  0.40591955,  0.3449484 , -0.5944633 ,\n",
            "       -8.170229  , 10.475435  ,  1.8433638 ], dtype=float32), 'agent_1': Array([ 0.55060554, -0.26017097, -0.10462824, -0.0460127 ,  0.9587736 ,\n",
            "        0.01652659, -0.03162752, -1.1562634 , -0.05057357, -0.01430067,\n",
            "       -0.09717941,  0.27457476,  0.40591955,  0.3449484 , -0.5944633 ,\n",
            "       -8.170229  ,  9.902325  ,  2.4545016 ], dtype=float32), 'agent_2': Array([ 0.55060554, -0.26017097, -0.10462824, -0.0460127 ,  0.9587736 ,\n",
            "        0.01652659, -0.03162752, -0.05057357, -1.1281912 , -0.01430067,\n",
            "       -0.09717941,  0.27457476,  0.40591955,  0.3449484 , -0.5944633 ,\n",
            "       -8.170229  ,  9.381905  ,  2.7254624 ], dtype=float32), 'agent_3': Array([ 0.55060554, -0.26017097, -0.10462824, -0.0460127 ,  0.9587736 ,\n",
            "        0.01652659, -0.03162752, -0.05057357, -0.01430067,  0.61837465,\n",
            "       -0.09717941,  0.27457476,  0.40591955,  0.3449484 , -0.5944633 ,\n",
            "       -8.170229  , 10.053342  ,  2.4275239 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1584637 -1.5782362 -1.160736  -1.5781761 -1.1599189 -1.5746558\n",
            " -1.1594396 -1.5756067]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.01981354, dtype=float32), 'agent_0': Array(-0.01981354, dtype=float32), 'agent_1': Array(-0.01981354, dtype=float32), 'agent_2': Array(-0.01981354, dtype=float32), 'agent_3': Array(-0.01981354, dtype=float32)}\n",
            "step: 404\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.55474174,  -0.39957854,  -0.14215653,  -0.02006689,\n",
            "         0.90538716,  -0.32386315,   0.4702725 ,  -0.4065622 ,\n",
            "        -0.44613293,  -0.3824375 ,   0.19431114,   0.23211241,\n",
            "        -0.17156601,   0.5207297 ,   0.26168165,  10.322635  ,\n",
            "       -12.68288   ,   0.07456315], dtype=float32), 'agent_1': Array([  0.55474174,  -0.39957854,  -0.14215653,  -0.02006689,\n",
            "         0.90538716,  -0.32386315,  -0.4065622 ,  -1.2722862 ,\n",
            "        -0.44613293,  -0.3824375 ,   0.19431114,   0.23211241,\n",
            "        -0.17156601,   0.5207297 ,   0.26168165,  10.322635  ,\n",
            "       -13.019558  ,  -0.13443509], dtype=float32), 'agent_2': Array([  0.55474174,  -0.39957854,  -0.14215653,  -0.02006689,\n",
            "         0.90538716,  -0.32386315,  -0.4065622 ,  -0.44613293,\n",
            "        -1.2745245 ,  -0.3824375 ,   0.19431114,   0.23211241,\n",
            "        -0.17156601,   0.5207297 ,   0.26168165,  10.322635  ,\n",
            "       -13.246746  ,  -0.7170334 ], dtype=float32), 'agent_3': Array([  0.55474174,  -0.39957854,  -0.14215653,  -0.02006689,\n",
            "         0.90538716,  -0.32386315,  -0.4065622 ,  -0.44613293,\n",
            "        -0.3824375 ,   0.46393996,   0.19431114,   0.23211241,\n",
            "        -0.17156601,   0.5207297 ,   0.26168165,  10.322635  ,\n",
            "       -12.973061  ,  -0.39127883], dtype=float32)}\n",
            "ctrl action chosen: [-0.34117585 -0.24574775 -0.3391306  -0.24572982 -0.3391125  -0.24618748\n",
            " -0.3390276  -0.24341863]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.454031, dtype=float32), 'agent_0': Array(-6.454031, dtype=float32), 'agent_1': Array(-6.454031, dtype=float32), 'agent_2': Array(-6.454031, dtype=float32), 'agent_3': Array(-6.454031, dtype=float32)}\n",
            "step: 405\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3924102e-01, -4.4954312e-01, -1.3423735e-01, -8.5410220e-04,\n",
            "        8.8311422e-01, -5.2965003e-01,  5.1702392e-01, -5.5183727e-01,\n",
            "       -5.5463201e-01, -5.4834074e-01,  2.8553009e-01,  1.1481047e-01,\n",
            "       -4.5332909e-01,  7.1609885e-01,  2.6789561e-01, -6.3751185e-01,\n",
            "       -4.7285798e-01, -1.3322408e-01], dtype=float32), 'agent_1': Array([ 5.3924102e-01, -4.4954312e-01, -1.3423735e-01, -8.5410220e-04,\n",
            "        8.8311422e-01, -5.2965003e-01, -5.5183727e-01, -1.2368033e+00,\n",
            "       -5.5463201e-01, -5.4834074e-01,  2.8553009e-01,  1.1481047e-01,\n",
            "       -4.5332909e-01,  7.1609885e-01,  2.6789561e-01, -6.3751185e-01,\n",
            "        1.0071394e+00, -4.0945259e-01], dtype=float32), 'agent_2': Array([ 5.3924102e-01, -4.4954312e-01, -1.3423735e-01, -8.5410220e-04,\n",
            "        8.8311422e-01, -5.2965003e-01, -5.5183727e-01, -5.5463201e-01,\n",
            "       -1.2404213e+00, -5.4834074e-01,  2.8553009e-01,  1.1481047e-01,\n",
            "       -4.5332909e-01,  7.1609885e-01,  2.6789561e-01, -6.3751185e-01,\n",
            "        1.6311977e+00, -5.5314988e-01], dtype=float32), 'agent_3': Array([ 5.3924102e-01, -4.4954312e-01, -1.3423735e-01, -8.5410220e-04,\n",
            "        8.8311422e-01, -5.2965003e-01, -5.5183727e-01, -5.5463201e-01,\n",
            "       -5.4834074e-01,  5.1124597e-01,  2.8553009e-01,  1.1481047e-01,\n",
            "       -4.5332909e-01,  7.1609885e-01,  2.6789561e-01, -6.3751185e-01,\n",
            "        6.6950619e-01, -1.8541351e-01], dtype=float32)}\n",
            "ctrl action chosen: [1.1389788  0.4756414  1.1397829  0.4770146  1.1398747  0.47750452\n",
            " 1.1388817  0.47938263]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7624716, dtype=float32), 'agent_0': Array(0.7624716, dtype=float32), 'agent_1': Array(0.7624716, dtype=float32), 'agent_2': Array(0.7624716, dtype=float32), 'agent_3': Array(0.7624716, dtype=float32)}\n",
            "step: 406\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.53392124,  -0.2152688 ,  -0.10569734,  -0.02264641,\n",
            "         0.9705537 ,   0.03652333,   0.647641  ,   0.08938639,\n",
            "         0.12573549,   0.06975783,   0.7206917 ,  -0.17783642,\n",
            "         0.5391121 ,   0.22717114,  -2.025846  , -13.100331  ,\n",
            "        15.798109  ,   3.4073927 ], dtype=float32), 'agent_1': Array([  0.53392124,  -0.2152688 ,  -0.10569734,  -0.02264641,\n",
            "         0.9705537 ,   0.03652333,   0.08938639,  -1.0948415 ,\n",
            "         0.12573549,   0.06975783,   0.7206917 ,  -0.17783642,\n",
            "         0.5391121 ,   0.22717114,  -2.025846  , -13.100331  ,\n",
            "        16.84589   ,   4.805057  ], dtype=float32), 'agent_2': Array([  0.53392124,  -0.2152688 ,  -0.10569734,  -0.02264641,\n",
            "         0.9705537 ,   0.03652333,   0.08938639,   0.12573549,\n",
            "        -1.1234158 ,   0.06975783,   0.7206917 ,  -0.17783642,\n",
            "         0.5391121 ,   0.22717114,  -2.025846  , -13.100331  ,\n",
            "        17.646482  ,   4.017335  ], dtype=float32), 'agent_3': Array([  0.53392124,  -0.2152688 ,  -0.10569734,  -0.02264641,\n",
            "         0.9705537 ,   0.03652333,   0.08938639,   0.12573549,\n",
            "         0.06975783,   0.61081016,   0.7206917 ,  -0.17783642,\n",
            "         0.5391121 ,   0.22717114,  -2.025846  , -13.100331  ,\n",
            "        16.603733  ,   2.7231936 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.64674366  0.18794057 -0.6480937   0.18958361 -0.64518243  0.1914325\n",
            " -0.64721596  0.18731947]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7418301, dtype=float32), 'agent_0': Array(-1.7418301, dtype=float32), 'agent_1': Array(-1.7418301, dtype=float32), 'agent_2': Array(-1.7418301, dtype=float32), 'agent_3': Array(-1.7418301, dtype=float32)}\n",
            "step: 407\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5298585e-01, -2.5385225e-01, -6.7384966e-02,  5.7310229e-03,\n",
            "        9.6487588e-01, -2.0085828e-02,  7.8553826e-01,  2.5873454e-02,\n",
            "        1.1197289e-01,  1.8992586e-02,  6.8898201e-01, -3.2202005e-01,\n",
            "        2.0443201e-01,  6.8198496e-01, -1.8058699e+00,  5.4690337e+00,\n",
            "       -6.2109885e+00,  3.2051411e+00], dtype=float32), 'agent_1': Array([ 5.5298585e-01, -2.5385225e-01, -6.7384966e-02,  5.7310229e-03,\n",
            "        9.6487588e-01, -2.0085828e-02,  2.5873454e-02, -8.8654602e-01,\n",
            "        1.1197289e-01,  1.8992586e-02,  6.8898201e-01, -3.2202005e-01,\n",
            "        2.0443201e-01,  6.8198496e-01, -1.8058699e+00,  5.4690337e+00,\n",
            "       -6.6310191e+00,  3.8515730e+00], dtype=float32), 'agent_2': Array([ 0.55298585, -0.25385225, -0.06738497,  0.00573102,  0.9648759 ,\n",
            "       -0.02008583,  0.02587345,  0.11197289, -0.9135624 ,  0.01899259,\n",
            "        0.688982  , -0.32202005,  0.20443201,  0.68198496, -1.8058699 ,\n",
            "        5.4690337 , -5.4843183 ,  4.5948224 ], dtype=float32), 'agent_3': Array([ 5.5298585e-01, -2.5385225e-01, -6.7384966e-02,  5.7310229e-03,\n",
            "        9.6487588e-01, -2.0085828e-02,  2.5873454e-02,  1.1197289e-01,\n",
            "        1.8992586e-02,  6.8158108e-01,  6.8898201e-01, -3.2202005e-01,\n",
            "        2.0443201e-01,  6.8198496e-01, -1.8058699e+00,  5.4690337e+00,\n",
            "       -6.4289646e+00,  1.2945437e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.4633479  0.2562139  0.46377942 0.25689778 0.46213335 0.25893092\n",
            " 0.46748823 0.2570873 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.80103683, dtype=float32), 'agent_0': Array(0.80103683, dtype=float32), 'agent_1': Array(0.80103683, dtype=float32), 'agent_2': Array(0.80103683, dtype=float32), 'agent_3': Array(0.80103683, dtype=float32)}\n",
            "step: 408\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5512663 , -0.21729343, -0.0178276 ,  0.03152085,  0.9754344 ,\n",
            "        0.09757449,  1.0004241 ,  0.11244531,  0.25971118,  0.11133984,\n",
            "        0.5914688 , -0.22199154, -0.25732517,  0.5662727 , -2.344514  ,\n",
            "       -3.313976  ,  5.0229874 ,  4.565578  ], dtype=float32), 'agent_1': Array([ 0.5512663 , -0.21729343, -0.0178276 ,  0.03152085,  0.9754344 ,\n",
            "        0.09757449,  0.11244531, -0.65370286,  0.25971118,  0.11133984,\n",
            "        0.5914688 , -0.22199154, -0.25732517,  0.5662727 , -2.344514  ,\n",
            "       -3.313976  ,  4.4369807 ,  5.3537526 ], dtype=float32), 'agent_2': Array([ 0.5512663 , -0.21729343, -0.0178276 ,  0.03152085,  0.9754344 ,\n",
            "        0.09757449,  0.11244531,  0.25971118, -0.6586636 ,  0.11133984,\n",
            "        0.5914688 , -0.22199154, -0.25732517,  0.5662727 , -2.344514  ,\n",
            "       -3.313976  ,  5.6708856 ,  4.9675903 ], dtype=float32), 'agent_3': Array([ 0.5512663 , -0.21729343, -0.0178276 ,  0.03152085,  0.9754344 ,\n",
            "        0.09757449,  0.11244531,  0.25971118,  0.11133984,  0.81781274,\n",
            "        0.5914688 , -0.22199154, -0.25732517,  0.5662727 , -2.344514  ,\n",
            "       -3.313976  ,  4.501886  ,  3.4673078 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.07177384 -0.55038947  0.07026969 -0.5497441   0.07218708 -0.547045\n",
            "  0.07107768 -0.5502721 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0550101, dtype=float32), 'agent_0': Array(1.0550101, dtype=float32), 'agent_1': Array(1.0550101, dtype=float32), 'agent_2': Array(1.0550101, dtype=float32), 'agent_3': Array(1.0550101, dtype=float32)}\n",
            "step: 409\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52711433, -0.1599716 , -0.0050751 ,  0.04355913,  0.98614705,\n",
            "        0.27662194,  0.9623966 ,  0.2658822 ,  0.47297925,  0.27066597,\n",
            "        0.8143425 , -0.02295971, -0.654459  ,  0.24983707,  0.0594156 ,\n",
            "       -1.8799295 ,  2.893287  , -3.0593922 ], dtype=float32), 'agent_1': Array([ 0.52711433, -0.1599716 , -0.0050751 ,  0.04355913,  0.98614705,\n",
            "        0.27662194,  0.2658822 , -0.6412778 ,  0.47297925,  0.27066597,\n",
            "        0.8143425 , -0.02295971, -0.654459  ,  0.24983707,  0.0594156 ,\n",
            "       -1.8799295 ,  2.3958137 , -2.361338  ], dtype=float32), 'agent_2': Array([ 0.52711433, -0.1599716 , -0.0050751 ,  0.04355913,  0.98614705,\n",
            "        0.27662194,  0.2658822 ,  0.47297925, -0.67369807,  0.27066597,\n",
            "        0.8143425 , -0.02295971, -0.654459  ,  0.24983707,  0.0594156 ,\n",
            "       -1.8799295 ,  3.505998  , -2.3904977 ], dtype=float32), 'agent_3': Array([ 0.52711433, -0.1599716 , -0.0050751 ,  0.04355913,  0.98614705,\n",
            "        0.27662194,  0.2658822 ,  0.47297925,  0.27066597,  0.74610645,\n",
            "        0.8143425 , -0.02295971, -0.654459  ,  0.24983707,  0.0594156 ,\n",
            "       -1.8799295 ,  2.6853514 , -3.6259322 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.4599821  -0.0521613   0.45691082 -0.05130223  0.45744374 -0.05064126\n",
            "  0.46025535 -0.0515669 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1294103, dtype=float32), 'agent_0': Array(1.1294103, dtype=float32), 'agent_1': Array(1.1294103, dtype=float32), 'agent_2': Array(1.1294103, dtype=float32), 'agent_3': Array(1.1294103, dtype=float32)}\n",
            "step: 410\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.9073926e-01, -1.0927380e-01,  1.4470253e-04,  5.3532325e-02,\n",
            "        9.9256921e-01,  4.6709368e-01,  8.8172215e-01,  4.3473172e-01,\n",
            "        5.8953208e-01,  4.5484647e-01,  2.4604797e-02,  1.1628866e-01,\n",
            "       -5.3427219e-01, -8.2310311e-02, -2.7937758e-01, -8.2683307e-01,\n",
            "        3.1213334e+00, -1.8601826e+00], dtype=float32), 'agent_1': Array([ 4.9073926e-01, -1.0927380e-01,  1.4470253e-04,  5.3532325e-02,\n",
            "        9.9256921e-01,  4.6709368e-01,  4.3473172e-01, -7.0409566e-01,\n",
            "        5.8953208e-01,  4.5484647e-01,  2.4604797e-02,  1.1628866e-01,\n",
            "       -5.3427219e-01, -8.2310311e-02, -2.7937758e-01, -8.2683307e-01,\n",
            "        2.6224401e+00, -1.2813357e+00], dtype=float32), 'agent_2': Array([ 4.9073926e-01, -1.0927380e-01,  1.4470253e-04,  5.3532325e-02,\n",
            "        9.9256921e-01,  4.6709368e-01,  4.3473172e-01,  5.8953208e-01,\n",
            "       -6.6180933e-01,  4.5484647e-01,  2.4604797e-02,  1.1628866e-01,\n",
            "       -5.3427219e-01, -8.2310311e-02, -2.7937758e-01, -8.2683307e-01,\n",
            "        2.1914913e-01,  1.4092515e+00], dtype=float32), 'agent_3': Array([ 4.9073926e-01, -1.0927380e-01,  1.4470253e-04,  5.3532325e-02,\n",
            "        9.9256921e-01,  4.6709368e-01,  4.3473172e-01,  5.8953208e-01,\n",
            "        4.5484647e-01,  6.3968122e-01,  2.4604797e-02,  1.1628866e-01,\n",
            "       -5.3427219e-01, -8.2310311e-02, -2.7937758e-01, -8.2683307e-01,\n",
            "        2.8990850e+00, -1.9903663e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.27464995 0.34725028 0.27224314 0.3475426  0.26924664 0.35149634\n",
            " 0.2741846  0.34813398]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0702406, dtype=float32), 'agent_0': Array(1.0702406, dtype=float32), 'agent_1': Array(1.0702406, dtype=float32), 'agent_2': Array(1.0702406, dtype=float32), 'agent_3': Array(1.0702406, dtype=float32)}\n",
            "step: 411\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.46412915, -0.11621363,  0.02663184,  0.05387338,  0.99140453,\n",
            "        0.5523814 ,  0.87627345,  0.521792  ,  0.51357865,  0.5361557 ,\n",
            "       -0.4044056 , -0.21598339, -0.669235  , -0.04051885, -1.4351434 ,\n",
            "        1.0342985 ,  0.28150675,  1.0266383 ], dtype=float32), 'agent_1': Array([ 0.46412915, -0.11621363,  0.02663184,  0.05387338,  0.99140453,\n",
            "        0.5523814 ,  0.521792  , -0.649553  ,  0.51357865,  0.5361557 ,\n",
            "       -0.4044056 , -0.21598339, -0.669235  , -0.04051885, -1.4351434 ,\n",
            "        1.0342985 ,  1.4433473 ,  2.254837  ], dtype=float32), 'agent_2': Array([ 0.46412915, -0.11621363,  0.02663184,  0.05387338,  0.99140453,\n",
            "        0.5523814 ,  0.521792  ,  0.51357865, -0.488271  ,  0.5361557 ,\n",
            "       -0.4044056 , -0.21598339, -0.669235  , -0.04051885, -1.4351434 ,\n",
            "        1.0342985 , -2.1727538 ,  2.1950195 ], dtype=float32), 'agent_3': Array([ 0.46412915, -0.11621363,  0.02663184,  0.05387338,  0.99140453,\n",
            "        0.5523814 ,  0.521792  ,  0.51357865,  0.5361557 ,  0.687192  ,\n",
            "       -0.4044056 , -0.21598339, -0.669235  , -0.04051885, -1.4351434 ,\n",
            "        1.0342985 ,  0.605617  ,  2.5354018 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.32013702 -1.2145569   0.3198713  -1.2127249   0.31820053 -1.2200679\n",
            "  0.31832322 -1.215304  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.2635075, dtype=float32), 'agent_0': Array(0.2635075, dtype=float32), 'agent_1': Array(0.2635075, dtype=float32), 'agent_2': Array(0.2635075, dtype=float32), 'agent_3': Array(0.2635075, dtype=float32)}\n",
            "step: 412\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.4529134e-01, -1.5089893e-01,  5.0947191e-03,  1.5327909e-02,\n",
            "        9.8841721e-01,  5.2892631e-01,  5.6781137e-01,  5.3736371e-01,\n",
            "        4.0333402e-01,  5.4428864e-01,  3.8795471e-01, -3.3508539e-01,\n",
            "       -1.2956262e-01, -1.5963498e+00,  2.1551096e+00,  9.0404618e-01,\n",
            "       -5.9530693e-01, -8.6725035e+00], dtype=float32), 'agent_1': Array([ 4.4529134e-01, -1.5089893e-01,  5.0947191e-03,  1.5327909e-02,\n",
            "        9.8841721e-01,  5.2892631e-01,  5.3736371e-01, -8.3944440e-01,\n",
            "        4.0333402e-01,  5.4428864e-01,  3.8795471e-01, -3.3508539e-01,\n",
            "       -1.2956262e-01, -1.5963498e+00,  2.1551096e+00,  9.0404618e-01,\n",
            "       -1.4129256e-01, -5.2415714e+00], dtype=float32), 'agent_2': Array([ 4.4529134e-01, -1.5089893e-01,  5.0947191e-03,  1.5327909e-02,\n",
            "        9.8841721e-01,  5.2892631e-01,  5.3736371e-01,  4.0333402e-01,\n",
            "       -6.9672281e-01,  5.4428864e-01,  3.8795471e-01, -3.3508539e-01,\n",
            "       -1.2956262e-01, -1.5963498e+00,  2.1551096e+00,  9.0404618e-01,\n",
            "       -1.1828861e+00, -6.0781550e+00], dtype=float32), 'agent_3': Array([ 0.44529134, -0.15089893,  0.00509472,  0.01532791,  0.9884172 ,\n",
            "        0.5289263 ,  0.5373637 ,  0.40333402,  0.54428864,  0.46355492,\n",
            "        0.3879547 , -0.3350854 , -0.12956262, -1.5963498 ,  2.1551096 ,\n",
            "        0.9040462 ,  0.3416254 , -3.7201571 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.97041684 -0.9705056   0.96472096 -0.96510416  0.9658758  -0.966917\n",
            "  0.96501535 -0.9646193 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.1466708, dtype=float32), 'agent_0': Array(-2.1466708, dtype=float32), 'agent_1': Array(-2.1466708, dtype=float32), 'agent_2': Array(-2.1466708, dtype=float32), 'agent_3': Array(-2.1466708, dtype=float32)}\n",
            "step: 413\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.47495562, -0.1442745 , -0.02898484, -0.02000934,  0.9889107 ,\n",
            "        0.55415744,  0.45738208,  0.5340361 ,  0.53775984,  0.5649713 ,\n",
            "        1.0989189 , -0.5392909 ,  1.5432537 , -0.951773  ,  1.9625039 ,\n",
            "        0.37495342, -0.23087376, -0.02258369], dtype=float32), 'agent_1': Array([ 0.47495562, -0.1442745 , -0.02898484, -0.02000934,  0.9889107 ,\n",
            "        0.55415744,  0.5340361 , -1.0233284 ,  0.53775984,  0.5649713 ,\n",
            "        1.0989189 , -0.5392909 ,  1.5432537 , -0.951773  ,  1.9625039 ,\n",
            "        0.37495342, -1.1493285 , -2.8374014 ], dtype=float32), 'agent_2': Array([ 0.47495562, -0.1442745 , -0.02898484, -0.02000934,  0.9889107 ,\n",
            "        0.55415744,  0.5340361 ,  0.53775984, -1.0117619 ,  0.5649713 ,\n",
            "        1.0989189 , -0.5392909 ,  1.5432537 , -0.951773  ,  1.9625039 ,\n",
            "        0.37495342,  2.8767095 , -5.610089  ], dtype=float32), 'agent_3': Array([ 0.47495562, -0.1442745 , -0.02898484, -0.02000934,  0.9889107 ,\n",
            "        0.55415744,  0.5340361 ,  0.53775984,  0.5649713 ,  0.45824927,\n",
            "        1.0989189 , -0.5392909 ,  1.5432537 , -0.951773  ,  1.9625039 ,\n",
            "        0.37495342, -0.8401961 , -0.05463346], dtype=float32)}\n",
            "ctrl action chosen: [-1.9099059 -1.6964849 -1.911435  -1.6997285 -1.9084442 -1.70193\n",
            " -1.9096985 -1.6979766]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0463371, dtype=float32), 'agent_0': Array(-2.0463371, dtype=float32), 'agent_1': Array(-2.0463371, dtype=float32), 'agent_2': Array(-2.0463371, dtype=float32), 'agent_3': Array(-2.0463371, dtype=float32)}\n",
            "step: 414\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.56615615,  -0.38183662,  -0.0965255 ,  -0.03151852,\n",
            "         0.9186351 ,  -0.04425356,   0.478036  ,  -0.13717473,\n",
            "         0.11273183,  -0.07223389,   1.2600422 ,  -0.6335616 ,\n",
            "         1.7519355 ,   0.6804199 ,   2.12736   ,  13.250653  ,\n",
            "       -16.442421  ,   0.9528972 ], dtype=float32), 'agent_1': Array([  0.56615615,  -0.38183662,  -0.0965255 ,  -0.03151852,\n",
            "         0.9186351 ,  -0.04425356,  -0.13717473,  -1.2955482 ,\n",
            "         0.11273183,  -0.07223389,   1.2600422 ,  -0.6335616 ,\n",
            "         1.7519355 ,   0.6804199 ,   2.12736   ,  13.250653  ,\n",
            "       -17.580193  ,  -2.948828  ], dtype=float32), 'agent_2': Array([  0.56615615,  -0.38183662,  -0.0965255 ,  -0.03151852,\n",
            "         0.9186351 ,  -0.04425356,  -0.13717473,   0.11273183,\n",
            "        -1.3095804 ,  -0.07223389,   1.2600422 ,  -0.6335616 ,\n",
            "         1.7519355 ,   0.6804199 ,   2.12736   ,  13.250653  ,\n",
            "       -12.512542  ,  -1.286153  ], dtype=float32), 'agent_3': Array([  0.56615615,  -0.38183662,  -0.0965255 ,  -0.03151852,\n",
            "         0.9186351 ,  -0.04425356,  -0.13717473,   0.11273183,\n",
            "        -0.07223389,   0.4895418 ,   1.2600422 ,  -0.6335616 ,\n",
            "         1.7519355 ,   0.6804199 ,   2.12736   ,  13.250653  ,\n",
            "       -17.134031  ,   0.65123767], dtype=float32)}\n",
            "ctrl action chosen: [0.67035085 0.81915104 0.67703176 0.81475955 0.6688949  0.8249248\n",
            " 0.67158216 0.81987315]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.810619, dtype=float32), 'agent_0': Array(-10.810619, dtype=float32), 'agent_1': Array(-10.810619, dtype=float32), 'agent_2': Array(-10.810619, dtype=float32), 'agent_3': Array(-10.810619, dtype=float32)}\n",
            "step: 415\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6185765 , -0.3688894 , -0.10122479, -0.0267424 ,  0.9235579 ,\n",
            "       -0.01917727,  0.87550306, -0.15146412,  0.28203815, -0.07664245,\n",
            "        0.7911205 , -0.7011056 ,  0.5380869 ,  0.0192027 , -0.01782172,\n",
            "       -4.77184   ,  6.24091   , 10.480673  ], dtype=float32), 'agent_1': Array([ 0.6185765 , -0.3688894 , -0.10122479, -0.0267424 ,  0.9235579 ,\n",
            "       -0.01917727, -0.15146412, -1.1649895 ,  0.28203815, -0.07664245,\n",
            "        0.7911205 , -0.7011056 ,  0.5380869 ,  0.0192027 , -0.01782172,\n",
            "       -4.77184   ,  5.5565724 ,  3.1906643 ], dtype=float32), 'agent_2': Array([ 0.6185765 , -0.3688894 , -0.10122479, -0.0267424 ,  0.9235579 ,\n",
            "       -0.01917727, -0.15146412,  0.28203815, -1.1572691 , -0.07664245,\n",
            "        0.7911205 , -0.7011056 ,  0.5380869 ,  0.0192027 , -0.01782172,\n",
            "       -4.77184   ,  8.39873   ,  3.6942034 ], dtype=float32), 'agent_3': Array([ 0.6185765 , -0.3688894 , -0.10122479, -0.0267424 ,  0.9235579 ,\n",
            "       -0.01917727, -0.15146412,  0.28203815, -0.07664245,  0.86192405,\n",
            "        0.7911205 , -0.7011056 ,  0.5380869 ,  0.0192027 , -0.01782172,\n",
            "       -4.77184   ,  5.521021  ,  8.924975  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.44828054 -0.21409723  0.4483639  -0.21779802  0.45183644 -0.21144772\n",
            "  0.44817245 -0.21146841]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.35159802, dtype=float32), 'agent_0': Array(-0.35159802, dtype=float32), 'agent_1': Array(-0.35159802, dtype=float32), 'agent_2': Array(-0.35159802, dtype=float32), 'agent_3': Array(-0.35159802, dtype=float32)}\n",
            "step: 416\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6790462 , -0.25511912, -0.11053   , -0.04362031,  0.9595805 ,\n",
            "        0.3341581 ,  1.0540543 ,  0.15744911,  0.62044036,  0.21828614,\n",
            "        0.09794235, -1.1887908 ,  1.7111421 ,  0.14004229,  0.46610528,\n",
            "       -1.735654  ,  4.4329715 ,  0.8036377 ], dtype=float32), 'agent_1': Array([ 0.6790462 , -0.25511912, -0.11053   , -0.04362031,  0.9595805 ,\n",
            "        0.3341581 ,  0.15744911, -1.0524621 ,  0.62044036,  0.21828614,\n",
            "        0.09794235, -1.1887908 ,  1.7111421 ,  0.14004229,  0.46610528,\n",
            "       -1.735654  ,  3.3798244 ,  2.7121904 ], dtype=float32), 'agent_2': Array([ 0.6790462 , -0.25511912, -0.11053   , -0.04362031,  0.9595805 ,\n",
            "        0.3341581 ,  0.15744911,  0.62044036, -1.0256475 ,  0.21828614,\n",
            "        0.09794235, -1.1887908 ,  1.7111421 ,  0.14004229,  0.46610528,\n",
            "       -1.735654  ,  0.04651641,  3.0165703 ], dtype=float32), 'agent_3': Array([ 0.6790462 , -0.25511912, -0.11053   , -0.04362031,  0.9595805 ,\n",
            "        0.3341581 ,  0.15744911,  0.62044036,  0.21828614,  0.9532959 ,\n",
            "        0.09794235, -1.1887908 ,  1.7111421 ,  0.14004229,  0.46610528,\n",
            "       -1.735654  ,  3.1553106 , -1.2442459 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.8610709 -1.2186196 -2.8630252 -1.2180761 -2.8643115 -1.2189618\n",
            " -2.8653224 -1.21988  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0617319, dtype=float32), 'agent_0': Array(1.0617319, dtype=float32), 'agent_1': Array(1.0617319, dtype=float32), 'agent_2': Array(1.0617319, dtype=float32), 'agent_3': Array(1.0617319, dtype=float32)}\n",
            "step: 417\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.4537641e-01, -4.6629992e-01, -1.6218109e-01, -3.1177161e-02,\n",
            "        8.6907405e-01, -1.5790343e-01,  8.1502926e-01, -3.6598191e-01,\n",
            "        6.2933578e-03, -3.1384191e-01,  2.7189255e-01, -9.6504688e-01,\n",
            "        1.0271430e+00,  2.1875320e-01,  2.7635415e+00,  1.2993196e+01,\n",
            "       -1.4746056e+01, -7.9090066e+00], dtype=float32), 'agent_1': Array([ 7.4537641e-01, -4.6629992e-01, -1.6218109e-01, -3.1177161e-02,\n",
            "        8.6907405e-01, -1.5790343e-01, -3.6598191e-01, -1.2317088e+00,\n",
            "        6.2933578e-03, -3.1384191e-01,  2.7189255e-01, -9.6504688e-01,\n",
            "        1.0271430e+00,  2.1875320e-01,  2.7635415e+00,  1.2993196e+01,\n",
            "       -1.5011672e+01, -5.9629869e+00], dtype=float32), 'agent_2': Array([ 7.4537641e-01, -4.6629992e-01, -1.6218109e-01, -3.1177161e-02,\n",
            "        8.6907405e-01, -1.5790343e-01, -3.6598191e-01,  6.2933578e-03,\n",
            "       -1.2152352e+00, -3.1384191e-01,  2.7189255e-01, -9.6504688e-01,\n",
            "        1.0271430e+00,  2.1875320e-01,  2.7635415e+00,  1.2993196e+01,\n",
            "       -1.7908937e+01, -7.4906259e+00], dtype=float32), 'agent_3': Array([ 7.4537641e-01, -4.6629992e-01, -1.6218109e-01, -3.1177161e-02,\n",
            "        8.6907405e-01, -1.5790343e-01, -3.6598191e-01,  6.2933578e-03,\n",
            "       -3.1384191e-01,  6.5326256e-01,  2.7189255e-01, -9.6504688e-01,\n",
            "        1.0271430e+00,  2.1875320e-01,  2.7635415e+00,  1.2993196e+01,\n",
            "       -1.5260164e+01, -8.0132303e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.3370868  -0.45066866 -1.3345002  -0.4483102  -1.3337742  -0.4547698\n",
            " -1.3360486  -0.44672418]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-18.18663, dtype=float32), 'agent_0': Array(-18.18663, dtype=float32), 'agent_1': Array(-18.18663, dtype=float32), 'agent_2': Array(-18.18663, dtype=float32), 'agent_3': Array(-18.18663, dtype=float32)}\n",
            "step: 418\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.77310795, -0.5885082 , -0.19725566, -0.02031022,  0.7837959 ,\n",
            "       -0.5433102 ,  0.4777635 , -0.59454304, -0.5345299 , -0.5932108 ,\n",
            "        0.13766289, -0.9435415 ,  0.10530949, -0.2690971 ,  0.9520456 ,\n",
            "        0.2955744 , -0.4919678 , -4.080027  ], dtype=float32), 'agent_1': Array([ 0.77310795, -0.5885082 , -0.19725566, -0.02031022,  0.7837959 ,\n",
            "       -0.5433102 , -0.59454304, -1.2618164 , -0.5345299 , -0.5932108 ,\n",
            "        0.13766289, -0.9435415 ,  0.10530949, -0.2690971 ,  0.9520456 ,\n",
            "        0.2955744 ,  2.9424174 , -0.28364587], dtype=float32), 'agent_2': Array([ 0.77310795, -0.5885082 , -0.19725566, -0.02031022,  0.7837959 ,\n",
            "       -0.5433102 , -0.59454304, -0.5345299 , -1.2668138 , -0.5932108 ,\n",
            "        0.13766289, -0.9435415 ,  0.10530949, -0.2690971 ,  0.9520456 ,\n",
            "        0.2955744 , -4.806151  , -0.24847023], dtype=float32), 'agent_3': Array([ 0.77310795, -0.5885082 , -0.19725566, -0.02031022,  0.7837959 ,\n",
            "       -0.5433102 , -0.59454304, -0.5345299 , -0.5932108 ,  0.46832728,\n",
            "        0.13766289, -0.9435415 ,  0.10530949, -0.2690971 ,  0.9520456 ,\n",
            "        0.2955744 ,  1.8444887 ,  0.3591608 ], dtype=float32)}\n",
            "ctrl action chosen: [1.1733674 2.2985806 1.174263  2.3042107 1.1736175 2.2990503 1.1732987\n",
            " 2.309207 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8159416, dtype=float32), 'agent_0': Array(-2.8159416, dtype=float32), 'agent_1': Array(-2.8159416, dtype=float32), 'agent_2': Array(-2.8159416, dtype=float32), 'agent_3': Array(-2.8159416, dtype=float32)}\n",
            "step: 419\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.82960176e-01, -3.94832492e-01, -1.54926181e-01, -6.24525063e-02,\n",
            "        9.03440595e-01, -1.97548093e-03,  6.35945678e-01,  1.93953633e-01,\n",
            "       -1.79593310e-01,  1.09327964e-01, -1.82056427e-01, -1.32277012e+00,\n",
            "        2.33900547e-01, -4.76473212e-01, -2.10223675e+00, -1.35357485e+01,\n",
            "        1.56562080e+01,  4.72368050e+00], dtype=float32), 'agent_1': Array([ 7.82960176e-01, -3.94832492e-01, -1.54926181e-01, -6.24525063e-02,\n",
            "        9.03440595e-01, -1.97548093e-03,  1.93953633e-01, -9.68163371e-01,\n",
            "       -1.79593310e-01,  1.09327964e-01, -1.82056427e-01, -1.32277012e+00,\n",
            "        2.33900547e-01, -4.76473212e-01, -2.10223675e+00, -1.35357485e+01,\n",
            "        2.13285351e+01,  9.30080414e+00], dtype=float32), 'agent_2': Array([ 7.82960176e-01, -3.94832492e-01, -1.54926181e-01, -6.24525063e-02,\n",
            "        9.03440595e-01, -1.97548093e-03,  1.93953633e-01, -1.79593310e-01,\n",
            "       -9.90599096e-01,  1.09327964e-01, -1.82056427e-01, -1.32277012e+00,\n",
            "        2.33900547e-01, -4.76473212e-01, -2.10223675e+00, -1.35357485e+01,\n",
            "        1.22207346e+01,  9.27352142e+00], dtype=float32), 'agent_3': Array([ 7.82960176e-01, -3.94832492e-01, -1.54926181e-01, -6.24525063e-02,\n",
            "        9.03440595e-01, -1.97548093e-03,  1.93953633e-01, -1.79593310e-01,\n",
            "        1.09327964e-01,  6.90631628e-01, -1.82056427e-01, -1.32277012e+00,\n",
            "        2.33900547e-01, -4.76473212e-01, -2.10223675e+00, -1.35357485e+01,\n",
            "        1.95849438e+01,  7.36010313e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.710307   -0.4597036  -0.70452935 -0.45182985 -0.7116756  -0.45652798\n",
            " -0.7075183  -0.45461047]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.4078, dtype=float32), 'agent_0': Array(-12.4078, dtype=float32), 'agent_1': Array(-12.4078, dtype=float32), 'agent_2': Array(-12.4078, dtype=float32), 'agent_3': Array(-12.4078, dtype=float32)}\n",
            "step: 420\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.77358806, -0.43440405, -0.14988333, -0.05893156,  0.88620275,\n",
            "       -0.11028064,  0.65694654,  0.25727516, -0.42280465,  0.12763213,\n",
            "        0.15711784, -0.98364353, -0.5019784 , -0.13326609,  0.36349547,\n",
            "        6.4088445 , -8.341951  , -0.14129649], dtype=float32), 'agent_1': Array([ 0.77358806, -0.43440405, -0.14988333, -0.05893156,  0.88620275,\n",
            "       -0.11028064,  0.25727516, -0.8180106 , -0.42280465,  0.12763213,\n",
            "        0.15711784, -0.98364353, -0.5019784 , -0.13326609,  0.36349547,\n",
            "        6.4088445 , -5.4197807 ,  0.46022648], dtype=float32), 'agent_2': Array([  0.77358806,  -0.43440405,  -0.14988333,  -0.05893156,\n",
            "         0.88620275,  -0.11028064,   0.25727516,  -0.42280465,\n",
            "        -0.8083624 ,   0.12763213,   0.15711784,  -0.98364353,\n",
            "        -0.5019784 ,  -0.13326609,   0.36349547,   6.4088445 ,\n",
            "       -10.35725   ,   1.711828  ], dtype=float32), 'agent_3': Array([ 0.77358806, -0.43440405, -0.14988333, -0.05893156,  0.88620275,\n",
            "       -0.11028064,  0.25727516, -0.42280465,  0.12763213,  0.82364863,\n",
            "        0.15711784, -0.98364353, -0.5019784 , -0.13326609,  0.36349547,\n",
            "        6.4088445 , -5.827561  ,  1.0910428 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5591012  -0.45352995 -0.55997026 -0.44735295 -0.5584223  -0.45401517\n",
            " -0.56069887 -0.44549116]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.37209535, dtype=float32), 'agent_0': Array(-0.37209535, dtype=float32), 'agent_1': Array(-0.37209535, dtype=float32), 'agent_2': Array(-0.37209535, dtype=float32), 'agent_3': Array(-0.37209535, dtype=float32)}\n",
            "step: 421\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.74119467, -0.52796537, -0.17539647, -0.05181909,  0.8293392 ,\n",
            "       -0.46919295,  0.56529135,  0.03422997, -0.63538533, -0.09995382,\n",
            "        0.8299351 , -1.1363745 , -0.7139206 ,  0.3467409 ,  1.6816802 ,\n",
            "        2.3044586 , -5.2404003 , -3.820255  ], dtype=float32), 'agent_1': Array([ 0.74119467, -0.52796537, -0.17539647, -0.05181909,  0.8293392 ,\n",
            "       -0.46919295,  0.03422997, -0.88259965, -0.63538533, -0.09995382,\n",
            "        0.8299351 , -1.1363745 , -0.7139206 ,  0.3467409 ,  1.6816802 ,\n",
            "        2.3044586 , -2.9060504 , -3.1410449 ], dtype=float32), 'agent_2': Array([ 0.74119467, -0.52796537, -0.17539647, -0.05181909,  0.8293392 ,\n",
            "       -0.46919295,  0.03422997, -0.63538533, -0.83271426, -0.09995382,\n",
            "        0.8299351 , -1.1363745 , -0.7139206 ,  0.3467409 ,  1.6816802 ,\n",
            "        2.3044586 ,  1.3429419 , -3.2261338 ], dtype=float32), 'agent_3': Array([ 0.74119467, -0.52796537, -0.17539647, -0.05181909,  0.8293392 ,\n",
            "       -0.46919295,  0.03422997, -0.63538533, -0.09995382,  0.76157504,\n",
            "        0.8299351 , -1.1363745 , -0.7139206 ,  0.3467409 ,  1.6816802 ,\n",
            "        2.3044586 , -2.9028046 , -3.668928  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7140212  -0.88639647 -0.717759   -0.8808316  -0.71919864 -0.8774621\n",
            " -0.71707076 -0.8775701 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.39139473, dtype=float32), 'agent_0': Array(0.39139473, dtype=float32), 'agent_1': Array(0.39139473, dtype=float32), 'agent_2': Array(0.39139473, dtype=float32), 'agent_3': Array(0.39139473, dtype=float32)}\n",
            "step: 422\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6925189 , -0.5599497 , -0.25074768, -0.0556451 ,  0.78770906,\n",
            "       -0.6120572 ,  0.4470726 , -0.18162197, -0.49391237, -0.3074144 ,\n",
            "        0.7624626 , -0.82325935, -1.1471152 ,  0.9123685 ,  2.3021586 ,\n",
            "        2.3842254 , -1.1216354 ,  0.26806492], dtype=float32), 'agent_1': Array([ 0.6925189 , -0.5599497 , -0.25074768, -0.0556451 ,  0.78770906,\n",
            "       -0.6120572 , -0.18162197, -1.2888786 , -0.49391237, -0.3074144 ,\n",
            "        0.7624626 , -0.82325935, -1.1471152 ,  0.9123685 ,  2.3021586 ,\n",
            "        2.3842254 , -5.876299  , -6.661828  ], dtype=float32), 'agent_2': Array([ 0.6925189 , -0.5599497 , -0.25074768, -0.0556451 ,  0.78770906,\n",
            "       -0.6120572 , -0.18162197, -0.49391237, -1.2407504 , -0.3074144 ,\n",
            "        0.7624626 , -0.82325935, -1.1471152 ,  0.9123685 ,  2.3021586 ,\n",
            "        2.3842254 ,  2.2071645 , -8.74097   ], dtype=float32), 'agent_3': Array([ 0.6925189 , -0.5599497 , -0.25074768, -0.0556451 ,  0.78770906,\n",
            "       -0.6120572 , -0.18162197, -0.49391237, -0.3074144 ,  0.42959633,\n",
            "        0.7624626 , -0.82325935, -1.1471152 ,  0.9123685 ,  2.3021586 ,\n",
            "        2.3842254 , -5.6405144 , -1.6341596 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.4534938   0.28808266 -1.4508097   0.27318686 -1.4506816   0.27670598\n",
            " -1.4516348   0.28023893]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.57437897, dtype=float32), 'agent_0': Array(-0.57437897, dtype=float32), 'agent_1': Array(-0.57437897, dtype=float32), 'agent_2': Array(-0.57437897, dtype=float32), 'agent_3': Array(-0.57437897, dtype=float32)}\n",
            "step: 423\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6567192 , -0.6235212 , -0.23043175, -0.04742165,  0.7455694 ,\n",
            "       -0.5506235 ,  0.6167375 , -0.5608177 , -0.5100396 , -0.60509425,\n",
            "       -0.55031776, -1.3343096 , -0.7869959 , -0.34258276, -0.5858531 ,\n",
            "        0.45294857,  4.62283   ,  5.0667286 ], dtype=float32), 'agent_1': Array([ 0.6567192 , -0.6235212 , -0.23043175, -0.04742165,  0.7455694 ,\n",
            "       -0.5506235 , -0.5608177 , -1.1577885 , -0.5100396 , -0.60509425,\n",
            "       -0.55031776, -1.3343096 , -0.7869959 , -0.34258276, -0.5858531 ,\n",
            "        0.45294857, -4.5234303 ,  2.5445664 ], dtype=float32), 'agent_2': Array([ 0.6567192 , -0.6235212 , -0.23043175, -0.04742165,  0.7455694 ,\n",
            "       -0.5506235 , -0.5608177 , -0.5100396 , -1.2082322 , -0.60509425,\n",
            "       -0.55031776, -1.3343096 , -0.7869959 , -0.34258276, -0.5858531 ,\n",
            "        0.45294857,  0.34062555,  0.25989053], dtype=float32), 'agent_3': Array([ 0.6567192 , -0.6235212 , -0.23043175, -0.04742165,  0.7455694 ,\n",
            "       -0.5506235 , -0.5608177 , -0.5100396 , -0.60509425,  0.5595147 ,\n",
            "       -0.55031776, -1.3343096 , -0.7869959 , -0.34258276, -0.5858531 ,\n",
            "        0.45294857, -0.90466523,  1.92151   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9095957  -0.34001544 -0.9155901  -0.35267574 -0.91317946 -0.34466556\n",
            " -0.9135898  -0.34381104]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6261954, dtype=float32), 'agent_0': Array(-3.6261954, dtype=float32), 'agent_1': Array(-3.6261954, dtype=float32), 'agent_2': Array(-3.6261954, dtype=float32), 'agent_3': Array(-3.6261954, dtype=float32)}\n",
            "step: 424\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6367507 , -0.60754186, -0.21977645, -0.05231376,  0.76148176,\n",
            "       -0.32384506,  0.7038245 , -0.5928672 , -0.5144125 , -0.5779407 ,\n",
            "       -0.35185814, -0.4446745 ,  0.16664267, -0.44783112, -0.40611592,\n",
            "       -1.2791142 ,  3.437141  , -0.2713951 ], dtype=float32), 'agent_1': Array([ 0.6367507 , -0.60754186, -0.21977645, -0.05231376,  0.76148176,\n",
            "       -0.32384506, -0.5928672 , -1.1856989 , -0.5144125 , -0.5779407 ,\n",
            "       -0.35185814, -0.4446745 ,  0.16664267, -0.44783112, -0.40611592,\n",
            "       -1.2791142 ,  0.9919211 , -1.0859146 ], dtype=float32), 'agent_2': Array([ 0.6367507 , -0.60754186, -0.21977645, -0.05231376,  0.76148176,\n",
            "       -0.32384506, -0.5928672 , -0.5144125 , -1.2345912 , -0.5779407 ,\n",
            "       -0.35185814, -0.4446745 ,  0.16664267, -0.44783112, -0.40611592,\n",
            "       -1.2791142 , -0.90792006,  0.5447159 ], dtype=float32), 'agent_3': Array([ 0.6367507 , -0.60754186, -0.21977645, -0.05231376,  0.76148176,\n",
            "       -0.32384506, -0.5928672 , -0.5144125 , -0.5779407 ,  0.51569635,\n",
            "       -0.35185814, -0.4446745 ,  0.16664267, -0.44783112, -0.40611592,\n",
            "       -1.2791142 ,  0.85281456, -1.1245785 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.21149819 -0.63896275  0.20708552 -0.63945806  0.20760167 -0.635337\n",
            "  0.206351   -0.6382119 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3757823, dtype=float32), 'agent_0': Array(-1.3757823, dtype=float32), 'agent_1': Array(-1.3757823, dtype=float32), 'agent_2': Array(-1.3757823, dtype=float32), 'agent_3': Array(-1.3757823, dtype=float32)}\n",
            "step: 425\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6369877 , -0.53920597, -0.20366184, -0.08664896,  0.8125705 ,\n",
            "       -0.04584725,  0.5150138 , -0.3729234 , -0.409831  , -0.38093424,\n",
            "       -0.31728745, -0.3849268 , -0.24923086, -1.108138  , -0.05102099,\n",
            "       -3.6023219 ,  4.9775825 , -5.125724  ], dtype=float32), 'agent_1': Array([ 0.6369877 , -0.53920597, -0.20366184, -0.08664896,  0.8125705 ,\n",
            "       -0.04584725, -0.3729234 , -1.2529937 , -0.409831  , -0.38093424,\n",
            "       -0.31728745, -0.3849268 , -0.24923086, -1.108138  , -0.05102099,\n",
            "       -3.6023219 ,  4.9802647 ,  0.01754619], dtype=float32), 'agent_2': Array([ 0.6369877 , -0.53920597, -0.20366184, -0.08664896,  0.8125705 ,\n",
            "       -0.04584725, -0.3729234 , -0.409831  , -1.2522807 , -0.38093424,\n",
            "       -0.31728745, -0.3849268 , -0.24923086, -1.108138  , -0.05102099,\n",
            "       -3.6023219 ,  1.9072998 ,  0.06128635], dtype=float32), 'agent_3': Array([ 0.6369877 , -0.53920597, -0.20366184, -0.08664896,  0.8125705 ,\n",
            "       -0.04584725, -0.3729234 , -0.409831  , -0.38093424,  0.49251768,\n",
            "       -0.31728745, -0.3849268 , -0.24923086, -1.108138  , -0.05102099,\n",
            "       -3.6023219 ,  4.5855927 , -0.00903765], dtype=float32)}\n",
            "ctrl action chosen: [0.43772656 1.230255   0.43236688 1.2400031  0.4302048  1.2417909\n",
            " 0.4325216  1.2418709 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.15590549, dtype=float32), 'agent_0': Array(-0.15590549, dtype=float32), 'agent_1': Array(-0.15590549, dtype=float32), 'agent_2': Array(-0.15590549, dtype=float32), 'agent_3': Array(-0.15590549, dtype=float32)}\n",
            "step: 426\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6087799 , -0.42283204, -0.13095763, -0.10492111,  0.8905362 ,\n",
            "        0.3415447 ,  0.67124665,  0.01226492, -0.16397919, -0.02123817,\n",
            "       -0.45313835, -0.7182598 , -0.6914139 , -0.57598174, -2.9459472 ,\n",
            "       -6.4885926 ,  8.441784  ,  5.047826  ], dtype=float32), 'agent_1': Array([ 0.6087799 , -0.42283204, -0.13095763, -0.10492111,  0.8905362 ,\n",
            "        0.3415447 ,  0.01226492, -0.987591  , -0.16397919, -0.02123817,\n",
            "       -0.45313835, -0.7182598 , -0.6914139 , -0.57598174, -2.9459472 ,\n",
            "       -6.4885926 ,  8.63318   ,  7.531638  ], dtype=float32), 'agent_2': Array([ 0.6087799 , -0.42283204, -0.13095763, -0.10492111,  0.8905362 ,\n",
            "        0.3415447 ,  0.01226492, -0.16397919, -0.9232863 , -0.02123817,\n",
            "       -0.45313835, -0.7182598 , -0.6914139 , -0.57598174, -2.9459472 ,\n",
            "       -6.4885926 ,  5.797967  ,  9.706586  ], dtype=float32), 'agent_3': Array([ 0.6087799 , -0.42283204, -0.13095763, -0.10492111,  0.8905362 ,\n",
            "        0.3415447 ,  0.01226492, -0.16397919, -0.02123817,  0.7914047 ,\n",
            "       -0.45313835, -0.7182598 , -0.6914139 , -0.57598174, -2.9459472 ,\n",
            "       -6.4885926 ,  7.8893647 ,  8.31387   ], dtype=float32)}\n",
            "ctrl action chosen: [0.77013135 0.49498945 0.76992375 0.4979351  0.76294416 0.49920997\n",
            " 0.7670599  0.49864584]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8436556, dtype=float32), 'agent_0': Array(-2.8436556, dtype=float32), 'agent_1': Array(-2.8436556, dtype=float32), 'agent_2': Array(-2.8436556, dtype=float32), 'agent_3': Array(-2.8436556, dtype=float32)}\n",
            "step: 427\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6034826 , -0.28991932, -0.04302778, -0.09140008,  0.9517045 ,\n",
            "        0.6582805 ,  0.80956024,  0.45121294,  0.19219238,  0.376362  ,\n",
            "        0.42967796, -0.5340576 ,  0.3974676 ,  0.954235  , -3.545144  ,\n",
            "       -2.4550064 ,  0.09348311,  2.5630958 ], dtype=float32), 'agent_1': Array([ 0.6034826 , -0.28991932, -0.04302778, -0.09140008,  0.9517045 ,\n",
            "        0.6582805 ,  0.45121294, -0.59585404,  0.19219238,  0.376362  ,\n",
            "        0.42967796, -0.5340576 ,  0.3974676 ,  0.954235  , -3.545144  ,\n",
            "       -2.4550064 ,  5.005619  ,  9.147167  ], dtype=float32), 'agent_2': Array([ 0.6034826 , -0.28991932, -0.04302778, -0.09140008,  0.9517045 ,\n",
            "        0.6582805 ,  0.45121294,  0.19219238, -0.47822887,  0.376362  ,\n",
            "        0.42967796, -0.5340576 ,  0.3974676 ,  0.954235  , -3.545144  ,\n",
            "       -2.4550064 ,  4.7653346 ,  7.5396523 ], dtype=float32), 'agent_3': Array([ 0.6034826 , -0.28991932, -0.04302778, -0.09140008,  0.9517045 ,\n",
            "        0.6582805 ,  0.45121294,  0.19219238,  0.376362  ,  1.1283082 ,\n",
            "        0.42967796, -0.5340576 ,  0.3974676 ,  0.954235  , -3.545144  ,\n",
            "       -2.4550064 ,  4.337621  ,  6.5971713 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6533441 -1.0858862  0.6526822 -1.077624   0.6515828 -1.0759847\n",
            "  0.652023  -1.0783415]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.80704284, dtype=float32), 'agent_0': Array(-0.80704284, dtype=float32), 'agent_1': Array(-0.80704284, dtype=float32), 'agent_2': Array(-0.80704284, dtype=float32), 'agent_3': Array(-0.80704284, dtype=float32)}\n",
            "step: 428\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2948740e-01, -2.6454291e-01, -2.9109804e-02, -9.4171040e-02,\n",
            "        9.5932353e-01,  5.0655907e-01,  5.4984039e-01,  5.7809556e-01,\n",
            "        3.9872590e-01,  5.5545604e-01,  1.2358665e+00,  7.6293945e-04,\n",
            "        4.6648979e-01, -5.1238501e-01,  8.5878301e-01, -5.5727679e-01,\n",
            "       -4.3579588e+00, -8.1894312e+00], dtype=float32), 'agent_1': Array([ 6.2948740e-01, -2.6454291e-01, -2.9109804e-02, -9.4171040e-02,\n",
            "        9.5932353e-01,  5.0655907e-01,  5.7809556e-01, -6.2565261e-01,\n",
            "        3.9872590e-01,  5.5545604e-01,  1.2358665e+00,  7.6293945e-04,\n",
            "        4.6648979e-01, -5.1238501e-01,  8.5878301e-01, -5.5727679e-01,\n",
            "        8.7003273e-01, -5.3026609e+00], dtype=float32), 'agent_2': Array([ 6.2948740e-01, -2.6454291e-01, -2.9109804e-02, -9.4171040e-02,\n",
            "        9.5932353e-01,  5.0655907e-01,  5.7809556e-01,  3.9872590e-01,\n",
            "       -6.1256611e-01,  5.5545604e-01,  1.2358665e+00,  7.6293945e-04,\n",
            "        4.6648979e-01, -5.1238501e-01,  8.5878301e-01, -5.5727679e-01,\n",
            "        4.3874125e+00, -4.9938774e+00], dtype=float32), 'agent_3': Array([ 6.2948740e-01, -2.6454291e-01, -2.9109804e-02, -9.4171040e-02,\n",
            "        9.5932353e-01,  5.0655907e-01,  5.7809556e-01,  3.9872590e-01,\n",
            "        5.5545604e-01,  9.9942613e-01,  1.2358665e+00,  7.6293945e-04,\n",
            "        4.6648979e-01, -5.1238501e-01,  8.5878301e-01, -5.5727679e-01,\n",
            "        3.0295606e+00, -6.6071801e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.38003868 -0.61127234 -0.38686687 -0.60571575 -0.38610435 -0.60467416\n",
            " -0.3846425  -0.60668004]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.150625, dtype=float32), 'agent_0': Array(-1.150625, dtype=float32), 'agent_1': Array(-1.150625, dtype=float32), 'agent_2': Array(-1.150625, dtype=float32), 'agent_3': Array(-1.150625, dtype=float32)}\n",
            "step: 429\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.63279456,  -0.37307015,  -0.05271929,  -0.09113134,\n",
            "         0.92181045,  -0.04732702,   0.4749171 ,   0.3271533 ,\n",
            "         0.30097112,   0.40663165,   1.1479378 ,  -0.14698505,\n",
            "        -0.10403395,   0.17812258,   0.59657407,   5.654776  ,\n",
            "       -11.509284  ,  -0.29844528], dtype=float32), 'agent_1': Array([ 0.63279456, -0.37307015, -0.05271929, -0.09113134,  0.92181045,\n",
            "       -0.04732702,  0.3271533 , -0.91761076,  0.30097112,  0.40663165,\n",
            "        1.1479378 , -0.14698505, -0.10403395,  0.17812258,  0.59657407,\n",
            "        5.654776  , -7.262787  , -7.110291  ], dtype=float32), 'agent_2': Array([ 0.63279456, -0.37307015, -0.05271929, -0.09113134,  0.92181045,\n",
            "       -0.04732702,  0.3271533 ,  0.30097112, -0.9549907 ,  0.40663165,\n",
            "        1.1479378 , -0.14698505, -0.10403395,  0.17812258,  0.59657407,\n",
            "        5.654776  , -3.1393974 , -8.30821   ], dtype=float32), 'agent_3': Array([ 0.63279456, -0.37307015, -0.05271929, -0.09113134,  0.92181045,\n",
            "       -0.04732702,  0.3271533 ,  0.30097112,  0.40663165,  0.6630044 ,\n",
            "        1.1479378 , -0.14698505, -0.10403395,  0.17812258,  0.59657407,\n",
            "        5.654776  , -4.881729  , -7.9728823 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.04380702  1.4248817  -0.04820138  1.4283943  -0.049309    1.4298106\n",
            " -0.04906324  1.4295933 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1645014, dtype=float32), 'agent_0': Array(1.1645014, dtype=float32), 'agent_1': Array(1.1645014, dtype=float32), 'agent_2': Array(1.1645014, dtype=float32), 'agent_3': Array(1.1645014, dtype=float32)}\n",
            "step: 430\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.61957407, -0.44979075, -0.01907296, -0.05817446,  0.8910333 ,\n",
            "       -0.44307998,  0.7509031 ,  0.14323667,  0.2592205 ,  0.29641047,\n",
            "        0.6655693 , -0.5132437 , -0.59330463,  0.23228732, -3.1846976 ,\n",
            "        2.2895846 , -6.2801104 ,  9.732201  ], dtype=float32), 'agent_1': Array([ 0.61957407, -0.44979075, -0.01907296, -0.05817446,  0.8910333 ,\n",
            "       -0.44307998,  0.14323667, -0.8570385 ,  0.2592205 ,  0.29641047,\n",
            "        0.6655693 , -0.5132437 , -0.59330463,  0.23228732, -3.1846976 ,\n",
            "        2.2895846 , -2.025362  ,  4.6174035 ], dtype=float32), 'agent_2': Array([ 0.61957407, -0.44979075, -0.01907296, -0.05817446,  0.8910333 ,\n",
            "       -0.44307998,  0.14323667,  0.2592205 , -0.95773983,  0.29641047,\n",
            "        0.6655693 , -0.5132437 , -0.59330463,  0.23228732, -3.1846976 ,\n",
            "        2.2895846 , -0.32543847,  2.8022554 ], dtype=float32), 'agent_3': Array([ 0.61957407, -0.44979075, -0.01907296, -0.05817446,  0.8910333 ,\n",
            "       -0.44307998,  0.14323667,  0.2592205 ,  0.29641047,  0.6967353 ,\n",
            "        0.6655693 , -0.5132437 , -0.59330463,  0.23228732, -3.1846976 ,\n",
            "        2.2895846 , -0.95879155,  4.6632385 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.36878788  0.23300365 -0.3659453   0.2491589  -0.36479712  0.25321782\n",
            " -0.36695418  0.25053138]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2494798, dtype=float32), 'agent_0': Array(-2.2494798, dtype=float32), 'agent_1': Array(-2.2494798, dtype=float32), 'agent_2': Array(-2.2494798, dtype=float32), 'agent_3': Array(-2.2494798, dtype=float32)}\n",
            "step: 431\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5726543 , -0.49402362,  0.04012262, -0.0205776 ,  0.86827844,\n",
            "       -0.5846115 ,  1.1559856 ,  0.01165532,  0.22625025,  0.21095961,\n",
            "        0.35715103, -0.70331097, -0.9965062 ,  0.21484968, -3.4333987 ,\n",
            "        0.88845897,  0.5094812 ,  7.2181063 ], dtype=float32), 'agent_1': Array([ 0.5726543 , -0.49402362,  0.04012262, -0.0205776 ,  0.86827844,\n",
            "       -0.5846115 ,  0.01165532, -0.66860473,  0.22625025,  0.21095961,\n",
            "        0.35715103, -0.70331097, -0.9965062 ,  0.21484968, -3.4333987 ,\n",
            "        0.88845897, -2.3130162 ,  5.2046328 ], dtype=float32), 'agent_2': Array([ 0.5726543 , -0.49402362,  0.04012262, -0.0205776 ,  0.86827844,\n",
            "       -0.5846115 ,  0.01165532,  0.22625025, -0.8472541 ,  0.21095961,\n",
            "        0.35715103, -0.70331097, -0.9965062 ,  0.21484968, -3.4333987 ,\n",
            "        0.88845897, -0.07297781,  4.2588243 ], dtype=float32), 'agent_3': Array([ 0.5726543 , -0.49402362,  0.04012262, -0.0205776 ,  0.86827844,\n",
            "       -0.5846115 ,  0.01165532,  0.22625025,  0.21095961,  0.8702743 ,\n",
            "        0.35715103, -0.70331097, -0.9965062 ,  0.21484968, -3.4333987 ,\n",
            "        0.88845897, -1.4228454 ,  4.2644987 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7781369   1.4139811  -0.77663565  1.41235    -0.7760695   1.4175813\n",
            " -0.77660596  1.4148821 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1690472, dtype=float32), 'agent_0': Array(1.1690472, dtype=float32), 'agent_1': Array(1.1690472, dtype=float32), 'agent_2': Array(1.1690472, dtype=float32), 'agent_3': Array(1.1690472, dtype=float32)}\n",
            "step: 432\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.51590085, -0.57293797,  0.12792403,  0.02211905,  0.8092518 ,\n",
            "       -0.5888759 ,  1.29281   , -0.3300761 ,  0.01125634, -0.08808435,\n",
            "       -0.22754669, -0.6686926 , -1.4198303 ,  0.07768684, -2.3436983 ,\n",
            "        4.8052945 ,  0.47603768, -1.2823853 ], dtype=float32), 'agent_1': Array([ 0.51590085, -0.57293797,  0.12792403,  0.02211905,  0.8092518 ,\n",
            "       -0.5888759 , -0.3300761 , -0.44579723,  0.01125634, -0.08808435,\n",
            "       -0.22754669, -0.6686926 , -1.4198303 ,  0.07768684, -2.3436983 ,\n",
            "        4.8052945 , -8.752598  , -1.600308  ], dtype=float32), 'agent_2': Array([ 0.51590085, -0.57293797,  0.12792403,  0.02211905,  0.8092518 ,\n",
            "       -0.5888759 , -0.3300761 ,  0.01125634, -0.44341242, -0.08808435,\n",
            "       -0.22754669, -0.6686926 , -1.4198303 ,  0.07768684, -2.3436983 ,\n",
            "        4.8052945 , -6.087928  ,  2.594161  ], dtype=float32), 'agent_3': Array([ 0.51590085, -0.57293797,  0.12792403,  0.02211905,  0.8092518 ,\n",
            "       -0.5888759 , -0.3300761 ,  0.01125634, -0.08808435,  1.3063121 ,\n",
            "       -0.22754669, -0.6686926 , -1.4198303 ,  0.07768684, -2.3436983 ,\n",
            "        4.8052945 , -7.929462  ,  3.285534  ], dtype=float32)}\n",
            "ctrl action chosen: [-2.5097685  -0.5582199  -2.5078835  -0.57308936 -2.5157645  -0.5667705\n",
            " -2.5136616  -0.5691673 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.2839017, dtype=float32), 'agent_0': Array(-4.2839017, dtype=float32), 'agent_1': Array(-4.2839017, dtype=float32), 'agent_2': Array(-4.2839017, dtype=float32), 'agent_3': Array(-4.2839017, dtype=float32)}\n",
            "step: 433\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4804195 , -0.6705245 ,  0.11949911,  0.02043224,  0.7319149 ,\n",
            "       -0.51447165,  0.95265055, -0.6453426 , -0.38726717, -0.5528239 ,\n",
            "        0.13780594, -0.5251646 , -0.29900074,  0.82128876, -0.09717546,\n",
            "        2.493486  ,  3.0440876 , -9.32341   ], dtype=float32), 'agent_1': Array([ 0.4804195 , -0.6705245 ,  0.11949911,  0.02043224,  0.7319149 ,\n",
            "       -0.51447165, -0.6453426 , -0.5497764 , -0.38726717, -0.5528239 ,\n",
            "        0.13780594, -0.5251646 , -0.29900074,  0.82128876, -0.09717546,\n",
            "        2.493486  ,  0.06951205, -0.9130243 ], dtype=float32), 'agent_2': Array([ 0.4804195 , -0.6705245 ,  0.11949911,  0.02043224,  0.7319149 ,\n",
            "       -0.51447165, -0.6453426 , -0.38726717, -0.58816314, -0.5528239 ,\n",
            "        0.13780594, -0.5251646 , -0.29900074,  0.82128876, -0.09717546,\n",
            "        2.493486  , -6.45834   , -2.594231  ], dtype=float32), 'agent_3': Array([ 0.4804195 , -0.6705245 ,  0.11949911,  0.02043224,  0.7319149 ,\n",
            "       -0.51447165, -0.6453426 , -0.38726717, -0.5528239 ,  1.1151145 ,\n",
            "        0.13780594, -0.5251646 , -0.29900074,  0.82128876, -0.09717546,\n",
            "        2.493486  , -6.4253936 , -4.042508  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9974447  -0.17847566  0.9830143  -0.1648079   0.9854382  -0.17760801\n",
            "  0.98680407 -0.1740976 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.252753, dtype=float32), 'agent_0': Array(-12.252753, dtype=float32), 'agent_1': Array(-12.252753, dtype=float32), 'agent_2': Array(-12.252753, dtype=float32), 'agent_3': Array(-12.252753, dtype=float32)}\n",
            "step: 434\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5098104 ,  -0.49318936,   0.09372921,   0.06469578,\n",
            "         0.86243474,   0.35518268,   0.63586557,  -0.06647263,\n",
            "         0.0953747 ,  -0.1783341 ,  -0.74415207,  -1.3527155 ,\n",
            "         1.1453986 ,   0.7002197 ,   0.46774867, -11.800827  ,\n",
            "        20.699383  ,  -5.4212284 ], dtype=float32), 'agent_1': Array([  0.5098104 ,  -0.49318936,   0.09372921,   0.06469578,\n",
            "         0.86243474,   0.35518268,  -0.06647263,  -0.52630705,\n",
            "         0.0953747 ,  -0.1783341 ,  -0.74415207,  -1.3527155 ,\n",
            "         1.1453986 ,   0.7002197 ,   0.46774867, -11.800827  ,\n",
            "        16.081339  ,   0.0326107 ], dtype=float32), 'agent_2': Array([  0.5098104 ,  -0.49318936,   0.09372921,   0.06469578,\n",
            "         0.86243474,   0.35518268,  -0.06647263,   0.0953747 ,\n",
            "        -0.5984807 ,  -0.1783341 ,  -0.74415207,  -1.3527155 ,\n",
            "         1.1453986 ,   0.7002197 ,   0.46774867, -11.800827  ,\n",
            "        15.114736  ,   1.2085323 ], dtype=float32), 'agent_3': Array([  0.5098104 ,  -0.49318936,   0.09372921,   0.06469578,\n",
            "         0.86243474,   0.35518268,  -0.06647263,   0.0953747 ,\n",
            "        -0.1783341 ,   0.9319446 ,  -0.74415207,  -1.3527155 ,\n",
            "         1.1453986 ,   0.7002197 ,   0.46774867, -11.800827  ,\n",
            "        11.34479   ,  -3.6784644 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.4331102  -0.7384695   0.4307885  -0.72483426  0.4306426  -0.7195075\n",
            "  0.42469484 -0.73246634]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1764789, dtype=float32), 'agent_0': Array(-1.1764789, dtype=float32), 'agent_1': Array(-1.1764789, dtype=float32), 'agent_2': Array(-1.1764789, dtype=float32), 'agent_3': Array(-1.1764789, dtype=float32)}\n",
            "step: 435\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5553527 , -0.42924145,  0.05250136,  0.07105459,  0.8988586 ,\n",
            "        0.6402969 ,  0.4618505 ,  0.26740035,  0.42400387, -0.04060123,\n",
            "        0.0412941 , -0.64201355,  0.7068157 ,  1.5115553 ,  1.673366  ,\n",
            "        0.66513854, -1.9320467 ,  1.3052319 ], dtype=float32), 'agent_1': Array([ 0.5553527 , -0.42924145,  0.05250136,  0.07105459,  0.8988586 ,\n",
            "        0.6402969 ,  0.26740035, -0.740488  ,  0.42400387, -0.04060123,\n",
            "        0.0412941 , -0.64201355,  0.7068157 ,  1.5115553 ,  1.673366  ,\n",
            "        0.66513854,  2.408519  , -6.7904387 ], dtype=float32), 'agent_2': Array([ 0.5553527 , -0.42924145,  0.05250136,  0.07105459,  0.8988586 ,\n",
            "        0.6402969 ,  0.26740035,  0.42400387, -0.6745953 , -0.04060123,\n",
            "        0.0412941 , -0.64201355,  0.7068157 ,  1.5115553 ,  1.673366  ,\n",
            "        0.66513854,  2.5444908 , -3.0032763 ], dtype=float32), 'agent_3': Array([ 0.5553527 , -0.42924145,  0.05250136,  0.07105459,  0.8988586 ,\n",
            "        0.6402969 ,  0.26740035,  0.42400387, -0.04060123,  0.57841444,\n",
            "        0.0412941 , -0.64201355,  0.7068157 ,  1.5115553 ,  1.673366  ,\n",
            "        0.66513854, -0.8006889 , -9.171767  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.33023778  0.4499401  -0.32361865  0.44434774 -0.3311992   0.4496982\n",
            " -0.32153064  0.44192362]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.808061, dtype=float32), 'agent_0': Array(-0.808061, dtype=float32), 'agent_1': Array(-0.808061, dtype=float32), 'agent_2': Array(-0.808061, dtype=float32), 'agent_3': Array(-0.808061, dtype=float32)}\n",
            "step: 436\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.59912485,  -0.549385  ,   0.04482827,   0.0831566 ,\n",
            "         0.8302117 ,   0.22842357,   0.5812875 ,   0.09520932,\n",
            "         0.2600406 ,  -0.35887796,  -0.14476776,  -0.5596638 ,\n",
            "         0.96355677,   0.36110067,  -0.16754945,   6.7320046 ,\n",
            "       -10.885068  ,   3.1175704 ], dtype=float32), 'agent_1': Array([ 0.59912485, -0.549385  ,  0.04482827,  0.0831566 ,  0.8302117 ,\n",
            "        0.22842357,  0.09520932, -0.82268363,  0.2600406 , -0.35887796,\n",
            "       -0.14476776, -0.5596638 ,  0.96355677,  0.36110067, -0.16754945,\n",
            "        6.7320046 , -4.552686  ,  0.67159355], dtype=float32), 'agent_2': Array([ 0.59912485, -0.549385  ,  0.04482827,  0.0831566 ,  0.8302117 ,\n",
            "        0.22842357,  0.09520932,  0.2600406 , -0.6084368 , -0.35887796,\n",
            "       -0.14476776, -0.5596638 ,  0.96355677,  0.36110067, -0.16754945,\n",
            "        6.7320046 , -4.7078066 ,  1.0848416 ], dtype=float32), 'agent_3': Array([ 0.59912485, -0.549385  ,  0.04482827,  0.0831566 ,  0.8302117 ,\n",
            "        0.22842357,  0.09520932,  0.2600406 , -0.35887796,  0.5151551 ,\n",
            "       -0.14476776, -0.5596638 ,  0.96355677,  0.36110067, -0.16754945,\n",
            "        6.7320046 , -7.278491  ,  1.0963537 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.19886886 -0.8366028  -0.20139848 -0.827148   -0.20485444 -0.8273129\n",
            " -0.20086439 -0.82875806]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.28791648, dtype=float32), 'agent_0': Array(0.28791648, dtype=float32), 'agent_1': Array(0.28791648, dtype=float32), 'agent_2': Array(0.28791648, dtype=float32), 'agent_3': Array(0.28791648, dtype=float32)}\n",
            "step: 437\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6197576 , -0.64106274,  0.02220643,  0.06108855,  0.7647311 ,\n",
            "       -0.15259635,  0.4949658 , -0.02192535,  0.12357923, -0.5664352 ,\n",
            "       -0.09422302, -0.26755333,  0.09144545, -0.00540412,  1.7016081 ,\n",
            "        2.4507349 , -5.2300124 , -1.7845663 ], dtype=float32), 'agent_1': Array([ 6.19757593e-01, -6.41062737e-01,  2.22064331e-02,  6.10885508e-02,\n",
            "        7.64731109e-01, -1.52596354e-01, -2.19253469e-02, -1.09057450e+00,\n",
            "        1.23579234e-01, -5.66435218e-01, -9.42230225e-02, -2.67553329e-01,\n",
            "        9.14454460e-02, -5.40411752e-03,  1.70160806e+00,  2.45073485e+00,\n",
            "       -5.01549840e-01, -6.90651035e+00], dtype=float32), 'agent_2': Array([ 6.19757593e-01, -6.41062737e-01,  2.22064331e-02,  6.10885508e-02,\n",
            "        7.64731109e-01, -1.52596354e-01, -2.19253469e-02,  1.23579234e-01,\n",
            "       -8.75591397e-01, -5.66435218e-01, -9.42230225e-02, -2.67553329e-01,\n",
            "        9.14454460e-02, -5.40411752e-03,  1.70160806e+00,  2.45073485e+00,\n",
            "       -9.58315134e-01, -6.46460485e+00], dtype=float32), 'agent_3': Array([ 0.6197576 , -0.64106274,  0.02220643,  0.06108855,  0.7647311 ,\n",
            "       -0.15259635, -0.02192535,  0.12357923, -0.5664352 ,  0.49898905,\n",
            "       -0.09422302, -0.26755333,  0.09144545, -0.00540412,  1.7016081 ,\n",
            "        2.4507349 , -0.2742268 ,  0.53915465], dtype=float32)}\n",
            "ctrl action chosen: [ 0.10975631 -1.0370106   0.10816845 -1.0363667   0.10609131 -1.0368338\n",
            "  0.10622624 -1.0229006 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5154462, dtype=float32), 'agent_0': Array(-0.5154462, dtype=float32), 'agent_1': Array(-0.5154462, dtype=float32), 'agent_2': Array(-0.5154462, dtype=float32), 'agent_3': Array(-0.5154462, dtype=float32)}\n",
            "step: 438\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6286259 , -0.65207446,  0.00275276,  0.03694926,  0.7572491 ,\n",
            "       -0.26609066,  0.46444866,  0.05780474,  0.20429733, -0.46661884,\n",
            "       -0.62208176, -0.02024174,  0.6694555 , -1.2449161 ,  0.95494616,\n",
            "       -0.10506596, -1.1974249 , -0.22701438], dtype=float32), 'agent_1': Array([ 0.6286259 , -0.65207446,  0.00275276,  0.03694926,  0.7572491 ,\n",
            "       -0.26609066,  0.05780474, -1.2887098 ,  0.20429733, -0.46661884,\n",
            "       -0.62208176, -0.02024174,  0.6694555 , -1.2449161 ,  0.95494616,\n",
            "       -0.10506596,  1.8867215 ,  0.9395096 ], dtype=float32), 'agent_2': Array([ 6.2862593e-01, -6.5207446e-01,  2.7527635e-03,  3.6949262e-02,\n",
            "        7.5724912e-01, -2.6609066e-01,  5.7804737e-02,  2.0429733e-01,\n",
            "       -1.2526125e+00, -4.6661884e-01, -6.2208176e-01, -2.0241737e-02,\n",
            "        6.6945553e-01, -1.2449161e+00,  9.5494616e-01, -1.0506596e-01,\n",
            "        2.3520072e+00, -6.0950527e+00], dtype=float32), 'agent_3': Array([ 6.2862593e-01, -6.5207446e-01,  2.7527635e-03,  3.6949262e-02,\n",
            "        7.5724912e-01, -2.6609066e-01,  5.7804737e-02,  2.0429733e-01,\n",
            "       -4.6661884e-01,  4.9444252e-01, -6.2208176e-01, -2.0241737e-02,\n",
            "        6.6945553e-01, -1.2449161e+00,  9.5494616e-01, -1.0506596e-01,\n",
            "        3.1229856e+00,  4.3926319e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 1.7785379  -0.4151296   1.7758986  -0.41183394  1.7808254  -0.4194454\n",
            "  1.7793133  -0.4095442 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3944137, dtype=float32), 'agent_0': Array(-1.3944137, dtype=float32), 'agent_1': Array(-1.3944137, dtype=float32), 'agent_2': Array(-1.3944137, dtype=float32), 'agent_3': Array(-1.3944137, dtype=float32)}\n",
            "step: 439\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.66780055, -0.513876  , -0.01016258,  0.01741452,  0.8576275 ,\n",
            "        0.13377391,  0.5161169 ,  0.56376487,  0.6494392 ,  0.11482304,\n",
            "       -0.95272064, -0.11916161,  0.38776398, -0.726971  ,  0.87683785,\n",
            "       -2.8254108 ,  5.3417315 ,  0.51951903], dtype=float32), 'agent_1': Array([ 0.66780055, -0.513876  , -0.01016258,  0.01741452,  0.8576275 ,\n",
            "        0.13377391,  0.56376487, -1.2475283 ,  0.6494392 ,  0.11482304,\n",
            "       -0.95272064, -0.11916161,  0.38776398, -0.726971  ,  0.87683785,\n",
            "       -2.8254108 ,  5.3131585 ,  0.78218484], dtype=float32), 'agent_2': Array([ 0.66780055, -0.513876  , -0.01016258,  0.01741452,  0.8576275 ,\n",
            "        0.13377391,  0.56376487,  0.6494392 , -1.2489582 ,  0.11482304,\n",
            "       -0.95272064, -0.11916161,  0.38776398, -0.726971  ,  0.87683785,\n",
            "       -2.8254108 ,  0.6284367 ,  0.1157443 ], dtype=float32), 'agent_3': Array([ 0.66780055, -0.513876  , -0.01016258,  0.01741452,  0.8576275 ,\n",
            "        0.13377391,  0.56376487,  0.6494392 ,  0.11482304,  0.5056374 ,\n",
            "       -0.95272064, -0.11916161,  0.38776398, -0.726971  ,  0.87683785,\n",
            "       -2.8254108 ,  8.332302  , -0.7144381 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9223174  -0.6841891   0.9204892  -0.6847506   0.918059   -0.6844645\n",
            "  0.9230224  -0.68506694]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.3130836, dtype=float32), 'agent_0': Array(-6.3130836, dtype=float32), 'agent_1': Array(-6.3130836, dtype=float32), 'agent_2': Array(-6.3130836, dtype=float32), 'agent_3': Array(-6.3130836, dtype=float32)}\n",
            "step: 440\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6698264 , -0.48887002, -0.01696384, -0.01084956,  0.8721242 ,\n",
            "        0.3714532 ,  0.50542825,  0.6055051 ,  0.53997326,  0.48025852,\n",
            "       -1.6127586 , -0.15730858, -0.07189512, -0.6042399 ,  0.650232  ,\n",
            "       -1.6345493 ,  6.1314716 , -0.08154721], dtype=float32), 'agent_1': Array([ 0.6698264 , -0.48887002, -0.01696384, -0.01084956,  0.8721242 ,\n",
            "        0.3714532 ,  0.6055051 , -1.2299457 ,  0.53997326,  0.48025852,\n",
            "       -1.6127586 , -0.15730858, -0.07189512, -0.6042399 ,  0.650232  ,\n",
            "       -1.6345493 , -0.7477864 ,  0.23560879], dtype=float32), 'agent_2': Array([ 0.6698264 , -0.48887002, -0.01696384, -0.01084956,  0.8721242 ,\n",
            "        0.3714532 ,  0.6055051 ,  0.53997326, -1.2478976 ,  0.48025852,\n",
            "       -1.6127586 , -0.15730858, -0.07189512, -0.6042399 ,  0.650232  ,\n",
            "       -1.6345493 , -2.7254028 ,  0.4822471 ], dtype=float32), 'agent_3': Array([ 0.6698264 , -0.48887002, -0.01696384, -0.01084956,  0.8721242 ,\n",
            "        0.3714532 ,  0.6055051 ,  0.53997326,  0.48025852,  0.48182997,\n",
            "       -1.6127586 , -0.15730858, -0.07189512, -0.6042399 ,  0.650232  ,\n",
            "       -1.6345493 ,  8.474593  , -0.02618532], dtype=float32)}\n",
            "ctrl action chosen: [0.74091804 0.9503135  0.739799   0.9504345  0.74159694 0.9482676\n",
            " 0.74335665 0.9513433 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.972858, dtype=float32), 'agent_0': Array(-2.972858, dtype=float32), 'agent_1': Array(-2.972858, dtype=float32), 'agent_2': Array(-2.972858, dtype=float32), 'agent_3': Array(-2.972858, dtype=float32)}\n",
            "step: 441\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.6219985e-01, -5.0947464e-01,  8.0929268e-03,  1.2384982e-02,\n",
            "        8.6035854e-01,  5.7214183e-01,  8.1805348e-01,  4.5158809e-01,\n",
            "        3.4940353e-01,  6.1721569e-01, -1.1187077e+00, -8.8174343e-01,\n",
            "       -3.9138794e-01,  6.2948179e-01, -2.0350425e+00,  2.4943588e+00,\n",
            "        1.2120323e+00,  8.3308983e+00], dtype=float32), 'agent_1': Array([ 6.6219985e-01, -5.0947464e-01,  8.0929268e-03,  1.2384982e-02,\n",
            "        8.6035854e-01,  5.7214183e-01,  4.5158809e-01, -8.7183040e-01,\n",
            "        3.4940353e-01,  6.1721569e-01, -1.1187077e+00, -8.8174343e-01,\n",
            "       -3.9138794e-01,  6.2948179e-01, -2.0350425e+00,  2.4943588e+00,\n",
            "       -3.2695234e+00,  9.0241241e+00], dtype=float32), 'agent_2': Array([ 6.6219985e-01, -5.0947464e-01,  8.0929268e-03,  1.2384982e-02,\n",
            "        8.6035854e-01,  5.7214183e-01,  4.5158809e-01,  3.4940353e-01,\n",
            "       -8.8710272e-01,  6.1721569e-01, -1.1187077e+00, -8.8174343e-01,\n",
            "       -3.9138794e-01,  6.2948179e-01, -2.0350425e+00,  2.4943588e+00,\n",
            "       -3.8052223e+00,  1.0220175e+01], dtype=float32), 'agent_3': Array([ 6.6219985e-01, -5.0947464e-01,  8.0929268e-03,  1.2384982e-02,\n",
            "        8.6035854e-01,  5.7214183e-01,  4.5158809e-01,  3.4940353e-01,\n",
            "        6.1721569e-01,  7.9694110e-01, -1.1187077e+00, -8.8174343e-01,\n",
            "       -3.9138794e-01,  6.2948179e-01, -2.0350425e+00,  2.4943588e+00,\n",
            "       -1.0154190e+00,  9.7752876e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.13925742 -1.4797484   0.14026222 -1.4890968   0.13854021 -1.490627\n",
            "  0.14069039 -1.4878663 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.4206362, dtype=float32), 'agent_0': Array(-3.4206362, dtype=float32), 'agent_1': Array(-3.4206362, dtype=float32), 'agent_2': Array(-3.4206362, dtype=float32), 'agent_3': Array(-3.4206362, dtype=float32)}\n",
            "step: 442\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6234467 , -0.5788611 , -0.00821749, -0.02213985,  0.8150841 ,\n",
            "        0.54490393,  0.7355874 ,  0.25587574,  0.16040374,  0.4704369 ,\n",
            "       -0.7534027 , -0.01785755, -1.0133743 , -1.0862808 ,  2.6214817 ,\n",
            "        2.5694249 , -1.1498843 , -4.9787602 ], dtype=float32), 'agent_1': Array([ 0.6234467 , -0.5788611 , -0.00821749, -0.02213985,  0.8150841 ,\n",
            "        0.54490393,  0.25587574, -0.9706729 ,  0.16040374,  0.4704369 ,\n",
            "       -0.7534027 , -0.01785755, -1.0133743 , -1.0862808 ,  2.6214817 ,\n",
            "        2.5694249 , -1.9748031 , -5.4504366 ], dtype=float32), 'agent_2': Array([ 0.6234467 , -0.5788611 , -0.00821749, -0.02213985,  0.8150841 ,\n",
            "        0.54490393,  0.25587574,  0.16040374, -0.90899974,  0.4704369 ,\n",
            "       -0.7534027 , -0.01785755, -1.0133743 , -1.0862808 ,  2.6214817 ,\n",
            "        2.5694249 , -2.1683517 , -4.942613  ], dtype=float32), 'agent_3': Array([ 0.6234467 , -0.5788611 , -0.00821749, -0.02213985,  0.8150841 ,\n",
            "        0.54490393,  0.25587574,  0.16040374,  0.4704369 ,  0.7720565 ,\n",
            "       -0.7534027 , -0.01785755, -1.0133743 , -1.0862808 ,  2.6214817 ,\n",
            "        2.5694249 , -2.5944664 , -4.9866037 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.69357884 -0.7129891  -0.6928463  -0.7131712  -0.6929256  -0.71352464\n",
            " -0.6912376  -0.71290857]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.3316364, dtype=float32), 'agent_0': Array(-4.3316364, dtype=float32), 'agent_1': Array(-4.3316364, dtype=float32), 'agent_2': Array(-4.3316364, dtype=float32), 'agent_3': Array(-4.3316364, dtype=float32)}\n",
            "step: 443\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5581051e-01, -7.3431957e-01, -5.3888965e-02, -7.1775742e-02,\n",
            "        6.7284399e-01,  1.1915835e-01,  4.7635096e-01, -2.1775833e-01,\n",
            "       -2.9388145e-01, -5.8704675e-03, -6.8922043e-01, -2.5177002e-02,\n",
            "       -1.6979575e+00, -2.3825805e-01,  2.9278355e+00,  9.7308331e+00,\n",
            "       -1.0464682e+01, -3.7388918e+00], dtype=float32), 'agent_1': Array([ 5.5581051e-01, -7.3431957e-01, -5.3888965e-02, -7.1775742e-02,\n",
            "        6.7284399e-01,  1.1915835e-01, -2.1775833e-01, -1.2391828e+00,\n",
            "       -2.9388145e-01, -5.8704675e-03, -6.8922043e-01, -2.5177002e-02,\n",
            "       -1.6979575e+00, -2.3825805e-01,  2.9278355e+00,  9.7308331e+00,\n",
            "       -1.1520099e+01, -5.9268169e+00], dtype=float32), 'agent_2': Array([ 5.5581051e-01, -7.3431957e-01, -5.3888965e-02, -7.1775742e-02,\n",
            "        6.7284399e-01,  1.1915835e-01, -2.1775833e-01, -2.9388145e-01,\n",
            "       -1.2086701e+00, -5.8704675e-03, -6.8922043e-01, -2.5177002e-02,\n",
            "       -1.6979575e+00, -2.3825805e-01,  2.9278355e+00,  9.7308331e+00,\n",
            "       -1.0418957e+01, -7.4442835e+00], dtype=float32), 'agent_3': Array([ 5.55810511e-01, -7.34319568e-01, -5.38889654e-02, -7.17757419e-02,\n",
            "        6.72843993e-01,  1.19158350e-01, -2.17758328e-01, -2.93881446e-01,\n",
            "       -5.87046752e-03,  4.94334757e-01, -6.89220428e-01, -2.51770020e-02,\n",
            "       -1.69795752e+00, -2.38258049e-01,  2.92783546e+00,  9.73083305e+00,\n",
            "       -1.13321905e+01, -5.46870661e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.2345132  -1.8067478  -0.23103736 -1.8084862  -0.23178011 -1.8121064\n",
            " -0.23206812 -1.8066175 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7095957, dtype=float32), 'agent_0': Array(-1.7095957, dtype=float32), 'agent_1': Array(-1.7095957, dtype=float32), 'agent_2': Array(-1.7095957, dtype=float32), 'agent_3': Array(-1.7095957, dtype=float32)}\n",
            "step: 444\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48812875, -0.8205895 , -0.09279969, -0.0863921 ,  0.557277  ,\n",
            "       -0.15819721,  0.45706084, -0.56556845, -0.56069493, -0.36460695,\n",
            "       -0.15053749, -0.48408508, -0.7973969 ,  0.44720876,  1.2085719 ,\n",
            "        1.8654033 , -1.2726519 ,  0.6259019 ], dtype=float32), 'agent_1': Array([ 0.48812875, -0.8205895 , -0.09279969, -0.0863921 ,  0.557277  ,\n",
            "       -0.15819721, -0.56556845, -1.2796392 , -0.56069493, -0.36460695,\n",
            "       -0.15053749, -0.48408508, -0.7973969 ,  0.44720876,  1.2085719 ,\n",
            "        1.8654033 , -1.16817   ,  0.7549596 ], dtype=float32), 'agent_2': Array([ 0.48812875, -0.8205895 , -0.09279969, -0.0863921 ,  0.557277  ,\n",
            "       -0.15819721, -0.56556845, -0.56069493, -1.2804003 , -0.36460695,\n",
            "       -0.15053749, -0.48408508, -0.7973969 ,  0.44720876,  1.2085719 ,\n",
            "        1.8654033 ,  0.0471297 ,  0.4318723 ], dtype=float32), 'agent_3': Array([ 0.48812875, -0.8205895 , -0.09279969, -0.0863921 ,  0.557277  ,\n",
            "       -0.15819721, -0.56556845, -0.56069493, -0.36460695,  0.45108488,\n",
            "       -0.15053749, -0.48408508, -0.7973969 ,  0.44720876,  1.2085719 ,\n",
            "        1.8654033 , -3.0081966 ,  0.33688954], dtype=float32)}\n",
            "ctrl action chosen: [-1.9506656   0.06886189 -1.9490786   0.0718315  -1.9502589   0.07310073\n",
            " -1.9515349   0.06854935]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.1073427, dtype=float32), 'agent_0': Array(-6.1073427, dtype=float32), 'agent_1': Array(-6.1073427, dtype=float32), 'agent_2': Array(-6.1073427, dtype=float32), 'agent_3': Array(-6.1073427, dtype=float32)}\n",
            "step: 445\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48577145, -0.84932745, -0.11316009, -0.0869474 ,  0.50821054,\n",
            "       -0.32207993,  0.5212493 , -0.56343997, -0.5546763 , -0.58039975,\n",
            "        0.56438446, -0.846529  ,  0.7237792 ,  0.07193848, -0.20260306,\n",
            "        1.7247183 , -2.7715256 ,  0.46705467], dtype=float32), 'agent_1': Array([ 0.48577145, -0.84932745, -0.11316009, -0.0869474 ,  0.50821054,\n",
            "       -0.32207993, -0.56343997, -1.1606263 , -0.5546763 , -0.58039975,\n",
            "        0.56438446, -0.846529  ,  0.7237792 ,  0.07193848, -0.20260306,\n",
            "        1.7247183 ,  1.3833152 ,  2.8003573 ], dtype=float32), 'agent_2': Array([ 0.48577145, -0.84932745, -0.11316009, -0.0869474 ,  0.50821054,\n",
            "       -0.32207993, -0.56343997, -0.5546763 , -1.1761156 , -0.58039975,\n",
            "        0.56438446, -0.846529  ,  0.7237792 ,  0.07193848, -0.20260306,\n",
            "        1.7247183 ,  1.1683797 ,  3.22203   ], dtype=float32), 'agent_3': Array([ 0.48577145, -0.84932745, -0.11316009, -0.0869474 ,  0.50821054,\n",
            "       -0.32207993, -0.56343997, -0.5546763 , -0.58039975,  0.5049974 ,\n",
            "        0.56438446, -0.846529  ,  0.7237792 ,  0.07193848, -0.20260306,\n",
            "        1.7247183 , -2.259542  ,  0.17994373], dtype=float32)}\n",
            "ctrl action chosen: [-0.89048886 -0.16079354 -0.8883637  -0.1522949  -0.8895714  -0.15238355\n",
            " -0.8901751  -0.15669985]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.343467, dtype=float32), 'agent_0': Array(-6.343467, dtype=float32), 'agent_1': Array(-6.343467, dtype=float32), 'agent_2': Array(-6.343467, dtype=float32), 'agent_3': Array(-6.343467, dtype=float32)}\n",
            "step: 446\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5413973 , -0.8754491 , -0.110303  , -0.07473336,  0.46458253,\n",
            "       -0.5087872 ,  0.51689196, -0.52903014, -0.52340996, -0.6017529 ,\n",
            "        0.14367104, -0.17485619,  1.0707974 , -0.04161344, -0.23803857,\n",
            "        2.2015224 , -5.135349  , -0.03073938], dtype=float32), 'agent_1': Array([ 0.5413973 , -0.8754491 , -0.110303  , -0.07473336,  0.46458253,\n",
            "       -0.5087872 , -0.52903014, -1.059347  , -0.52340996, -0.6017529 ,\n",
            "        0.14367104, -0.17485619,  1.0707974 , -0.04161344, -0.23803857,\n",
            "        2.2015224 , -0.17881854,  1.2889565 ], dtype=float32), 'agent_2': Array([ 0.5413973 , -0.8754491 , -0.110303  , -0.07473336,  0.46458253,\n",
            "       -0.5087872 , -0.52903014, -0.52340996, -1.0261618 , -0.6017529 ,\n",
            "        0.14367104, -0.17485619,  1.0707974 , -0.04161344, -0.23803857,\n",
            "        2.2015224 , -0.15258998,  1.8737046 ], dtype=float32), 'agent_3': Array([ 0.5413973 , -0.8754491 , -0.110303  , -0.07473336,  0.46458253,\n",
            "       -0.5087872 , -0.52903014, -0.52340996, -0.6017529 ,  0.509632  ,\n",
            "        0.14367104, -0.17485619,  1.0707974 , -0.04161344, -0.23803857,\n",
            "        2.2015224 ,  1.1683226 ,  0.41227603], dtype=float32)}\n",
            "ctrl action chosen: [-0.93028903  0.8059461  -0.93383634  0.8163416  -0.93398625  0.8173582\n",
            " -0.9335817   0.8225393 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.32064056, dtype=float32), 'agent_0': Array(-0.32064056, dtype=float32), 'agent_1': Array(-0.32064056, dtype=float32), 'agent_2': Array(-0.32064056, dtype=float32), 'agent_3': Array(-0.32064056, dtype=float32)}\n",
            "step: 447\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58651304, -0.8951588 , -0.0728    , -0.04336409,  0.43761897,\n",
            "       -0.60985947,  0.7801662 , -0.5343486 , -0.54235464, -0.5057962 ,\n",
            "       -0.3024578 , -0.70233345,  0.6864667 , -1.4911541 , -2.4649098 ,\n",
            "        1.0917908 ,  0.09409096,  7.877439  ], dtype=float32), 'agent_1': Array([ 0.58651304, -0.8951588 , -0.0728    , -0.04336409,  0.43761897,\n",
            "       -0.60985947, -0.5343486 , -0.74077904, -0.54235464, -0.5057962 ,\n",
            "       -0.3024578 , -0.70233345,  0.6864667 , -1.4911541 , -2.4649098 ,\n",
            "        1.0917908 , -0.11996491,  8.423143  ], dtype=float32), 'agent_2': Array([ 0.58651304, -0.8951588 , -0.0728    , -0.04336409,  0.43761897,\n",
            "       -0.60985947, -0.5343486 , -0.54235464, -0.6971764 , -0.5057962 ,\n",
            "       -0.3024578 , -0.70233345,  0.6864667 , -1.4911541 , -2.4649098 ,\n",
            "        1.0917908 , -0.6991    ,  8.379919  ], dtype=float32), 'agent_3': Array([ 0.58651304, -0.8951588 , -0.0728    , -0.04336409,  0.43761897,\n",
            "       -0.60985947, -0.5343486 , -0.54235464, -0.5057962 ,  0.77632755,\n",
            "       -0.3024578 , -0.70233345,  0.6864667 , -1.4911541 , -2.4649098 ,\n",
            "        1.0917908 ,  1.007631  ,  7.784572  ], dtype=float32)}\n",
            "ctrl action chosen: [1.2348996  0.27693707 1.2359544  0.27862263 1.2355926  0.27786162\n",
            " 1.2365739  0.28453133]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.13843, dtype=float32), 'agent_0': Array(-2.13843, dtype=float32), 'agent_1': Array(-2.13843, dtype=float32), 'agent_2': Array(-2.13843, dtype=float32), 'agent_3': Array(-2.13843, dtype=float32)}\n",
            "step: 448\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6102997 ,  -0.7769406 ,  -0.02366353,  -0.02486634,\n",
            "         0.62863743,   0.0230492 ,   1.0829687 ,   0.06204775,\n",
            "         0.03313383,   0.14491153,  -0.47869682,  -0.5326271 ,\n",
            "         0.36878586,  -0.23509894,  -1.0863128 , -12.111411  ,\n",
            "        17.670977  ,   5.215141  ], dtype=float32), 'agent_1': Array([  0.6102997 ,  -0.7769406 ,  -0.02366353,  -0.02486634,\n",
            "         0.62863743,   0.0230492 ,   0.06204775,  -0.47026783,\n",
            "         0.03313383,   0.14491153,  -0.47869682,  -0.5326271 ,\n",
            "         0.36878586,  -0.23509894,  -1.0863128 , -12.111411  ,\n",
            "        15.504691  ,   0.7101055 ], dtype=float32), 'agent_2': Array([  0.6102997 ,  -0.7769406 ,  -0.02366353,  -0.02486634,\n",
            "         0.62863743,   0.0230492 ,   0.06204775,   0.03313383,\n",
            "        -0.47659212,   0.14491153,  -0.47869682,  -0.5326271 ,\n",
            "         0.36878586,  -0.23509894,  -1.0863128 , -12.111411  ,\n",
            "        15.76758   ,   0.11284549], dtype=float32), 'agent_3': Array([  0.6102997 ,  -0.7769406 ,  -0.02366353,  -0.02486634,\n",
            "         0.62863743,   0.0230492 ,   0.06204775,   0.03313383,\n",
            "         0.14491153,   1.0605651 ,  -0.47869682,  -0.5326271 ,\n",
            "         0.36878586,  -0.23509894,  -1.0863128 , -12.111411  ,\n",
            "        15.92207   ,   4.5756927 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.2007123  -0.00533862  1.1946542  -0.01729627  1.1951985  -0.0180938\n",
            "  1.1971973  -0.00536819]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.6552207, dtype=float32), 'agent_0': Array(-2.6552207, dtype=float32), 'agent_1': Array(-2.6552207, dtype=float32), 'agent_2': Array(-2.6552207, dtype=float32), 'agent_3': Array(-2.6552207, dtype=float32)}\n",
            "step: 449\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6475448 , -0.6575356 , -0.0192557 , -0.01222989,  0.75307816,\n",
            "        0.5838071 ,  1.232687  ,  0.55483603,  0.55271024,  0.5898194 ,\n",
            "       -0.05908012, -0.43196678,  0.7303715 ,  0.48856992, -0.5222866 ,\n",
            "        1.7710328 ,  0.21398143,  2.123817  ], dtype=float32), 'agent_1': Array([ 0.6475448 , -0.6575356 , -0.0192557 , -0.01222989,  0.75307816,\n",
            "        0.5838071 ,  0.55483603, -0.5176984 ,  0.55271024,  0.5898194 ,\n",
            "       -0.05908012, -0.43196678,  0.7303715 ,  0.48856992, -0.5222866 ,\n",
            "        1.7710328 ,  0.01889563, -0.85081214], dtype=float32), 'agent_2': Array([ 0.6475448 , -0.6575356 , -0.0192557 , -0.01222989,  0.75307816,\n",
            "        0.5838071 ,  0.55483603,  0.55271024, -0.5050041 ,  0.5898194 ,\n",
            "       -0.05908012, -0.43196678,  0.7303715 ,  0.48856992, -0.5222866 ,\n",
            "        1.7710328 ,  0.5550285 , -1.0345945 ], dtype=float32), 'agent_3': Array([ 0.6475448 , -0.6575356 , -0.0192557 , -0.01222989,  0.75307816,\n",
            "        0.5838071 ,  0.55483603,  0.55271024,  0.5898194 ,  1.151127  ,\n",
            "       -0.05908012, -0.43196678,  0.7303715 ,  0.48856992, -0.5222866 ,\n",
            "        1.7710328 , -1.8866109 ,  1.5824703 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7353229   2.1192753  -0.73131     2.1235375  -0.7327775   2.1236703\n",
            " -0.73454964  2.1194766 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0794005, dtype=float32), 'agent_0': Array(-2.0794005, dtype=float32), 'agent_1': Array(-2.0794005, dtype=float32), 'agent_2': Array(-2.0794005, dtype=float32), 'agent_3': Array(-2.0794005, dtype=float32)}\n",
            "step: 450\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.6420257e-01, -7.8919703e-01, -6.1900606e-03,  8.1793256e-03,\n",
            "        6.1405456e-01,  2.2191468e-01,  1.2779179e+00,  1.6760518e-01,\n",
            "        1.8641841e-01,  1.1595981e-01, -2.6741028e-01, -3.4461021e-01,\n",
            "       -5.0330162e-02,  6.3572854e-02,  1.2210137e-01,  1.1744912e+01,\n",
            "       -1.2590057e+01, -7.9107124e-01], dtype=float32), 'agent_1': Array([ 6.6420257e-01, -7.8919703e-01, -6.1900606e-03,  8.1793256e-03,\n",
            "        6.1405456e-01,  2.2191468e-01,  1.6760518e-01, -4.9655715e-01,\n",
            "        1.8641841e-01,  1.1595981e-01, -2.6741028e-01, -3.4461021e-01,\n",
            "       -5.0330162e-02,  6.3572854e-02,  1.2210137e-01,  1.1744912e+01,\n",
            "       -1.2608394e+01, -3.3194703e-01], dtype=float32), 'agent_2': Array([ 6.6420257e-01, -7.8919703e-01, -6.1900606e-03,  8.1793256e-03,\n",
            "        6.1405456e-01,  2.2191468e-01,  1.6760518e-01,  1.8641841e-01,\n",
            "       -5.0983888e-01,  1.1595981e-01, -2.6741028e-01, -3.4461021e-01,\n",
            "       -5.0330162e-02,  6.3572854e-02,  1.2210137e-01,  1.1744912e+01,\n",
            "       -1.2191519e+01, -4.8117495e-01], dtype=float32), 'agent_3': Array([ 6.6420257e-01, -7.8919703e-01, -6.1900606e-03,  8.1793256e-03,\n",
            "        6.1405456e-01,  2.2191468e-01,  1.6760518e-01,  1.8641841e-01,\n",
            "        1.1595981e-01,  1.2867750e+00, -2.6741028e-01, -3.4461021e-01,\n",
            "       -5.0330162e-02,  6.3572854e-02,  1.2210137e-01,  1.1744912e+01,\n",
            "       -1.4962939e+01, -1.1304737e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.0105414  -0.47732258 -1.0093231  -0.47511768 -1.0112249  -0.47462544\n",
            " -1.0071836  -0.4760725 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.286795, dtype=float32), 'agent_0': Array(-9.286795, dtype=float32), 'agent_1': Array(-9.286795, dtype=float32), 'agent_2': Array(-9.286795, dtype=float32), 'agent_3': Array(-9.286795, dtype=float32)}\n",
            "step: 451\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63423616, -0.943156  , -0.02135908, -0.00787951,  0.3315699 ,\n",
            "       -0.51211727,  1.0377481 , -0.55639476, -0.52845156, -0.64706707,\n",
            "       -0.5501747 , -0.13017654, -0.80281496,  0.19075373,  1.0124592 ,\n",
            "        5.600227  , -7.395471  , -6.8743534 ], dtype=float32), 'agent_1': Array([ 0.63423616, -0.943156  , -0.02135908, -0.00787951,  0.3315699 ,\n",
            "       -0.51211727, -0.55639476, -0.6983118 , -0.52845156, -0.64706707,\n",
            "       -0.5501747 , -0.13017654, -0.80281496,  0.19075373,  1.0124592 ,\n",
            "        5.600227  , -6.018916  , -3.9098828 ], dtype=float32), 'agent_2': Array([ 0.63423616, -0.943156  , -0.02135908, -0.00787951,  0.3315699 ,\n",
            "       -0.51211727, -0.55639476, -0.52845156, -0.73704547, -0.64706707,\n",
            "       -0.5501747 , -0.13017654, -0.80281496,  0.19075373,  1.0124592 ,\n",
            "        5.600227  , -6.8413672 , -4.4603157 ], dtype=float32), 'agent_3': Array([ 0.63423616, -0.943156  , -0.02135908, -0.00787951,  0.3315699 ,\n",
            "       -0.51211727, -0.55639476, -0.52845156, -0.64706707,  1.0858734 ,\n",
            "       -0.5501747 , -0.13017654, -0.80281496,  0.19075373,  1.0124592 ,\n",
            "        5.600227  , -3.0620139 , -5.507072  ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1542706  -0.24176581  1.1534921  -0.23588476  1.1540387  -0.23783517\n",
            "  1.1490408  -0.22548166]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8891826, dtype=float32), 'agent_0': Array(-1.8891826, dtype=float32), 'agent_1': Array(-1.8891826, dtype=float32), 'agent_2': Array(-1.8891826, dtype=float32), 'agent_3': Array(-1.8891826, dtype=float32)}\n",
            "step: 452\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5901704 ,  -0.8852297 ,  -0.03347564,  -0.02685256,\n",
            "         0.46317023,  -0.13441952,   0.7490235 ,  -0.15539767,\n",
            "        -0.13393965,  -0.16238691,  -0.4635334 ,  -0.17285347,\n",
            "        -1.0694742 ,   0.26526806,   0.87062   , -10.230372  ,\n",
            "        13.527704  ,  -4.860496  ], dtype=float32), 'agent_1': Array([  0.5901704 ,  -0.8852297 ,  -0.03347564,  -0.02685256,\n",
            "         0.46317023,  -0.13441952,  -0.15539767,  -0.87582934,\n",
            "        -0.13393965,  -0.16238691,  -0.4635334 ,  -0.17285347,\n",
            "        -1.0694742 ,   0.26526806,   0.87062   , -10.230372  ,\n",
            "        13.876148  ,  -4.55868   ], dtype=float32), 'agent_2': Array([  0.5901704 ,  -0.8852297 ,  -0.03347564,  -0.02685256,\n",
            "         0.46317023,  -0.13441952,  -0.15539767,  -0.13393965,\n",
            "        -0.90493447,  -0.16238691,  -0.4635334 ,  -0.17285347,\n",
            "        -1.0694742 ,   0.26526806,   0.87062   , -10.230372  ,\n",
            "        13.711026  ,  -3.827265  ], dtype=float32), 'agent_3': Array([  0.5901704 ,  -0.8852297 ,  -0.03347564,  -0.02685256,\n",
            "         0.46317023,  -0.13441952,  -0.15539767,  -0.13393965,\n",
            "        -0.16238691,   0.83261025,  -0.4635334 ,  -0.17285347,\n",
            "        -1.0694742 ,   0.26526806,   0.87062   , -10.230372  ,\n",
            "        16.256865  ,  -4.940693  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9976961   0.9662633  -0.997665    0.967041   -0.99784815  0.9712748\n",
            " -0.9942174   0.9703592 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.246901, dtype=float32), 'agent_0': Array(-2.246901, dtype=float32), 'agent_1': Array(-2.246901, dtype=float32), 'agent_2': Array(-2.246901, dtype=float32), 'agent_3': Array(-2.246901, dtype=float32)}\n",
            "step: 453\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2083981e-01, -9.3620116e-01, -1.3762395e-02,  1.3559723e-03,\n",
            "        3.5119265e-01, -3.9930883e-01,  8.6063170e-01, -3.9402094e-01,\n",
            "       -3.9260909e-01, -3.2302949e-01, -4.7550201e-01, -5.3963661e-01,\n",
            "       -1.3578176e+00, -8.8025254e-01, -2.3027081e+00,  1.0348009e+01,\n",
            "       -1.2165275e+01,  4.9560709e+00], dtype=float32), 'agent_1': Array([ 5.2083981e-01, -9.3620116e-01, -1.3762395e-02,  1.3559723e-03,\n",
            "        3.5119265e-01, -3.9930883e-01, -3.9402094e-01, -7.4922967e-01,\n",
            "       -3.9260909e-01, -3.2302949e-01, -4.7550201e-01, -5.3963661e-01,\n",
            "       -1.3578176e+00, -8.8025254e-01, -2.3027081e+00,  1.0348009e+01,\n",
            "       -1.1579419e+01,  6.1446371e+00], dtype=float32), 'agent_2': Array([ 5.2083981e-01, -9.3620116e-01, -1.3762395e-02,  1.3559723e-03,\n",
            "        3.5119265e-01, -3.9930883e-01, -3.9402094e-01, -3.9260909e-01,\n",
            "       -7.6620841e-01, -3.2302949e-01, -4.7550201e-01, -5.3963661e-01,\n",
            "       -1.3578176e+00, -8.8025254e-01, -2.3027081e+00,  1.0348009e+01,\n",
            "       -1.2389160e+01,  6.0562067e+00], dtype=float32), 'agent_3': Array([ 5.2083981e-01, -9.3620116e-01, -1.3762395e-02,  1.3559723e-03,\n",
            "        3.5119265e-01, -3.9930883e-01, -3.9402094e-01, -3.9260909e-01,\n",
            "       -3.2302949e-01,  9.3378967e-01, -4.7550201e-01, -5.3963661e-01,\n",
            "       -1.3578176e+00, -8.8025254e-01, -2.3027081e+00,  1.0348009e+01,\n",
            "       -1.0829699e+01,  4.1858978e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.10923129 -0.44165242 -0.11103788 -0.43781486 -0.11083338 -0.4393273\n",
            " -0.10780142 -0.435269  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.272135, dtype=float32), 'agent_0': Array(-3.272135, dtype=float32), 'agent_1': Array(-3.272135, dtype=float32), 'agent_2': Array(-3.272135, dtype=float32), 'agent_3': Array(-3.272135, dtype=float32)}\n",
            "step: 454\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4698883 , -0.9605761 ,  0.00414302,  0.00810862,  0.277868  ,\n",
            "       -0.5403603 ,  0.80432075, -0.54102737, -0.54518664, -0.5211692 ,\n",
            "       -0.75917244,  0.21309853, -0.33561587, -0.60098654, -0.344795  ,\n",
            "        0.22074728,  1.0345402 , -2.8550744 ], dtype=float32), 'agent_1': Array([ 0.4698883 , -0.9605761 ,  0.00414302,  0.00810862,  0.277868  ,\n",
            "       -0.5403603 , -0.54102737, -0.7103862 , -0.54518664, -0.5211692 ,\n",
            "       -0.75917244,  0.21309853, -0.33561587, -0.60098654, -0.344795  ,\n",
            "        0.22074728,  0.71928126, -0.5337014 ], dtype=float32), 'agent_2': Array([ 0.4698883 , -0.9605761 ,  0.00414302,  0.00810862,  0.277868  ,\n",
            "       -0.5403603 , -0.54102737, -0.54518664, -0.746152  , -0.5211692 ,\n",
            "       -0.75917244,  0.21309853, -0.33561587, -0.60098654, -0.344795  ,\n",
            "        0.22074728,  0.96326065, -1.1685636 ], dtype=float32), 'agent_3': Array([ 0.4698883 , -0.9605761 ,  0.00414302,  0.00810862,  0.277868  ,\n",
            "       -0.5403603 , -0.54102737, -0.54518664, -0.5211692 ,  0.81558657,\n",
            "       -0.75917244,  0.21309853, -0.33561587, -0.60098654, -0.344795  ,\n",
            "        0.22074728, -1.3510138 , -3.925662  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5493177  -1.9058276   0.5470048  -1.9009602   0.547381   -1.9018552\n",
            "  0.54754007 -1.9050264 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.19297361, dtype=float32), 'agent_0': Array(-0.19297361, dtype=float32), 'agent_1': Array(-0.19297361, dtype=float32), 'agent_2': Array(-0.19297361, dtype=float32), 'agent_3': Array(-0.19297361, dtype=float32)}\n",
            "step: 455\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.6271676e-01, -9.1631514e-01, -1.5429240e-03, -1.0230181e-02,\n",
            "        4.0032431e-01, -1.5779997e-01,  4.7265488e-01, -1.8866444e-01,\n",
            "       -1.5785185e-01, -2.2019577e-01, -4.9605370e-01,  5.3820610e-01,\n",
            "        5.1980019e-01,  1.5915725e-01,  2.0304780e+00, -7.9975848e+00,\n",
            "        1.0712395e+01, -6.6535401e+00], dtype=float32), 'agent_1': Array([ 4.6271676e-01, -9.1631514e-01, -1.5429240e-03, -1.0230181e-02,\n",
            "        4.0032431e-01, -1.5779997e-01, -1.8866444e-01, -9.2686176e-01,\n",
            "       -1.5785185e-01, -2.2019577e-01, -4.9605370e-01,  5.3820610e-01,\n",
            "        5.1980019e-01,  1.5915725e-01,  2.0304780e+00, -7.9975848e+00,\n",
            "        9.3657284e+00, -5.5027170e+00], dtype=float32), 'agent_2': Array([ 4.6271676e-01, -9.1631514e-01, -1.5429240e-03, -1.0230181e-02,\n",
            "        4.0032431e-01, -1.5779997e-01, -1.8866444e-01, -1.5785185e-01,\n",
            "       -9.5736349e-01, -2.2019577e-01, -4.9605370e-01,  5.3820610e-01,\n",
            "        5.1980019e-01,  1.5915725e-01,  2.0304780e+00, -7.9975848e+00,\n",
            "        1.1069540e+01, -5.2011762e+00], dtype=float32), 'agent_3': Array([ 4.6271676e-01, -9.1631514e-01, -1.5429240e-03, -1.0230181e-02,\n",
            "        4.0032431e-01, -1.5779997e-01, -1.8866444e-01, -1.5785185e-01,\n",
            "       -2.2019577e-01,  4.5936382e-01, -4.9605370e-01,  5.3820610e-01,\n",
            "        5.1980019e-01,  1.5915725e-01,  2.0304780e+00, -7.9975848e+00,\n",
            "        9.2727852e+00, -5.3712878e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.54204124 -0.8378197   0.54025954 -0.83560055  0.5429292  -0.8349349\n",
            "  0.54055935 -0.8334388 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.5835323, dtype=float32), 'agent_0': Array(-7.5835323, dtype=float32), 'agent_1': Array(-7.5835323, dtype=float32), 'agent_2': Array(-7.5835323, dtype=float32), 'agent_3': Array(-7.5835323, dtype=float32)}\n",
            "step: 456\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3926039e-01, -8.2002807e-01,  8.9944561e-04, -3.3053722e-02,\n",
            "        5.7136738e-01,  3.8358623e-01,  4.5697129e-01,  2.4995162e-01,\n",
            "        4.3686771e-01,  2.4284150e-01, -5.5470467e-01,  4.7364235e-01,\n",
            "        2.4034739e+00, -7.0246613e-01,  9.0114325e-01, -7.6238995e+00,\n",
            "        1.0601096e+01,  1.5116222e-01], dtype=float32), 'agent_1': Array([ 5.3926039e-01, -8.2002807e-01,  8.9944561e-04, -3.3053722e-02,\n",
            "        5.7136738e-01,  3.8358623e-01,  2.4995162e-01, -1.1037710e+00,\n",
            "        4.3686771e-01,  2.4284150e-01, -5.5470467e-01,  4.7364235e-01,\n",
            "        2.4034739e+00, -7.0246613e-01,  9.0114325e-01, -7.6238995e+00,\n",
            "        8.5252581e+00, -2.5196483e+00], dtype=float32), 'agent_2': Array([ 5.3926039e-01, -8.2002807e-01,  8.9944561e-04, -3.3053722e-02,\n",
            "        5.7136738e-01,  3.8358623e-01,  2.4995162e-01,  4.3686771e-01,\n",
            "       -1.1590834e+00,  2.4284150e-01, -5.5470467e-01,  4.7364235e-01,\n",
            "        2.4034739e+00, -7.0246613e-01,  9.0114325e-01, -7.6238995e+00,\n",
            "        1.2136924e+01, -4.0852003e+00], dtype=float32), 'agent_3': Array([ 5.3926039e-01, -8.2002807e-01,  8.9944561e-04, -3.3053722e-02,\n",
            "        5.7136738e-01,  3.8358623e-01,  2.4995162e-01,  4.3686771e-01,\n",
            "        2.4284150e-01,  4.5922551e-01, -5.5470467e-01,  4.7364235e-01,\n",
            "        2.4034739e+00, -7.0246613e-01,  9.0114325e-01, -7.6238995e+00,\n",
            "        9.1490602e+00,  3.8350603e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.79484934 -0.45077088  0.7874118  -0.45831847  0.79158366 -0.45804864\n",
            "  0.7935192  -0.449079  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4882483, dtype=float32), 'agent_0': Array(-1.4882483, dtype=float32), 'agent_1': Array(-1.4882483, dtype=float32), 'agent_2': Array(-1.4882483, dtype=float32), 'agent_3': Array(-1.4882483, dtype=float32)}\n",
            "step: 457\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6512742 , -0.77143544,  0.00321953, -0.05786596,  0.6336629 ,\n",
            "        0.5841908 ,  0.52209395,  0.50339127,  0.60382485,  0.5190817 ,\n",
            "       -0.46453476,  0.47783852,  1.9105196 , -0.22071604,  0.81301296,\n",
            "       -0.29897478, -0.41526523,  1.1161306 ], dtype=float32), 'agent_1': Array([ 0.6512742 , -0.77143544,  0.00321953, -0.05786596,  0.6336629 ,\n",
            "        0.5841908 ,  0.50339127, -1.2765601 ,  0.60382485,  0.5190817 ,\n",
            "       -0.46453476,  0.47783852,  1.9105196 , -0.22071604,  0.81301296,\n",
            "       -0.29897478,  3.013377  , -2.3252578 ], dtype=float32), 'agent_2': Array([ 0.6512742 , -0.77143544,  0.00321953, -0.05786596,  0.6336629 ,\n",
            "        0.5841908 ,  0.50339127,  0.60382485, -1.2814212 ,  0.5190817 ,\n",
            "       -0.46453476,  0.47783852,  1.9105196 , -0.22071604,  0.81301296,\n",
            "       -0.29897478, -1.6930497 , -0.25260937], dtype=float32), 'agent_3': Array([ 0.6512742 , -0.77143544,  0.00321953, -0.05786596,  0.6336629 ,\n",
            "        0.5841908 ,  0.50339127,  0.60382485,  0.5190817 ,  0.5214381 ,\n",
            "       -0.46453476,  0.47783852,  1.9105196 , -0.22071604,  0.81301296,\n",
            "       -0.29897478,  3.0052133 ,  0.4900635 ], dtype=float32)}\n",
            "ctrl action chosen: [0.93564034 0.07616738 0.935744   0.07258771 0.9380822  0.07326137\n",
            " 0.9387012  0.0792042 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1951225, dtype=float32), 'agent_0': Array(-1.1951225, dtype=float32), 'agent_1': Array(-1.1951225, dtype=float32), 'agent_2': Array(-1.1951225, dtype=float32), 'agent_3': Array(-1.1951225, dtype=float32)}\n",
            "step: 458\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7067798 , -0.78092927,  0.00552409, -0.05520341,  0.62215084,\n",
            "        0.5156636 ,  0.72205603,  0.583471  ,  0.47045964,  0.57777554,\n",
            "       -0.36644936,  0.30622482,  0.5402565 , -0.06791073, -0.23838453,\n",
            "        0.84094393, -1.0413759 ,  4.298514  ], dtype=float32), 'agent_1': Array([ 0.7067798 , -0.78092927,  0.00552409, -0.05520341,  0.62215084,\n",
            "        0.5156636 ,  0.583471  , -1.2297757 ,  0.47045964,  0.57777554,\n",
            "       -0.36644936,  0.30622482,  0.5402565 , -0.06791073, -0.23838453,\n",
            "        0.84094393,  0.5066826 ,  1.1622349 ], dtype=float32), 'agent_2': Array([ 0.7067798 , -0.78092927,  0.00552409, -0.05520341,  0.62215084,\n",
            "        0.5156636 ,  0.583471  ,  0.47045964, -1.2120037 ,  0.57777554,\n",
            "       -0.36644936,  0.30622482,  0.5402565 , -0.06791073, -0.23838453,\n",
            "        0.84094393, -1.9839038 ,  1.8075789 ], dtype=float32), 'agent_3': Array([ 0.7067798 , -0.78092927,  0.00552409, -0.05520341,  0.62215084,\n",
            "        0.5156636 ,  0.583471  ,  0.47045964,  0.57777554,  0.67847824,\n",
            "       -0.36644936,  0.30622482,  0.5402565 , -0.06791073, -0.23838453,\n",
            "        0.84094393,  0.33080122,  3.5873842 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.34786302 -2.2852826   0.34993836 -2.275522    0.34709102 -2.279604\n",
            "  0.34799707 -2.2800856 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1482757, dtype=float32), 'agent_0': Array(-1.1482757, dtype=float32), 'agent_1': Array(-1.1482757, dtype=float32), 'agent_2': Array(-1.1482757, dtype=float32), 'agent_3': Array(-1.1482757, dtype=float32)}\n",
            "step: 459\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.3081869e-01, -7.9662126e-01,  1.4777037e-03, -9.6392795e-02,\n",
            "        5.9674186e-01,  4.6648318e-01,  5.1756907e-01,  5.3994930e-01,\n",
            "        3.9714372e-01,  5.4479384e-01, -5.7463646e-01,  5.1114559e-01,\n",
            "        2.8783083e-01, -1.0983869e+00,  1.6517435e+00,  2.1065343e-02,\n",
            "        8.2948029e-01, -7.2282419e+00], dtype=float32), 'agent_1': Array([ 7.3081869e-01, -7.9662126e-01,  1.4777037e-03, -9.6392795e-02,\n",
            "        5.9674186e-01,  4.6648318e-01,  5.3994930e-01, -1.2556133e+00,\n",
            "        3.9714372e-01,  5.4479384e-01, -5.7463646e-01,  5.1114559e-01,\n",
            "        2.8783083e-01, -1.0983869e+00,  1.6517435e+00,  2.1065343e-02,\n",
            "       -4.8989922e-01, -3.8496190e-01], dtype=float32), 'agent_2': Array([ 7.3081869e-01, -7.9662126e-01,  1.4777037e-03, -9.6392795e-02,\n",
            "        5.9674186e-01,  4.6648318e-01,  5.3994930e-01,  3.9714372e-01,\n",
            "       -1.2560614e+00,  5.4479384e-01, -5.7463646e-01,  5.1114559e-01,\n",
            "        2.8783083e-01, -1.0983869e+00,  1.6517435e+00,  2.1065343e-02,\n",
            "        9.8775065e-01, -7.7382523e-01], dtype=float32), 'agent_3': Array([ 7.3081869e-01, -7.9662126e-01,  1.4777037e-03, -9.6392795e-02,\n",
            "        5.9674186e-01,  4.6648318e-01,  5.3994930e-01,  3.9714372e-01,\n",
            "        5.4479384e-01,  4.7480354e-01, -5.7463646e-01,  5.1114559e-01,\n",
            "        2.8783083e-01, -1.0983869e+00,  1.6517435e+00,  2.1065343e-02,\n",
            "       -1.7437302e-01, -4.1438475e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.03639521 -2.0889018  -0.03960042 -2.0840662  -0.04032961 -2.081696\n",
            " -0.04037029 -2.0856872 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.175758, dtype=float32), 'agent_0': Array(-10.175758, dtype=float32), 'agent_1': Array(-10.175758, dtype=float32), 'agent_2': Array(-10.175758, dtype=float32), 'agent_3': Array(-10.175758, dtype=float32)}\n",
            "step: 460\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7242476 , -0.81168395,  0.0024463 , -0.11539209,  0.5725801 ,\n",
            "        0.45576492,  0.46470457,  0.45536405,  0.38017207,  0.4693408 ,\n",
            "       -0.36263466,  0.37174225, -0.16133785, -0.44290376,  0.50788736,\n",
            "        1.0627244 , -0.00405721, -0.23658356], dtype=float32), 'agent_1': Array([ 0.7242476 , -0.81168395,  0.0024463 , -0.11539209,  0.5725801 ,\n",
            "        0.45576492,  0.45536405, -1.2564235 ,  0.38017207,  0.4693408 ,\n",
            "       -0.36263466,  0.37174225, -0.16133785, -0.44290376,  0.50788736,\n",
            "        1.0627244 , -1.6112318 ,  0.09337063], dtype=float32), 'agent_2': Array([ 0.7242476 , -0.81168395,  0.0024463 , -0.11539209,  0.5725801 ,\n",
            "        0.45576492,  0.45536405,  0.38017207, -1.2660497 ,  0.4693408 ,\n",
            "       -0.36263466,  0.37174225, -0.16133785, -0.44290376,  0.50788736,\n",
            "        1.0627244 , -0.20314085,  0.4438055 ], dtype=float32), 'agent_3': Array([ 0.7242476 , -0.81168395,  0.0024463 , -0.11539209,  0.5725801 ,\n",
            "        0.45576492,  0.45536405,  0.38017207,  0.4693408 ,  0.46715835,\n",
            "       -0.36263466,  0.37174225, -0.16133785, -0.44290376,  0.50788736,\n",
            "        1.0627244 , -1.6070135 , -0.25998348], dtype=float32)}\n",
            "ctrl action chosen: [-1.5800668   0.43545887 -1.5782067   0.4346503  -1.5796591   0.4362598\n",
            " -1.5797008   0.43386197]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.145539, dtype=float32), 'agent_0': Array(-8.145539, dtype=float32), 'agent_1': Array(-8.145539, dtype=float32), 'agent_2': Array(-8.145539, dtype=float32), 'agent_3': Array(-8.145539, dtype=float32)}\n",
            "step: 461\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.7144843 ,  -0.9306383 ,  -0.01942501,  -0.10681488,\n",
            "         0.34946507,  -0.11223121,   0.61015177,  -0.16728438,\n",
            "        -0.20139469,  -0.1647072 ,  -0.29358864,   0.35114288,\n",
            "        -0.4100561 ,  -0.13935977,  -0.34794107,  13.063539  ,\n",
            "       -15.163696  ,   3.8387082 ], dtype=float32), 'agent_1': Array([  0.7144843 ,  -0.9306383 ,  -0.01942501,  -0.10681488,\n",
            "         0.34946507,  -0.11223121,  -0.16728438,  -1.1076108 ,\n",
            "        -0.20139469,  -0.1647072 ,  -0.29358864,   0.35114288,\n",
            "        -0.4100561 ,  -0.13935977,  -0.34794107,  13.063539  ,\n",
            "       -16.043516  ,   3.2495527 ], dtype=float32), 'agent_2': Array([  0.7144843 ,  -0.9306383 ,  -0.01942501,  -0.10681488,\n",
            "         0.34946507,  -0.11223121,  -0.16728438,  -0.20139469,\n",
            "        -1.0872191 ,  -0.1647072 ,  -0.29358864,   0.35114288,\n",
            "        -0.4100561 ,  -0.13935977,  -0.34794107,  13.063539  ,\n",
            "       -15.468782  ,   4.215092  ], dtype=float32), 'agent_3': Array([  0.7144843 ,  -0.9306383 ,  -0.01942501,  -0.10681488,\n",
            "         0.34946507,  -0.11223121,  -0.16728438,  -0.20139469,\n",
            "        -0.1647072 ,   0.6295748 ,  -0.29358864,   0.35114288,\n",
            "        -0.4100561 ,  -0.13935977,  -0.34794107,  13.063539  ,\n",
            "       -16.421463  ,   4.265722  ], dtype=float32)}\n",
            "ctrl action chosen: [1.0321833 0.8680651 1.0355558 0.8675829 1.0316437 0.8683552 1.0331433\n",
            " 0.8688672]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.6472607, dtype=float32), 'agent_0': Array(-4.6472607, dtype=float32), 'agent_1': Array(-4.6472607, dtype=float32), 'agent_2': Array(-4.6472607, dtype=float32), 'agent_3': Array(-4.6472607, dtype=float32)}\n",
            "step: 462\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.66936594, -0.8976233 ,  0.01409112, -0.06837507,  0.43519968,\n",
            "        0.1654155 ,  1.037305  ,  0.05737615,  0.06080347,  0.03775106,\n",
            "       -0.12960434,  0.08203983, -1.2776494 , -0.20014544, -2.727818  ,\n",
            "       -8.891825  , 12.472376  ,  9.700258  ], dtype=float32), 'agent_1': Array([ 0.66936594, -0.8976233 ,  0.01409112, -0.06837507,  0.43519968,\n",
            "        0.1654155 ,  0.05737615, -0.72773445,  0.06080347,  0.03775106,\n",
            "       -0.12960434,  0.08203983, -1.2776494 , -0.20014544, -2.727818  ,\n",
            "       -8.891825  , 11.253477  , 10.587998  ], dtype=float32), 'agent_2': Array([ 0.66936594, -0.8976233 ,  0.01409112, -0.06837507,  0.43519968,\n",
            "        0.1654155 ,  0.05737615,  0.06080347, -0.6689288 ,  0.03775106,\n",
            "       -0.12960434,  0.08203983, -1.2776494 , -0.20014544, -2.727818  ,\n",
            "       -8.891825  , 12.261659  , 10.870529  ], dtype=float32), 'agent_3': Array([ 0.66936594, -0.8976233 ,  0.01409112, -0.06837507,  0.43519968,\n",
            "        0.1654155 ,  0.05737615,  0.06080347,  0.03775106,  1.0800924 ,\n",
            "       -0.12960434,  0.08203983, -1.2776494 , -0.20014544, -2.727818  ,\n",
            "       -8.891825  , 10.677574  , 11.544722  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.4418049  -0.5479865  -1.4441321  -0.54791087 -1.4447242  -0.5446996\n",
            " -1.4468665  -0.5465323 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8565207, dtype=float32), 'agent_0': Array(-2.8565207, dtype=float32), 'agent_1': Array(-2.8565207, dtype=float32), 'agent_2': Array(-2.8565207, dtype=float32), 'agent_3': Array(-2.8565207, dtype=float32)}\n",
            "step: 463\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.3167506e-01, -9.5005846e-01,  2.3622885e-03, -5.1603824e-02,\n",
            "        3.0776685e-01, -7.9786070e-02,  1.1238118e+00, -2.7068150e-01,\n",
            "       -2.0727488e-01, -3.1131241e-01, -2.3984909e-01,  3.5085678e-01,\n",
            "       -2.6378632e-01,  7.7608240e-01,  2.9727405e-01,  9.7557602e+00,\n",
            "       -1.0965708e+01, -1.2742792e+00], dtype=float32), 'agent_1': Array([ 6.3167506e-01, -9.5005846e-01,  2.3622885e-03, -5.1603824e-02,\n",
            "        3.0776685e-01, -7.9786070e-02, -2.7068150e-01, -5.5788314e-01,\n",
            "       -2.0727488e-01, -3.1131241e-01, -2.3984909e-01,  3.5085678e-01,\n",
            "       -2.6378632e-01,  7.7608240e-01,  2.9727405e-01,  9.7557602e+00,\n",
            "       -1.2488466e+01, -2.5318816e-01], dtype=float32), 'agent_2': Array([ 6.3167506e-01, -9.5005846e-01,  2.3622885e-03, -5.1603824e-02,\n",
            "        3.0776685e-01, -7.9786070e-02, -2.7068150e-01, -2.0727488e-01,\n",
            "       -5.0375986e-01, -3.1131241e-01, -2.3984909e-01,  3.5085678e-01,\n",
            "       -2.6378632e-01,  7.7608240e-01,  2.9727405e-01,  9.7557602e+00,\n",
            "       -1.1299506e+01, -6.9709039e-01], dtype=float32), 'agent_3': Array([ 6.3167506e-01, -9.5005846e-01,  2.3622885e-03, -5.1603824e-02,\n",
            "        3.0776685e-01, -7.9786070e-02, -2.7068150e-01, -2.0727488e-01,\n",
            "       -3.1131241e-01,  1.2295487e+00, -2.3984909e-01,  3.5085678e-01,\n",
            "       -2.6378632e-01,  7.7608240e-01,  2.9727405e-01,  9.7557602e+00,\n",
            "       -1.2462297e+01, -1.5950286e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.42274344 1.8759239  0.42322934 1.8758913  0.42251268 1.8770314\n",
            " 0.42519972 1.8802893 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.816855, dtype=float32), 'agent_0': Array(-3.816855, dtype=float32), 'agent_1': Array(-3.816855, dtype=float32), 'agent_2': Array(-3.816855, dtype=float32), 'agent_3': Array(-3.816855, dtype=float32)}\n",
            "step: 464\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.64681506, -0.9517036 ,  0.01011722, -0.02130507,  0.3061114 ,\n",
            "       -0.09109189,  1.257943  , -0.3106179 , -0.19034177, -0.3717737 ,\n",
            "       -0.29935837, -0.0718832 ,  0.26898384,  0.4679392 , -0.33422774,\n",
            "       -2.6443613 ,  3.1206317 , -0.04119934], dtype=float32), 'agent_1': Array([ 0.64681506, -0.9517036 ,  0.01011722, -0.02130507,  0.3061114 ,\n",
            "       -0.09109189, -0.3106179 , -0.47056386, -0.19034177, -0.3717737 ,\n",
            "       -0.29935837, -0.0718832 ,  0.26898384,  0.4679392 , -0.33422774,\n",
            "       -2.6443613 ,  3.1487265 , -0.8671602 ], dtype=float32), 'agent_2': Array([ 0.64681506, -0.9517036 ,  0.01011722, -0.02130507,  0.3061114 ,\n",
            "       -0.09109189, -0.3106179 , -0.19034177, -0.4788868 , -0.3717737 ,\n",
            "       -0.29935837, -0.0718832 ,  0.26898384,  0.4679392 , -0.33422774,\n",
            "       -2.6443613 ,  3.9664974 , -1.1352952 ], dtype=float32), 'agent_3': Array([ 0.64681506, -0.9517036 ,  0.01011722, -0.02130507,  0.3061114 ,\n",
            "       -0.09109189, -0.3106179 , -0.19034177, -0.3717737 ,  1.2639636 ,\n",
            "       -0.29935837, -0.0718832 ,  0.26898384,  0.4679392 , -0.33422774,\n",
            "       -2.6443613 ,  2.2367878 , -1.1694452 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.5966594  1.0678053 -1.5988133  1.0654471 -1.5975635  1.0653132\n",
            " -1.5990803  1.0681658]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.7635446, dtype=float32), 'agent_0': Array(-6.7635446, dtype=float32), 'agent_1': Array(-6.7635446, dtype=float32), 'agent_2': Array(-6.7635446, dtype=float32), 'agent_3': Array(-6.7635446, dtype=float32)}\n",
            "step: 465\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.64873403, -0.97964674,  0.00633037, -0.00705224,  0.2005057 ,\n",
            "       -0.40816316,  1.2816478 , -0.58097756, -0.47812542, -0.6044288 ,\n",
            "       -0.6204605 , -0.24960041, -0.23978949, -0.02803039, -0.866909  ,\n",
            "        1.8921831 , -5.163082  ,  0.2662284 ], dtype=float32), 'agent_1': Array([ 0.64873403, -0.97964674,  0.00633037, -0.00705224,  0.2005057 ,\n",
            "       -0.40816316, -0.58097756, -0.48395956, -0.47812542, -0.6044288 ,\n",
            "       -0.6204605 , -0.24960041, -0.23978949, -0.02803039, -0.866909  ,\n",
            "        1.8921831 , -1.9268845 , -0.20490249], dtype=float32), 'agent_2': Array([ 0.64873403, -0.97964674,  0.00633037, -0.00705224,  0.2005057 ,\n",
            "       -0.40816316, -0.58097756, -0.47812542, -0.49793354, -0.6044288 ,\n",
            "       -0.6204605 , -0.24960041, -0.23978949, -0.02803039, -0.866909  ,\n",
            "        1.8921831 , -4.8480325 ,  0.16709386], dtype=float32), 'agent_3': Array([ 0.64873403, -0.97964674,  0.00633037, -0.00705224,  0.2005057 ,\n",
            "       -0.40816316, -0.58097756, -0.47812542, -0.6044288 ,  1.2502322 ,\n",
            "       -0.6204605 , -0.24960041, -0.23978949, -0.02803039, -0.866909  ,\n",
            "        1.8921831 , -0.09480765,  0.29804528], dtype=float32)}\n",
            "ctrl action chosen: [-0.1682449  -1.7087365  -0.16930977 -1.7023704  -0.16864575 -1.7063073\n",
            " -0.16917826 -1.6935242 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.857997, dtype=float32), 'agent_0': Array(-6.857997, dtype=float32), 'agent_1': Array(-6.857997, dtype=float32), 'agent_2': Array(-6.857997, dtype=float32), 'agent_3': Array(-6.857997, dtype=float32)}\n",
            "step: 466\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6255275 , -0.97786754, -0.03069391, -0.02734879,  0.20514663,\n",
            "       -0.53711057,  0.98376745, -0.5180366 , -0.5500329 , -0.4686298 ,\n",
            "       -0.65140724,  0.19619465, -0.6702781 ,  1.7502382 ,  1.8242301 ,\n",
            "       -1.141088  , -1.3547616 , -8.946577  ], dtype=float32), 'agent_1': Array([  0.6255275 ,  -0.97786754,  -0.03069391,  -0.02734879,\n",
            "         0.20514663,  -0.53711057,  -0.5180366 ,  -0.8510496 ,\n",
            "        -0.5500329 ,  -0.4686298 ,  -0.65140724,   0.19619465,\n",
            "        -0.6702781 ,   1.7502382 ,   1.8242301 ,  -1.141088  ,\n",
            "         2.677864  , -10.139064  ], dtype=float32), 'agent_2': Array([ 0.6255275 , -0.97786754, -0.03069391, -0.02734879,  0.20514663,\n",
            "       -0.53711057, -0.5180366 , -0.5500329 , -0.84806037, -0.4686298 ,\n",
            "       -0.65140724,  0.19619465, -0.6702781 ,  1.7502382 ,  1.8242301 ,\n",
            "       -1.141088  ,  0.43134722, -8.955797  ], dtype=float32), 'agent_3': Array([ 0.6255275 , -0.97786754, -0.03069391, -0.02734879,  0.20514663,\n",
            "       -0.53711057, -0.5180366 , -0.5500329 , -0.4686298 ,  0.9341993 ,\n",
            "       -0.65140724,  0.19619465, -0.6702781 ,  1.7502382 ,  1.8242301 ,\n",
            "       -1.141088  ,  4.3646684 , -8.651049  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.27505144 -0.12109554  0.27458867 -0.12074517  0.27313602 -0.11887174\n",
            "  0.27257305 -0.11788552]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.5062485, dtype=float32), 'agent_0': Array(-5.5062485, dtype=float32), 'agent_1': Array(-5.5062485, dtype=float32), 'agent_2': Array(-5.5062485, dtype=float32), 'agent_3': Array(-5.5062485, dtype=float32)}\n",
            "step: 467\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5730165 , -0.9493927 , -0.05712841, -0.05247606,  0.30436197,\n",
            "       -0.41507983,  0.6367438 , -0.22320123, -0.3523399 , -0.11292588,\n",
            "       -0.58174133,  0.02293587, -1.3618946 ,  0.7677659 ,  1.0796729 ,\n",
            "       -4.1011724 ,  3.092421  , -6.7086596 ], dtype=float32), 'agent_1': Array([ 0.5730165 , -0.9493927 , -0.05712841, -0.05247606,  0.30436197,\n",
            "       -0.41507983, -0.22320123, -1.2017508 , -0.3523399 , -0.11292588,\n",
            "       -0.58174133,  0.02293587, -1.3618946 ,  0.7677659 ,  1.0796729 ,\n",
            "       -4.1011724 ,  5.60468   , -6.3271136 ], dtype=float32), 'agent_2': Array([ 0.5730165 , -0.9493927 , -0.05712841, -0.05247606,  0.30436197,\n",
            "       -0.41507983, -0.22320123, -0.3523399 , -1.1359688 , -0.11292588,\n",
            "       -0.58174133,  0.02293587, -1.3618946 ,  0.7677659 ,  1.0796729 ,\n",
            "       -4.1011724 ,  4.738958  , -5.8339953 ], dtype=float32), 'agent_3': Array([ 0.5730165 , -0.9493927 , -0.05712841, -0.05247606,  0.30436197,\n",
            "       -0.41507983, -0.22320123, -0.3523399 , -0.11292588,  0.6490932 ,\n",
            "       -0.58174133,  0.02293587, -1.3618946 ,  0.7677659 ,  1.0796729 ,\n",
            "       -4.1011724 ,  6.3288155 , -5.2443514 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.13542487 -0.08934975 -0.13809276 -0.09070151 -0.13788201 -0.08769332\n",
            " -0.13749945 -0.08831023]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.2267203, dtype=float32), 'agent_0': Array(0.2267203, dtype=float32), 'agent_1': Array(0.2267203, dtype=float32), 'agent_2': Array(0.2267203, dtype=float32), 'agent_3': Array(0.2267203, dtype=float32)}\n",
            "step: 468\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50995594, -0.94541645, -0.06392875, -0.06105343,  0.31364515,\n",
            "       -0.4644964 ,  0.48851433, -0.16577011, -0.3469993 , -0.03146993,\n",
            "       -0.32467842, -0.3091097 , -1.1981606 , -0.06179667, -1.0860572 ,\n",
            "        0.5882111 , -2.2491302 ,  1.668214  ], dtype=float32), 'agent_1': Array([ 0.50995594, -0.94541645, -0.06392875, -0.06105343,  0.31364515,\n",
            "       -0.4644964 , -0.16577011, -1.2444807 , -0.3469993 , -0.03146993,\n",
            "       -0.32467842, -0.3091097 , -1.1981606 , -0.06179667, -1.0860572 ,\n",
            "        0.5882111 , -0.03706022,  1.0276293 ], dtype=float32), 'agent_2': Array([ 0.50995594, -0.94541645, -0.06392875, -0.06105343,  0.31364515,\n",
            "       -0.4644964 , -0.16577011, -0.3469993 , -1.2457254 , -0.03146993,\n",
            "       -0.32467842, -0.3091097 , -1.1981606 , -0.06179667, -1.0860572 ,\n",
            "        0.5882111 , -1.5080453 ,  1.3702756 ], dtype=float32), 'agent_3': Array([ 0.50995594, -0.94541645, -0.06392875, -0.06105343,  0.31364515,\n",
            "       -0.4644964 , -0.16577011, -0.3469993 , -0.03146993,  0.49196392,\n",
            "       -0.32467842, -0.3091097 , -1.1981606 , -0.06179667, -1.0860572 ,\n",
            "        0.5882111 ,  0.06112403,  0.79596937], dtype=float32)}\n",
            "ctrl action chosen: [-1.8168317   0.14644462 -1.8129213   0.1521127  -1.8156487   0.1494789\n",
            " -1.8135246   0.15278569]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.38549286, dtype=float32), 'agent_0': Array(0.38549286, dtype=float32), 'agent_1': Array(0.38549286, dtype=float32), 'agent_2': Array(0.38549286, dtype=float32), 'agent_3': Array(0.38549286, dtype=float32)}\n",
            "step: 469\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49942008, -0.96845555, -0.05849494, -0.04254391,  0.23845804,\n",
            "       -0.6033684 ,  0.58073527, -0.41662776, -0.6049621 , -0.31789854,\n",
            "        0.35419464, -0.11031628,  0.15972257, -0.27139145, -0.41613886,\n",
            "        0.67270243,  1.1111087 ,  2.7050002 ], dtype=float32), 'agent_1': Array([ 0.49942008, -0.96845555, -0.05849494, -0.04254391,  0.23845804,\n",
            "       -0.6033684 , -0.41662776, -1.1340774 , -0.6049621 , -0.31789854,\n",
            "        0.35419464, -0.11031628,  0.15972257, -0.27139145, -0.41613886,\n",
            "        0.67270243, -3.741521  ,  3.269511  ], dtype=float32), 'agent_2': Array([ 0.49942008, -0.96845555, -0.05849494, -0.04254391,  0.23845804,\n",
            "       -0.6033684 , -0.41662776, -0.6049621 , -1.1267177 , -0.31789854,\n",
            "        0.35419464, -0.11031628,  0.15972257, -0.27139145, -0.41613886,\n",
            "        0.67270243, -1.3056611 ,  2.8342202 ], dtype=float32), 'agent_3': Array([ 0.49942008, -0.96845555, -0.05849494, -0.04254391,  0.23845804,\n",
            "       -0.6033684 , -0.41662776, -0.6049621 , -0.31789854,  0.5291593 ,\n",
            "        0.35419464, -0.11031628,  0.15972257, -0.27139145, -0.41613886,\n",
            "        0.67270243, -4.6509285 ,  0.23545115], dtype=float32)}\n",
            "ctrl action chosen: [-1.1807461 -1.322939  -1.1817578 -1.3301034 -1.1809509 -1.3259932\n",
            " -1.1787045 -1.330839 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.5628486, dtype=float32), 'agent_0': Array(-5.5628486, dtype=float32), 'agent_1': Array(-5.5628486, dtype=float32), 'agent_2': Array(-5.5628486, dtype=float32), 'agent_3': Array(-5.5628486, dtype=float32)}\n",
            "step: 470\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5058874 , -0.96620125, -0.07069761, -0.07067184,  0.23761858,\n",
            "       -0.48987702,  0.47553495, -0.5813709 , -0.5527012 , -0.557357  ,\n",
            "        0.59189796,  0.5887747 ,  0.10682344,  0.01945738,  1.2572119 ,\n",
            "       -1.5222232 ,  2.6382518 , -1.0039464 ], dtype=float32), 'agent_1': Array([ 0.5058874 , -0.96620125, -0.07069761, -0.07067184,  0.23761858,\n",
            "       -0.48987702, -0.5813709 , -1.2679003 , -0.5527012 , -0.557357  ,\n",
            "        0.59189796,  0.5887747 ,  0.10682344,  0.01945738,  1.2572119 ,\n",
            "       -1.5222232 , -0.9765205 , -1.5378743 ], dtype=float32), 'agent_2': Array([ 0.5058874 , -0.96620125, -0.07069761, -0.07067184,  0.23761858,\n",
            "       -0.48987702, -0.5813709 , -0.5527012 , -1.2600943 , -0.557357  ,\n",
            "        0.59189796,  0.5887747 ,  0.10682344,  0.01945738,  1.2572119 ,\n",
            "       -1.5222232 ,  3.1244574 , -1.6495512 ], dtype=float32), 'agent_3': Array([ 0.5058874 , -0.96620125, -0.07069761, -0.07067184,  0.23761858,\n",
            "       -0.48987702, -0.5813709 , -0.5527012 , -0.557357  ,  0.47764558,\n",
            "        0.59189796,  0.5887747 ,  0.10682344,  0.01945738,  1.2572119 ,\n",
            "       -1.5222232 , -2.903483  , -0.11095105], dtype=float32)}\n",
            "ctrl action chosen: [0.84738666 0.82103956 0.84224653 0.8199616  0.8483795  0.82120955\n",
            " 0.8441981  0.82119995]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.7901387, dtype=float32), 'agent_0': Array(-4.7901387, dtype=float32), 'agent_1': Array(-4.7901387, dtype=float32), 'agent_2': Array(-4.7901387, dtype=float32), 'agent_3': Array(-4.7901387, dtype=float32)}\n",
            "step: 471\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.51073587,  -0.8829395 ,  -0.03113372,  -0.07012215,\n",
            "         0.46317536,   0.17605959,   0.69389653,  -0.14870295,\n",
            "         0.11709524,  -0.21802188,   0.66137314,   0.16741753,\n",
            "         0.0767231 ,  -0.5398301 ,  -0.5638044 , -11.747658  ,\n",
            "        15.373854  ,   5.0665784 ], dtype=float32), 'agent_1': Array([  0.51073587,  -0.8829395 ,  -0.03113372,  -0.07012215,\n",
            "         0.46317536,   0.17605959,  -0.14870295,  -1.0634844 ,\n",
            "         0.11709524,  -0.21802188,   0.66137314,   0.16741753,\n",
            "         0.0767231 ,  -0.5398301 ,  -0.5638044 , -11.747658  ,\n",
            "        12.531046  ,   4.648203  ], dtype=float32), 'agent_2': Array([  0.51073587,  -0.8829395 ,  -0.03113372,  -0.07012215,\n",
            "         0.46317536,   0.17605959,  -0.14870295,   0.11709524,\n",
            "        -1.0213325 ,  -0.21802188,   0.66137314,   0.16741753,\n",
            "         0.0767231 ,  -0.5398301 ,  -0.5638044 , -11.747658  ,\n",
            "        15.943453  ,   5.329678  ], dtype=float32), 'agent_3': Array([  0.51073587,  -0.8829395 ,  -0.03113372,  -0.07012215,\n",
            "         0.46317536,   0.17605959,  -0.14870295,   0.11709524,\n",
            "        -0.21802188,   0.7520346 ,   0.66137314,   0.16741753,\n",
            "         0.0767231 ,  -0.5398301 ,  -0.5638044 , -11.747658  ,\n",
            "         9.949192  ,   6.967198  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.16685192 -1.9861776  -0.17147201 -1.9882252  -0.16726063 -1.9825892\n",
            " -0.17173488 -1.9855171 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0610578, dtype=float32), 'agent_0': Array(-1.0610578, dtype=float32), 'agent_1': Array(-1.0610578, dtype=float32), 'agent_2': Array(-1.0610578, dtype=float32), 'agent_3': Array(-1.0610578, dtype=float32)}\n",
            "step: 472\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52312434, -0.8360562 , -0.02922694, -0.11474258,  0.5357145 ,\n",
            "        0.45952463,  0.4799186 , -0.01106179,  0.3902727 , -0.18092553,\n",
            "        0.41093826,  0.39839745,  0.35963058, -0.43627182,  1.5491955 ,\n",
            "       -0.9354886 ,  2.0201116 , -3.591061  ], dtype=float32), 'agent_1': Array([ 0.52312434, -0.8360562 , -0.02922694, -0.11474258,  0.5357145 ,\n",
            "        0.45952463, -0.01106179, -1.2273562 ,  0.3902727 , -0.18092553,\n",
            "        0.41093826,  0.39839745,  0.35963058, -0.43627182,  1.5491955 ,\n",
            "       -0.9354886 , -0.39288592, -4.0683694 ], dtype=float32), 'agent_2': Array([ 0.52312434, -0.8360562 , -0.02922694, -0.11474258,  0.5357145 ,\n",
            "        0.45952463, -0.01106179,  0.3902727 , -1.2007227 , -0.18092553,\n",
            "        0.41093826,  0.39839745,  0.35963058, -0.43627182,  1.5491955 ,\n",
            "       -0.9354886 ,  1.9257588 , -5.310951  ], dtype=float32), 'agent_3': Array([ 0.52312434, -0.8360562 , -0.02922694, -0.11474258,  0.5357145 ,\n",
            "        0.45952463, -0.01106179,  0.3902727 , -0.18092553,  0.61196244,\n",
            "        0.41093826,  0.39839745,  0.35963058, -0.43627182,  1.5491955 ,\n",
            "       -0.9354886 , -1.7356603 , -5.7178125 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.18974736 -0.09020989  0.18902503 -0.08948642  0.19186977 -0.0891905\n",
            "  0.19342506 -0.08930559]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.466831, dtype=float32), 'agent_0': Array(-6.466831, dtype=float32), 'agent_1': Array(-6.466831, dtype=float32), 'agent_2': Array(-6.466831, dtype=float32), 'agent_3': Array(-6.466831, dtype=float32)}\n",
            "step: 473\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5355301 , -0.8129601 , -0.03134339, -0.11277456,  0.5704345 ,\n",
            "        0.5517837 ,  0.50943977,  0.01200825,  0.5317249 , -0.20525575,\n",
            "        0.48322678,  0.18892288,  0.10653734, -0.22260007,  0.11373966,\n",
            "       -0.58704674, -0.11600839, -0.45567748], dtype=float32), 'agent_1': Array([ 0.5355301 , -0.8129601 , -0.03134339, -0.11277456,  0.5704345 ,\n",
            "        0.5517837 ,  0.01200825, -1.2422886 ,  0.5317249 , -0.20525575,\n",
            "        0.48322678,  0.18892288,  0.10653734, -0.22260007,  0.11373966,\n",
            "       -0.58704674, -0.24112871, -0.3007336 ], dtype=float32), 'agent_2': Array([ 0.5355301 , -0.8129601 , -0.03134339, -0.11277456,  0.5704345 ,\n",
            "        0.5517837 ,  0.01200825,  0.5317249 , -1.2291853 , -0.20525575,\n",
            "        0.48322678,  0.18892288,  0.10653734, -0.22260007,  0.11373966,\n",
            "       -0.58704674,  1.4895608 , -1.0178015 ], dtype=float32), 'agent_3': Array([ 0.5355301 , -0.8129601 , -0.03134339, -0.11277456,  0.5704345 ,\n",
            "        0.5517837 ,  0.01200825,  0.5317249 , -0.20525575,  0.49815592,\n",
            "        0.48322678,  0.18892288,  0.10653734, -0.22260007,  0.11373966,\n",
            "       -0.58704674, -1.2428241 , -0.6210319 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.6079823  -0.0613003   1.6071823  -0.05975908  1.6104294  -0.06073633\n",
            "  1.609559   -0.06102932]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.4293603, dtype=float32), 'agent_0': Array(1.4293603, dtype=float32), 'agent_1': Array(1.4293603, dtype=float32), 'agent_2': Array(1.4293603, dtype=float32), 'agent_3': Array(1.4293603, dtype=float32)}\n",
            "step: 474\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5398185 , -0.77510494, -0.02456161, -0.12095483,  0.61966044,\n",
            "        0.57831657,  0.51899666,  0.22666152,  0.59827733, -0.05025962,\n",
            "        0.36420822,  0.3205061 , -0.11898279, -0.02516599,  0.19551109,\n",
            "       -2.5745971 , -0.43147618,  0.26809338], dtype=float32), 'agent_1': Array([ 0.5398185 , -0.77510494, -0.02456161, -0.12095483,  0.61966044,\n",
            "        0.57831657,  0.22666152, -1.2270703 ,  0.59827733, -0.05025962,\n",
            "        0.36420822,  0.3205061 , -0.11898279, -0.02516599,  0.19551109,\n",
            "       -2.5745971 ,  5.704371  ,  0.42313582], dtype=float32), 'agent_2': Array([ 0.5398185 , -0.77510494, -0.02456161, -0.12095483,  0.61966044,\n",
            "        0.57831657,  0.22666152,  0.59827733, -1.2438761 , -0.05025962,\n",
            "        0.36420822,  0.3205061 , -0.11898279, -0.02516599,  0.19551109,\n",
            "       -2.5745971 , -0.13685347,  0.19340321], dtype=float32), 'agent_3': Array([ 0.5398185 , -0.77510494, -0.02456161, -0.12095483,  0.61966044,\n",
            "        0.57831657,  0.22666152,  0.59827733, -0.05025962,  0.50391126,\n",
            "        0.36420822,  0.3205061 , -0.11898279, -0.02516599,  0.19551109,\n",
            "       -2.5745971 ,  4.470399  ,  0.28913146], dtype=float32)}\n",
            "ctrl action chosen: [-0.43333647  0.12184549 -0.43006444  0.12283277 -0.43328473  0.12474351\n",
            " -0.43121693  0.1265887 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.811059, dtype=float32), 'agent_0': Array(-3.811059, dtype=float32), 'agent_1': Array(-3.811059, dtype=float32), 'agent_2': Array(-3.811059, dtype=float32), 'agent_3': Array(-3.811059, dtype=float32)}\n",
            "step: 475\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5377789 , -0.8275689 , -0.03677522, -0.11234803,  0.54877615,\n",
            "        0.23023869,  0.54190433,  0.12419786,  0.22316296, -0.20674904,\n",
            "        0.30078888,  0.45261383, -0.0538826 ,  0.44528496, -0.44544423,\n",
            "        5.526518  , -8.802209  ,  0.9091389 ], dtype=float32), 'agent_1': Array([ 0.5377789 , -0.8275689 , -0.03677522, -0.11234803,  0.54877615,\n",
            "        0.23023869,  0.12419786, -1.1495019 ,  0.22316296, -0.20674904,\n",
            "        0.30078888,  0.45261383, -0.0538826 ,  0.44528496, -0.44544423,\n",
            "        5.526518  , -4.378141  ,  2.1078098 ], dtype=float32), 'agent_2': Array([  0.5377789 ,  -0.8275689 ,  -0.03677522,  -0.11234803,\n",
            "         0.54877615,   0.23023869,   0.12419786,   0.22316296,\n",
            "        -1.1765686 ,  -0.20674904,   0.30078888,   0.45261383,\n",
            "        -0.0538826 ,   0.44528496,  -0.44544423,   5.526518  ,\n",
            "       -10.187564  ,   2.7486541 ], dtype=float32), 'agent_3': Array([ 0.5377789 , -0.8275689 , -0.03677522, -0.11234803,  0.54877615,\n",
            "        0.23023869,  0.12419786,  0.22316296, -0.20674904,  0.5747122 ,\n",
            "        0.30078888,  0.45261383, -0.0538826 ,  0.44528496, -0.44544423,\n",
            "        5.526518  , -5.1819243 ,  2.457473  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.88143545  0.23284799 -0.88533765  0.240187   -0.8842461   0.23012768\n",
            " -0.88726544  0.24003907]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9642296, dtype=float32), 'agent_0': Array(0.9642296, dtype=float32), 'agent_1': Array(0.9642296, dtype=float32), 'agent_2': Array(0.9642296, dtype=float32), 'agent_3': Array(0.9642296, dtype=float32)}\n",
            "step: 476\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5339007 ,  -0.9321339 ,  -0.05513419,  -0.07566081,\n",
            "         0.34980315,  -0.42008156,   0.6151525 ,  -0.3651037 ,\n",
            "        -0.4945242 ,  -0.6399857 ,  -0.16379356,   0.6050825 ,\n",
            "        -0.08099079,   0.05781575,  -1.2256408 ,   6.19016   ,\n",
            "       -10.579044  ,   1.6928495 ], dtype=float32), 'agent_1': Array([ 0.5339007 , -0.9321339 , -0.05513419, -0.07566081,  0.34980315,\n",
            "       -0.42008156, -0.3651037 , -1.0098147 , -0.4945242 , -0.6399857 ,\n",
            "       -0.16379356,  0.6050825 , -0.08099079,  0.05781575, -1.2256408 ,\n",
            "        6.19016   , -7.747352  ,  3.2270572 ], dtype=float32), 'agent_2': Array([  0.5339007 ,  -0.9321339 ,  -0.05513419,  -0.07566081,\n",
            "         0.34980315,  -0.42008156,  -0.3651037 ,  -0.4945242 ,\n",
            "        -0.9560356 ,  -0.6399857 ,  -0.16379356,   0.6050825 ,\n",
            "        -0.08099079,   0.05781575,  -1.2256408 ,   6.19016   ,\n",
            "       -11.74408   ,   4.658505  ], dtype=float32), 'agent_3': Array([ 0.5339007 , -0.9321339 , -0.05513419, -0.07566081,  0.34980315,\n",
            "       -0.42008156, -0.3651037 , -0.4945242 , -0.6399857 ,  0.7469544 ,\n",
            "       -0.16379356,  0.6050825 , -0.08099079,  0.05781575, -1.2256408 ,\n",
            "        6.19016   , -2.1261547 ,  2.7693353 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8505399  1.0548048 -0.8545842  1.0607024 -0.8551986  1.0537071\n",
            " -0.8558677  1.0742218]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6024698, dtype=float32), 'agent_0': Array(-0.6024698, dtype=float32), 'agent_1': Array(-0.6024698, dtype=float32), 'agent_2': Array(-0.6024698, dtype=float32), 'agent_3': Array(-0.6024698, dtype=float32)}\n",
            "step: 477\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4837590e-01, -9.4030905e-01, -7.6601718e-04, -2.3586467e-02,\n",
            "        3.3950269e-01, -5.7765579e-01,  9.3157226e-01, -5.1384377e-01,\n",
            "       -5.9447920e-01, -4.9805465e-01, -7.2870255e-01,  5.6269169e-01,\n",
            "        4.7967434e-01, -2.1846938e+00, -3.3770950e+00, -9.5640832e-01,\n",
            "       -8.5687071e-02,  8.3355627e+00], dtype=float32), 'agent_1': Array([ 5.4837590e-01, -9.4030905e-01, -7.6601718e-04, -2.3586467e-02,\n",
            "        3.3950269e-01, -5.7765579e-01, -5.1384377e-01, -5.7313603e-01,\n",
            "       -5.9447920e-01, -4.9805465e-01, -7.2870255e-01,  5.6269169e-01,\n",
            "        4.7967434e-01, -2.1846938e+00, -3.3770950e+00, -9.5640832e-01,\n",
            "       -2.2349901e+00,  1.1469027e+01], dtype=float32), 'agent_2': Array([ 5.4837590e-01, -9.4030905e-01, -7.6601718e-04, -2.3586467e-02,\n",
            "        3.3950269e-01, -5.7765579e-01, -5.1384377e-01, -5.9447920e-01,\n",
            "       -5.1286781e-01, -4.9805465e-01, -7.2870255e-01,  5.6269169e-01,\n",
            "        4.7967434e-01, -2.1846938e+00, -3.3770950e+00, -9.5640832e-01,\n",
            "        1.0733953e+00,  1.0072297e+01], dtype=float32), 'agent_3': Array([ 5.4837590e-01, -9.4030905e-01, -7.6601718e-04, -2.3586467e-02,\n",
            "        3.3950269e-01, -5.7765579e-01, -5.1384377e-01, -5.9447920e-01,\n",
            "       -4.9805465e-01,  1.0599782e+00, -7.2870255e-01,  5.6269169e-01,\n",
            "        4.7967434e-01, -2.1846938e+00, -3.3770950e+00, -9.5640832e-01,\n",
            "        2.9506943e+00,  7.6089029e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.24990898  0.66143215 -0.25059122  0.65310264 -0.24997093  0.6642662\n",
            " -0.24811883  0.67610735]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.2726629, dtype=float32), 'agent_0': Array(-3.2726629, dtype=float32), 'agent_1': Array(-3.2726629, dtype=float32), 'agent_2': Array(-3.2726629, dtype=float32), 'agent_3': Array(-3.2726629, dtype=float32)}\n",
            "step: 478\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5751898 , -0.9217083 ,  0.03550832,  0.01377316,  0.3860096 ,\n",
            "       -0.49932784,  1.2480049 , -0.56663483, -0.46599418, -0.32323372,\n",
            "       -0.1762867 ,  0.8642912 ,  1.0142088 ,  0.41153312, -1.3642819 ,\n",
            "       -1.4545617 ,  1.4407128 ,  3.353499  ], dtype=float32), 'agent_1': Array([ 0.5751898 , -0.9217083 ,  0.03550832,  0.01377316,  0.3860096 ,\n",
            "       -0.49932784, -0.56663483, -0.46759856, -0.46599418, -0.32323372,\n",
            "       -0.1762867 ,  0.8642912 ,  1.0142088 ,  0.41153312, -1.3642819 ,\n",
            "       -1.4545617 , -0.8106599 , -0.92371   ], dtype=float32), 'agent_2': Array([ 0.5751898 , -0.9217083 ,  0.03550832,  0.01377316,  0.3860096 ,\n",
            "       -0.49932784, -0.56663483, -0.46599418, -0.4621346 , -0.32323372,\n",
            "       -0.1762867 ,  0.8642912 ,  1.0142088 ,  0.41153312, -1.3642819 ,\n",
            "       -1.4545617 ,  2.10732   ,  0.14128514], dtype=float32), 'agent_3': Array([ 0.5751898 , -0.9217083 ,  0.03550832,  0.01377316,  0.3860096 ,\n",
            "       -0.49932784, -0.56663483, -0.46599418, -0.32323372,  1.2689205 ,\n",
            "       -0.1762867 ,  0.8642912 ,  1.0142088 ,  0.41153312, -1.3642819 ,\n",
            "       -1.4545617 ,  1.2866652 , -0.6788232 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.66382647 -0.45011845  0.66379225 -0.45613176  0.66171515 -0.45163894\n",
            "  0.663252   -0.45267293]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5910319, dtype=float32), 'agent_0': Array(-0.5910319, dtype=float32), 'agent_1': Array(-0.5910319, dtype=float32), 'agent_2': Array(-0.5910319, dtype=float32), 'agent_3': Array(-0.5910319, dtype=float32)}\n",
            "step: 479\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2023634e-01, -8.3642423e-01,  3.0987641e-02,  3.4535814e-02,\n",
            "        5.4611492e-01, -8.2385473e-02,  1.2139145e+00, -2.5581911e-01,\n",
            "       -2.2139405e-03,  1.2087241e-01, -1.8596649e-01,  8.3670616e-01,\n",
            "        4.2686462e-01,  3.6053711e-01, -5.5426925e-01, -9.1246061e+00,\n",
            "        1.0296995e+01, -1.0898952e-01], dtype=float32), 'agent_1': Array([ 6.2023634e-01, -8.3642423e-01,  3.0987641e-02,  3.4535814e-02,\n",
            "        5.4611492e-01, -8.2385473e-02, -2.5581911e-01, -6.5433687e-01,\n",
            "       -2.2139405e-03,  1.2087241e-01, -1.8596649e-01,  8.3670616e-01,\n",
            "        4.2686462e-01,  3.6053711e-01, -5.5426925e-01, -9.1246061e+00,\n",
            "        9.2494068e+00, -5.3598671e+00], dtype=float32), 'agent_2': Array([ 6.2023634e-01, -8.3642423e-01,  3.0987641e-02,  3.4535814e-02,\n",
            "        5.4611492e-01, -8.2385473e-02, -2.5581911e-01, -2.2139405e-03,\n",
            "       -6.3346636e-01,  1.2087241e-01, -1.8596649e-01,  8.3670616e-01,\n",
            "        4.2686462e-01,  3.6053711e-01, -5.5426925e-01, -9.1246061e+00,\n",
            "        1.1345217e+01, -5.5762711e+00], dtype=float32), 'agent_3': Array([ 6.2023634e-01, -8.3642423e-01,  3.0987641e-02,  3.4535814e-02,\n",
            "        5.4611492e-01, -8.2385473e-02, -2.5581911e-01, -2.2139405e-03,\n",
            "        1.2087241e-01,  1.1954620e+00, -1.8596649e-01,  8.3670616e-01,\n",
            "        4.2686462e-01,  3.6053711e-01, -5.5426925e-01, -9.1246061e+00,\n",
            "        1.1224819e+01, -1.1985387e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.39563456 0.12551215 0.39501575 0.11343863 0.39664924 0.11263202\n",
            " 0.3955624  0.12598395]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.47503257, dtype=float32), 'agent_0': Array(-0.47503257, dtype=float32), 'agent_1': Array(-0.47503257, dtype=float32), 'agent_2': Array(-0.47503257, dtype=float32), 'agent_3': Array(-0.47503257, dtype=float32)}\n",
            "step: 480\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.61790806, -0.7170635 ,  0.02432753,  0.05838511,  0.69413215,\n",
            "        0.35707906,  1.2085979 ,  0.12139234,  0.48167664,  0.5788828 ,\n",
            "       -0.19454956,  0.8229017 , -0.301826  ,  0.25790155, -0.41006655,\n",
            "       -5.603817  ,  6.7168193 , -1.3383303 ], dtype=float32), 'agent_1': Array([ 0.61790806, -0.7170635 ,  0.02432753,  0.05838511,  0.69413215,\n",
            "        0.35707906,  0.12139234, -0.82503   ,  0.48167664,  0.5788828 ,\n",
            "       -0.19454956,  0.8229017 , -0.301826  ,  0.25790155, -0.41006655,\n",
            "       -5.603817  ,  5.4598284 , -2.6418715 ], dtype=float32), 'agent_2': Array([ 0.61790806, -0.7170635 ,  0.02432753,  0.05838511,  0.69413215,\n",
            "        0.35707906,  0.12139234,  0.48167664, -0.83933634,  0.5788828 ,\n",
            "       -0.19454956,  0.8229017 , -0.301826  ,  0.25790155, -0.41006655,\n",
            "       -5.603817  ,  7.404261  , -3.5261033 ], dtype=float32), 'agent_3': Array([ 0.61790806, -0.7170635 ,  0.02432753,  0.05838511,  0.69413215,\n",
            "        0.35707906,  0.12139234,  0.48167664,  0.5788828 ,  1.1516944 ,\n",
            "       -0.19454956,  0.8229017 , -0.301826  ,  0.25790155, -0.41006655,\n",
            "       -5.603817  ,  5.1966634 , -1.879626  ], dtype=float32)}\n",
            "ctrl action chosen: [0.22400002 1.7685218  0.22312324 1.7655842  0.22568698 1.7655053\n",
            " 0.22308761 1.7690179 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.46400276, dtype=float32), 'agent_0': Array(0.46400276, dtype=float32), 'agent_1': Array(0.46400276, dtype=float32), 'agent_2': Array(0.46400276, dtype=float32), 'agent_3': Array(0.46400276, dtype=float32)}\n",
            "step: 481\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5964522 , -0.6912284 ,  0.04015412,  0.10088512,  0.71443206,\n",
            "        0.469238  ,  1.2665844 ,  0.18736157,  0.5525656 ,  0.52591836,\n",
            "       -0.04653931,  0.3995657 , -0.6558895 ,  0.6789025 , -1.9877931 ,\n",
            "       -0.96347076,  2.1957307 ,  0.61085385], dtype=float32), 'agent_1': Array([ 0.5964522 , -0.6912284 ,  0.04015412,  0.10088512,  0.71443206,\n",
            "        0.469238  ,  0.18736157, -0.65796226,  0.5525656 ,  0.52591836,\n",
            "       -0.04653931,  0.3995657 , -0.6558895 ,  0.6789025 , -1.9877931 ,\n",
            "       -0.96347076,  1.1145594 ,  6.3697886 ], dtype=float32), 'agent_2': Array([ 0.5964522 , -0.6912284 ,  0.04015412,  0.10088512,  0.71443206,\n",
            "        0.469238  ,  0.18736157,  0.5525656 , -0.6732261 ,  0.52591836,\n",
            "       -0.04653931,  0.3995657 , -0.6558895 ,  0.6789025 , -1.9877931 ,\n",
            "       -0.96347076,  0.1674652 ,  6.5337114 ], dtype=float32), 'agent_3': Array([ 0.5964522 , -0.6912284 ,  0.04015412,  0.10088512,  0.71443206,\n",
            "        0.469238  ,  0.18736157,  0.5525656 ,  0.52591836,  1.2816969 ,\n",
            "       -0.04653931,  0.3995657 , -0.6558895 ,  0.6789025 , -1.9877931 ,\n",
            "       -0.96347076, -1.7505417 ,  1.2814941 ], dtype=float32)}\n",
            "ctrl action chosen: [0.39532667 2.4820447  0.3891102  2.4787571  0.38814458 2.4765353\n",
            " 0.3933604  2.4762778 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.3893805, dtype=float32), 'agent_0': Array(-5.3893805, dtype=float32), 'agent_1': Array(-5.3893805, dtype=float32), 'agent_2': Array(-5.3893805, dtype=float32), 'agent_3': Array(-5.3893805, dtype=float32)}\n",
            "step: 482\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53023344, -0.6683702 ,  0.0527918 ,  0.14176784,  0.7282831 ,\n",
            "        0.56380266,  1.2758886 ,  0.27860895,  0.53869116,  0.4660561 ,\n",
            "       -0.04572868,  0.40709972, -1.7358661 ,  0.38217   , -0.7057306 ,\n",
            "       -0.762964  ,  0.52126026, -0.664554  ], dtype=float32), 'agent_1': Array([ 0.53023344, -0.6683702 ,  0.0527918 ,  0.14176784,  0.7282831 ,\n",
            "        0.56380266,  0.27860895, -0.44544542,  0.53869116,  0.4660561 ,\n",
            "       -0.04572868,  0.40709972, -1.7358661 ,  0.38217   , -0.7057306 ,\n",
            "       -0.762964  ,  1.8638319 , -0.15502518], dtype=float32), 'agent_2': Array([ 0.53023344, -0.6683702 ,  0.0527918 ,  0.14176784,  0.7282831 ,\n",
            "        0.56380266,  0.27860895,  0.53869116, -0.44274494,  0.4660561 ,\n",
            "       -0.04572868,  0.40709972, -1.7358661 ,  0.38217   , -0.7057306 ,\n",
            "       -0.762964  , -0.44022968, -0.2541131 ], dtype=float32), 'agent_3': Array([ 0.53023344, -0.6683702 ,  0.0527918 ,  0.14176784,  0.7282831 ,\n",
            "        0.56380266,  0.27860895,  0.53869116,  0.4660561 ,  1.2828379 ,\n",
            "       -0.04572868,  0.40709972, -1.7358661 ,  0.38217   , -0.7057306 ,\n",
            "       -0.762964  , -0.4902832 , -0.9713287 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.55828583  0.5193711  -0.5582565   0.5218495  -0.5610514   0.5194996\n",
            " -0.5589446   0.51853174]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-11.61457, dtype=float32), 'agent_0': Array(-11.61457, dtype=float32), 'agent_1': Array(-11.61457, dtype=float32), 'agent_2': Array(-11.61457, dtype=float32), 'agent_3': Array(-11.61457, dtype=float32)}\n",
            "step: 483\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4746855 , -0.7485179 ,  0.0793178 ,  0.14291419,  0.64265484,\n",
            "        0.25215298,  1.2243296 ,  0.01763763,  0.19020371,  0.11034147,\n",
            "       -0.21128654,  0.24125576, -0.2543211 , -0.7532992 , -0.62279445,\n",
            "        7.3114924 , -9.648447  , -0.14099514], dtype=float32), 'agent_1': Array([ 0.4746855 , -0.7485179 ,  0.0793178 ,  0.14291419,  0.64265484,\n",
            "        0.25215298,  0.01763763, -0.4767581 ,  0.19020371,  0.11034147,\n",
            "       -0.21128654,  0.24125576, -0.2543211 , -0.7532992 , -0.62279445,\n",
            "        7.3114924 , -8.12069   ,  0.7723747 ], dtype=float32), 'agent_2': Array([ 0.4746855 , -0.7485179 ,  0.0793178 ,  0.14291419,  0.64265484,\n",
            "        0.25215298,  0.01763763,  0.19020371, -0.45803428,  0.11034147,\n",
            "       -0.21128654,  0.24125576, -0.2543211 , -0.7532992 , -0.62279445,\n",
            "        7.3114924 , -8.651482  , -0.3872926 ], dtype=float32), 'agent_3': Array([ 0.4746855 , -0.7485179 ,  0.0793178 ,  0.14291419,  0.64265484,\n",
            "        0.25215298,  0.01763763,  0.19020371,  0.11034147,  1.2205582 ,\n",
            "       -0.21128654,  0.24125576, -0.2543211 , -0.7532992 , -0.62279445,\n",
            "        7.3114924 , -9.878908  ,  0.15713318], dtype=float32)}\n",
            "ctrl action chosen: [-1.1431655 -1.5702868 -1.1450205 -1.5659039 -1.1440376 -1.5668297\n",
            " -1.1428035 -1.5657296]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.3457954, dtype=float32), 'agent_0': Array(-0.3457954, dtype=float32), 'agent_1': Array(-0.3457954, dtype=float32), 'agent_2': Array(-0.3457954, dtype=float32), 'agent_3': Array(-0.3457954, dtype=float32)}\n",
            "step: 484\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.53796667,  -0.8970008 ,   0.07495535,   0.06504684,\n",
            "         0.43074396,  -0.44629025,   0.82745713,  -0.6404298 ,\n",
            "        -0.45101532,  -0.5902667 ,   0.43029785,   0.96235275,\n",
            "         1.260817  ,   1.3327992 ,   3.2516322 ,   4.4693646 ,\n",
            "        -8.605327  , -10.026852  ], dtype=float32), 'agent_1': Array([ 0.53796667, -0.8970008 ,  0.07495535,  0.06504684,  0.43074396,\n",
            "       -0.44629025, -0.6404298 , -0.6906848 , -0.45101532, -0.5902667 ,\n",
            "        0.43029785,  0.96235275,  1.260817  ,  1.3327992 ,  3.2516322 ,\n",
            "        4.4693646 , -3.5587428 , -6.8422866 ], dtype=float32), 'agent_2': Array([ 0.53796667, -0.8970008 ,  0.07495535,  0.06504684,  0.43074396,\n",
            "       -0.44629025, -0.6404298 , -0.45101532, -0.6778275 , -0.5902667 ,\n",
            "        0.43029785,  0.96235275,  1.260817  ,  1.3327992 ,  3.2516322 ,\n",
            "        4.4693646 , -7.5322857 , -6.6946454 ], dtype=float32), 'agent_3': Array([ 0.53796667, -0.8970008 ,  0.07495535,  0.06504684,  0.43074396,\n",
            "       -0.44629025, -0.6404298 , -0.45101532, -0.5902667 ,  0.8568538 ,\n",
            "        0.43029785,  0.96235275,  1.260817  ,  1.3327992 ,  3.2516322 ,\n",
            "        4.4693646 , -5.749851  , -9.66117   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7860854  -1.4626099  -0.78887093 -1.448725   -0.78547287 -1.4553316\n",
            " -0.7873901  -1.451645  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.2940025, dtype=float32), 'agent_0': Array(-6.2940025, dtype=float32), 'agent_1': Array(-6.2940025, dtype=float32), 'agent_2': Array(-6.2940025, dtype=float32), 'agent_3': Array(-6.2940025, dtype=float32)}\n",
            "step: 485\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5839269 , -0.8956572 , -0.00431292,  0.00654254,  0.44467613,\n",
            "       -0.5524642 ,  0.4200248 , -0.5368668 , -0.53777504, -0.54954904,\n",
            "        0.46157837,  0.852561  ,  0.79159737,  1.5886265 ,  3.1819193 ,\n",
            "       -1.2862415 , -0.04872383, -1.402461  ], dtype=float32), 'agent_1': Array([ 5.8392692e-01, -8.9565718e-01, -4.3129236e-03,  6.5425350e-03,\n",
            "        4.4467613e-01, -5.5246419e-01, -5.3686678e-01, -1.1872929e+00,\n",
            "       -5.3777504e-01, -5.4954904e-01,  4.6157837e-01,  8.5256100e-01,\n",
            "        7.9159737e-01,  1.5886265e+00,  3.1819193e+00, -1.2862415e+00,\n",
            "        2.4580238e+00, -1.2147104e+01], dtype=float32), 'agent_2': Array([ 5.8392692e-01, -8.9565718e-01, -4.3129236e-03,  6.5425350e-03,\n",
            "        4.4467613e-01, -5.5246419e-01, -5.3686678e-01, -5.3777504e-01,\n",
            "       -1.1643721e+00, -5.4954904e-01,  4.6157837e-01,  8.5256100e-01,\n",
            "        7.9159737e-01,  1.5886265e+00,  3.1819193e+00, -1.2862415e+00,\n",
            "       -2.7872559e-01, -1.1557256e+01], dtype=float32), 'agent_3': Array([ 0.5839269 , -0.8956572 , -0.00431292,  0.00654254,  0.44467613,\n",
            "       -0.5524642 , -0.5368668 , -0.53777504, -0.54954904,  0.41034546,\n",
            "        0.46157837,  0.852561  ,  0.79159737,  1.5886265 ,  3.1819193 ,\n",
            "       -1.2862415 ,  1.5540241 , -2.2509482 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.15310842 -1.31856    -0.14238493 -1.3299222  -0.14384806 -1.3308805\n",
            " -0.15282212 -1.3194253 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.9182358, dtype=float32), 'agent_0': Array(-3.9182358, dtype=float32), 'agent_1': Array(-3.9182358, dtype=float32), 'agent_2': Array(-3.9182358, dtype=float32), 'agent_3': Array(-3.9182358, dtype=float32)}\n",
            "step: 486\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.65538293, -0.8750987 , -0.01928969, -0.02033585,  0.48313218,\n",
            "       -0.53386414,  0.46324527, -0.39882132, -0.5333041 , -0.45203435,\n",
            "        0.34270287,  0.45995712,  1.5111208 , -0.018652  ,  0.5957301 ,\n",
            "       -0.7598809 , -0.2934894 ,  1.8545156 ], dtype=float32), 'agent_1': Array([ 0.65538293, -0.8750987 , -0.01928969, -0.02033585,  0.48313218,\n",
            "       -0.53386414, -0.39882132, -1.2904139 , -0.5333041 , -0.45203435,\n",
            "        0.34270287,  0.45995712,  1.5111208 , -0.018652  ,  0.5957301 ,\n",
            "       -0.7598809 ,  1.3635447 ,  0.10514045], dtype=float32), 'agent_2': Array([ 0.65538293, -0.8750987 , -0.01928969, -0.02033585,  0.48313218,\n",
            "       -0.53386414, -0.39882132, -0.5333041 , -1.2870882 , -0.45203435,\n",
            "        0.34270287,  0.45995712,  1.5111208 , -0.018652  ,  0.5957301 ,\n",
            "       -0.7598809 , -0.9673462 ,  0.21545514], dtype=float32), 'agent_3': Array([ 0.65538293, -0.8750987 , -0.01928969, -0.02033585,  0.48313218,\n",
            "       -0.53386414, -0.39882132, -0.5333041 , -0.45203435,  0.47242844,\n",
            "        0.34270287,  0.45995712,  1.5111208 , -0.018652  ,  0.5957301 ,\n",
            "       -0.7598809 ,  0.66823024,  1.9086753 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.23927693 -0.18298198 -0.2388559  -0.18232515 -0.23938848 -0.18455616\n",
            " -0.2390255  -0.17929515]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2214217, dtype=float32), 'agent_0': Array(-2.2214217, dtype=float32), 'agent_1': Array(-2.2214217, dtype=float32), 'agent_2': Array(-2.2214217, dtype=float32), 'agent_3': Array(-2.2214217, dtype=float32)}\n",
            "step: 487\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.69134647, -0.8671842 , -0.02491304, -0.03778667,  0.49592644,\n",
            "       -0.5336898 ,  0.6158457 , -0.36750123, -0.55058515, -0.46480578,\n",
            "        0.34899712,  0.47917366,  0.10896921, -0.18076026,  0.8045638 ,\n",
            "       -0.68856144,  0.26839298,  3.0803728 ], dtype=float32), 'agent_1': Array([ 0.69134647, -0.8671842 , -0.02491304, -0.03778667,  0.49592644,\n",
            "       -0.5336898 , -0.36750123, -1.2253116 , -0.55058515, -0.46480578,\n",
            "        0.34899712,  0.47917366,  0.10896921, -0.18076026,  0.8045638 ,\n",
            "       -0.68856144,  0.21328962,  1.228832  ], dtype=float32), 'agent_2': Array([ 0.69134647, -0.8671842 , -0.02491304, -0.03778667,  0.49592644,\n",
            "       -0.5336898 , -0.36750123, -0.55058515, -1.2298623 , -0.46480578,\n",
            "        0.34899712,  0.47917366,  0.10896921, -0.18076026,  0.8045638 ,\n",
            "       -0.68856144,  0.42154798,  1.1339116 ], dtype=float32), 'agent_3': Array([ 0.69134647, -0.8671842 , -0.02491304, -0.03778667,  0.49592644,\n",
            "       -0.5336898 , -0.36750123, -0.55058515, -0.46480578,  0.6281027 ,\n",
            "        0.34899712,  0.47917366,  0.10896921, -0.18076026,  0.8045638 ,\n",
            "       -0.68856144, -0.6492852 ,  3.1532843 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.6165202 -0.7373231  1.617354  -0.7361979  1.6185368 -0.7347719\n",
            "  1.6181629 -0.7367057]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1494517, dtype=float32), 'agent_0': Array(1.1494517, dtype=float32), 'agent_1': Array(1.1494517, dtype=float32), 'agent_2': Array(1.1494517, dtype=float32), 'agent_3': Array(1.1494517, dtype=float32)}\n",
            "step: 488\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.68648416,  -0.71120256,  -0.0325249 ,  -0.07489836,\n",
            "         0.6982287 ,   0.0574107 ,   0.5638985 ,   0.22455877,\n",
            "         0.05680753,   0.10101429,   0.2881527 ,   0.5997658 ,\n",
            "        -0.2283454 ,  -0.3177387 ,   1.7968668 , -13.197966  ,\n",
            "        15.598645  ,  -3.6691597 ], dtype=float32), 'agent_1': Array([  0.68648416,  -0.71120256,  -0.0325249 ,  -0.07489836,\n",
            "         0.6982287 ,   0.0574107 ,   0.22455877,  -1.2347918 ,\n",
            "         0.05680753,   0.10101429,   0.2881527 ,   0.5997658 ,\n",
            "        -0.2283454 ,  -0.3177387 ,   1.7968668 , -13.197966  ,\n",
            "        15.349412  ,  -0.51532376], dtype=float32), 'agent_2': Array([  0.68648416,  -0.71120256,  -0.0325249 ,  -0.07489836,\n",
            "         0.6982287 ,   0.0574107 ,   0.22455877,   0.05680753,\n",
            "        -1.22998   ,   0.10101429,   0.2881527 ,   0.5997658 ,\n",
            "        -0.2283454 ,  -0.3177387 ,   1.7968668 , -13.197966  ,\n",
            "        16.247913  ,  -0.38945317], dtype=float32), 'agent_3': Array([  0.68648416,  -0.71120256,  -0.0325249 ,  -0.07489836,\n",
            "         0.6982287 ,   0.0574107 ,   0.22455877,   0.05680753,\n",
            "         0.10101429,   0.54615146,   0.2881527 ,   0.5997658 ,\n",
            "        -0.2283454 ,  -0.3177387 ,   1.7968668 , -13.197966  ,\n",
            "        15.314803  ,  -4.4049425 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3267007  -1.9782155  -0.3267627  -1.969694   -0.32445413 -1.9656435\n",
            " -0.32699665 -1.9796212 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.982936, dtype=float32), 'agent_0': Array(-4.982936, dtype=float32), 'agent_1': Array(-4.982936, dtype=float32), 'agent_2': Array(-4.982936, dtype=float32), 'agent_3': Array(-4.982936, dtype=float32)}\n",
            "step: 489\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6530043 , -0.65944445, -0.04294316, -0.11587881,  0.7415261 ,\n",
            "        0.20822741,  0.45696577,  0.3541227 ,  0.23104768,  0.2198556 ,\n",
            "        0.36330223,  0.4775524 , -0.8350849 , -0.45056325,  0.95539016,\n",
            "        0.24842098, -0.8938313 ,  0.03366673], dtype=float32), 'agent_1': Array([ 0.6530043 , -0.65944445, -0.04294316, -0.11587881,  0.7415261 ,\n",
            "        0.20822741,  0.3541227 , -1.2744844 ,  0.23104768,  0.2198556 ,\n",
            "        0.36330223,  0.4775524 , -0.8350849 , -0.45056325,  0.95539016,\n",
            "        0.24842098, -1.2848719 ,  0.07333735], dtype=float32), 'agent_2': Array([ 0.6530043 , -0.65944445, -0.04294316, -0.11587881,  0.7415261 ,\n",
            "        0.20822741,  0.3541227 ,  0.23104768, -1.2756146 ,  0.2198556 ,\n",
            "        0.36330223,  0.4775524 , -0.8350849 , -0.45056325,  0.95539016,\n",
            "        0.24842098, -0.38713974, -0.05644407], dtype=float32), 'agent_3': Array([ 0.6530043 , -0.65944445, -0.04294316, -0.11587881,  0.7415261 ,\n",
            "        0.20822741,  0.3541227 ,  0.23104768,  0.2198556 ,  0.46179983,\n",
            "        0.36330223,  0.4775524 , -0.8350849 , -0.45056325,  0.95539016,\n",
            "        0.24842098, -1.8898427 , -0.02107597], dtype=float32)}\n",
            "ctrl action chosen: [ 0.10830612 -0.4169395   0.10843892 -0.41521177  0.10885568 -0.4153465\n",
            "  0.1080144  -0.4172367 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.717764, dtype=float32), 'agent_0': Array(-6.717764, dtype=float32), 'agent_1': Array(-6.717764, dtype=float32), 'agent_2': Array(-6.717764, dtype=float32), 'agent_3': Array(-6.717764, dtype=float32)}\n",
            "step: 490\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6112461 , -0.6416867 , -0.04934968, -0.13938184,  0.7525793 ,\n",
            "        0.23126145,  0.50567216,  0.36473987,  0.26701546,  0.19703119,\n",
            "        0.3464222 ,  0.5265951 , -0.9883404 , -0.6393864 ,  1.1608413 ,\n",
            "       -0.96896267,  0.8554487 ,  0.65109706], dtype=float32), 'agent_1': Array([ 0.6112461 , -0.6416867 , -0.04934968, -0.13938184,  0.7525793 ,\n",
            "        0.23126145,  0.36473987, -1.2396467 ,  0.26701546,  0.19703119,\n",
            "        0.3464222 ,  0.5265951 , -0.9883404 , -0.6393864 ,  1.1608413 ,\n",
            "       -0.96896267,  0.5938452 ,  0.14540881], dtype=float32), 'agent_2': Array([ 0.6112461 , -0.6416867 , -0.04934968, -0.13938184,  0.7525793 ,\n",
            "        0.23126145,  0.36473987,  0.26701546, -1.2394302 ,  0.19703119,\n",
            "        0.3464222 ,  0.5265951 , -0.9883404 , -0.6393864 ,  1.1608413 ,\n",
            "       -0.96896267,  0.8521546 ,  0.17947416], dtype=float32), 'agent_3': Array([ 0.6112461 , -0.6416867 , -0.04934968, -0.13938184,  0.7525793 ,\n",
            "        0.23126145,  0.36473987,  0.26701546,  0.19703119,  0.5051193 ,\n",
            "        0.3464222 ,  0.5265951 , -0.9883404 , -0.6393864 ,  1.1608413 ,\n",
            "       -0.96896267,  0.05775435,  0.65488386], dtype=float32)}\n",
            "ctrl action chosen: [ 0.58468354 -1.322089    0.58412844 -1.322706    0.5856999  -1.3210605\n",
            "  0.5841819  -1.322551  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0015769, dtype=float32), 'agent_0': Array(1.0015769, dtype=float32), 'agent_1': Array(1.0015769, dtype=float32), 'agent_2': Array(1.0015769, dtype=float32), 'agent_3': Array(1.0015769, dtype=float32)}\n",
            "step: 491\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57935077, -0.5427359 , -0.04824387, -0.15460707,  0.82414025,\n",
            "        0.5333316 ,  0.46541178,  0.58497626,  0.55140865,  0.46071744,\n",
            "        0.27861595,  0.29509068, -0.5085826 ,  0.8129318 ,  0.318746  ,\n",
            "       -1.9236071 ,  3.0292993 , -0.19972861], dtype=float32), 'agent_1': Array([ 0.57935077, -0.5427359 , -0.04824387, -0.15460707,  0.82414025,\n",
            "        0.5333316 ,  0.58497626, -1.2515402 ,  0.55140865,  0.46071744,\n",
            "        0.27861595,  0.29509068, -0.5085826 ,  0.8129318 ,  0.318746  ,\n",
            "       -1.9236071 , -0.73314315,  0.12631065], dtype=float32), 'agent_2': Array([ 0.57935077, -0.5427359 , -0.04824387, -0.15460707,  0.82414025,\n",
            "        0.5333316 ,  0.58497626,  0.55140865, -1.2402155 ,  0.46071744,\n",
            "        0.27861595,  0.29509068, -0.5085826 ,  0.8129318 ,  0.318746  ,\n",
            "       -1.9236071 ,  2.072787  ,  0.34954342], dtype=float32), 'agent_3': Array([ 0.57935077, -0.5427359 , -0.04824387, -0.15460707,  0.82414025,\n",
            "        0.5333316 ,  0.58497626,  0.55140865,  0.46071744,  0.49859622,\n",
            "        0.27861595,  0.29509068, -0.5085826 ,  0.8129318 ,  0.318746  ,\n",
            "       -1.9236071 ,  3.0349245 ,  0.19148372], dtype=float32)}\n",
            "ctrl action chosen: [ 0.69628465 -0.85120183  0.69687593 -0.85162663  0.69462365 -0.8475314\n",
            "  0.69661194 -0.8496894 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.765994, dtype=float32), 'agent_0': Array(-2.765994, dtype=float32), 'agent_1': Array(-2.765994, dtype=float32), 'agent_2': Array(-2.765994, dtype=float32), 'agent_3': Array(-2.765994, dtype=float32)}\n",
            "step: 492\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55703   , -0.5268635 , -0.06425793, -0.14663719,  0.83473545,\n",
            "        0.5511832 ,  0.4695519 ,  0.50903755,  0.54993   ,  0.5548082 ,\n",
            "        0.16264915,  0.1609087 , -0.41804314,  0.8942271 ,  0.39385498,\n",
            "       -0.3834186 , -0.49340367,  0.368129  ], dtype=float32), 'agent_1': Array([ 0.55703   , -0.5268635 , -0.06425793, -0.14663719,  0.83473545,\n",
            "        0.5511832 ,  0.50903755, -1.2619033 ,  0.54993   ,  0.5548082 ,\n",
            "        0.16264915,  0.1609087 , -0.41804314,  0.8942271 ,  0.39385498,\n",
            "       -0.3834186 , -1.3657503 , -0.21081631], dtype=float32), 'agent_2': Array([ 0.55703   , -0.5268635 , -0.06425793, -0.14663719,  0.83473545,\n",
            "        0.5511832 ,  0.50903755,  0.54993   , -1.2589674 ,  0.5548082 ,\n",
            "        0.16264915,  0.1609087 , -0.41804314,  0.8942271 ,  0.39385498,\n",
            "       -0.3834186 , -0.7088819 , -0.49993187], dtype=float32), 'agent_3': Array([ 0.55703   , -0.5268635 , -0.06425793, -0.14663719,  0.83473545,\n",
            "        0.5511832 ,  0.50903755,  0.54993   ,  0.5548082 ,  0.48760784,\n",
            "        0.16264915,  0.1609087 , -0.41804314,  0.8942271 ,  0.39385498,\n",
            "       -0.3834186 ,  0.99787164, -0.5364142 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.78270155 -0.3379315   0.78634596 -0.33774722  0.7828846  -0.3366471\n",
            "  0.78386444 -0.33758366]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2470582, dtype=float32), 'agent_0': Array(-1.2470582, dtype=float32), 'agent_1': Array(-1.2470582, dtype=float32), 'agent_2': Array(-1.2470582, dtype=float32), 'agent_3': Array(-1.2470582, dtype=float32)}\n",
            "step: 493\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53604054, -0.513208  , -0.08202297, -0.11710582,  0.8462719 ,\n",
            "        0.5489353 ,  0.5116998 ,  0.5273124 ,  0.5282647 ,  0.5675195 ,\n",
            "        0.519228  ,  0.20349026, -0.46231747,  1.433876  ,  0.32950348,\n",
            "       -0.4373031 ,  0.3577216 ,  0.01682463], dtype=float32), 'agent_1': Array([ 0.53604054, -0.513208  , -0.08202297, -0.11710582,  0.8462719 ,\n",
            "        0.5489353 ,  0.5273124 , -1.2360708 ,  0.5282647 ,  0.5675195 ,\n",
            "        0.519228  ,  0.20349026, -0.46231747,  1.433876  ,  0.32950348,\n",
            "       -0.4373031 ,  1.246726  , -0.03612255], dtype=float32), 'agent_2': Array([ 0.53604054, -0.513208  , -0.08202297, -0.11710582,  0.8462719 ,\n",
            "        0.5489353 ,  0.5273124 ,  0.5282647 , -1.2361486 ,  0.5675195 ,\n",
            "        0.519228  ,  0.20349026, -0.46231747,  1.433876  ,  0.32950348,\n",
            "       -0.4373031 , -0.06762344,  0.08074832], dtype=float32), 'agent_3': Array([ 0.53604054, -0.513208  , -0.08202297, -0.11710582,  0.8462719 ,\n",
            "        0.5489353 ,  0.5273124 ,  0.5282647 ,  0.5675195 ,  0.5031979 ,\n",
            "        0.519228  ,  0.20349026, -0.46231747,  1.433876  ,  0.32950348,\n",
            "       -0.4373031 , -0.76450247, -0.42376894], dtype=float32)}\n",
            "ctrl action chosen: [-0.71061957 -0.44115433 -0.70700234 -0.4412014  -0.7119165  -0.43893918\n",
            " -0.7079321  -0.44113636]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.08525419, dtype=float32), 'agent_0': Array(-0.08525419, dtype=float32), 'agent_1': Array(-0.08525419, dtype=float32), 'agent_2': Array(-0.08525419, dtype=float32), 'agent_3': Array(-0.08525419, dtype=float32)}\n",
            "step: 494\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.52537477,  -0.6383747 ,  -0.10707738,  -0.06906658,\n",
            "         0.7591061 ,   0.16296734,   0.51088005,   0.17641689,\n",
            "         0.10998888,   0.11578739,   0.61306953,   0.19538403,\n",
            "        -0.03995895,   1.0518345 ,  -1.1011384 ,   8.636491  ,\n",
            "       -10.926197  ,   0.1390703 ], dtype=float32), 'agent_1': Array([ 0.52537477, -0.6383747 , -0.10707738, -0.06906658,  0.7591061 ,\n",
            "        0.16296734,  0.17641689, -1.2305893 ,  0.10998888,  0.11578739,\n",
            "        0.61306953,  0.19538403, -0.03995895,  1.0518345 , -1.1011384 ,\n",
            "        8.636491  , -9.945514  ,  0.2733128 ], dtype=float32), 'agent_2': Array([  0.52537477,  -0.6383747 ,  -0.10707738,  -0.06906658,\n",
            "         0.7591061 ,   0.16296734,   0.17641689,   0.10998888,\n",
            "        -1.2360857 ,   0.11578739,   0.61306953,   0.19538403,\n",
            "        -0.03995895,   1.0518345 ,  -1.1011384 ,   8.636491  ,\n",
            "       -11.100461  ,   0.08670458], dtype=float32), 'agent_3': Array([ 5.25374770e-01, -6.38374686e-01, -1.07077383e-01, -6.90665841e-02,\n",
            "        7.59106100e-01,  1.62967339e-01,  1.76416889e-01,  1.09988876e-01,\n",
            "        1.15787387e-01,  4.92307216e-01,  6.13069534e-01,  1.95384026e-01,\n",
            "       -3.99589539e-02,  1.05183446e+00, -1.10113835e+00,  8.63649082e+00,\n",
            "       -1.23258619e+01, -5.35961427e-03], dtype=float32)}\n",
            "ctrl action chosen: [ 0.80328244 -0.3503397   0.80411047 -0.34974173  0.80312216 -0.35091257\n",
            "  0.80509984 -0.350533  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.11025226, dtype=float32), 'agent_0': Array(0.11025226, dtype=float32), 'agent_1': Array(0.11025226, dtype=float32), 'agent_2': Array(0.11025226, dtype=float32), 'agent_3': Array(0.11025226, dtype=float32)}\n",
            "step: 495\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.528941  , -0.55566853, -0.09174938, -0.047819  ,  0.8249412 ,\n",
            "        0.39442208,  0.5079638 ,  0.44522196,  0.33601287,  0.2824886 ,\n",
            "        0.44431686,  0.19712448,  0.18898249,  0.48345122, -0.93577504,\n",
            "       -7.895526  ,  9.708238  , -0.38159546], dtype=float32), 'agent_1': Array([ 0.528941  , -0.55566853, -0.09174938, -0.047819  ,  0.8249412 ,\n",
            "        0.39442208,  0.44522196, -1.2278603 ,  0.33601287,  0.2824886 ,\n",
            "        0.44431686,  0.19712448,  0.18898249,  0.48345122, -0.93577504,\n",
            "       -7.895526  , 10.213769  , -0.14174534], dtype=float32), 'agent_2': Array([ 0.528941  , -0.55566853, -0.09174938, -0.047819  ,  0.8249412 ,\n",
            "        0.39442208,  0.44522196,  0.33601287, -1.2319872 ,  0.2824886 ,\n",
            "        0.44431686,  0.19712448,  0.18898249,  0.48345122, -0.93577504,\n",
            "       -7.895526  ,  9.473011  , -0.08649337], dtype=float32), 'agent_3': Array([ 0.528941  , -0.55566853, -0.09174938, -0.047819  ,  0.8249412 ,\n",
            "        0.39442208,  0.44522196,  0.33601287,  0.2824886 ,  0.49853656,\n",
            "        0.44431686,  0.19712448,  0.18898249,  0.48345122, -0.93577504,\n",
            "       -7.895526  ,  8.709567  ,  0.29893216], dtype=float32)}\n",
            "ctrl action chosen: [-0.9395839  -0.88403344 -0.94098085 -0.8846126  -0.93994087 -0.8810476\n",
            " -0.940476   -0.8816307 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.0567528, dtype=float32), 'agent_0': Array(0.0567528, dtype=float32), 'agent_1': Array(0.0567528, dtype=float32), 'agent_2': Array(0.0567528, dtype=float32), 'agent_3': Array(0.0567528, dtype=float32)}\n",
            "step: 496\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5345056 ,  -0.6562181 ,  -0.08518718,  -0.01901159,\n",
            "         0.74950624,   0.08200473,   0.48009217,   0.15913922,\n",
            "         0.01872046,  -0.06967416,   0.5002022 ,   0.24068356,\n",
            "         0.24795532,   0.26527348,  -0.9820985 ,   8.827856  ,\n",
            "       -11.45616   ,   0.2932972 ], dtype=float32), 'agent_1': Array([  0.5345056 ,  -0.6562181 ,  -0.08518718,  -0.01901159,\n",
            "         0.74950624,   0.08200473,   0.15913922,  -1.2694505 ,\n",
            "         0.01872046,  -0.06967416,   0.5002022 ,   0.24068356,\n",
            "         0.24795532,   0.26527348,  -0.9820985 ,   8.827856  ,\n",
            "       -10.750775  ,  -0.112786  ], dtype=float32), 'agent_2': Array([  0.5345056 ,  -0.6562181 ,  -0.08518718,  -0.01901159,\n",
            "         0.74950624,   0.08200473,   0.15913922,   0.01872046,\n",
            "        -1.2504746 ,  -0.06967416,   0.5002022 ,   0.24068356,\n",
            "         0.24795532,   0.26527348,  -0.9820985 ,   8.827856  ,\n",
            "       -11.505601  ,   0.19716167], dtype=float32), 'agent_3': Array([  0.5345056 ,  -0.6562181 ,  -0.08518718,  -0.01901159,\n",
            "         0.74950624,   0.08200473,   0.15913922,   0.01872046,\n",
            "        -0.06967416,   0.4950606 ,   0.5002022 ,   0.24068356,\n",
            "         0.24795532,   0.26527348,  -0.9820985 ,   8.827856  ,\n",
            "       -12.190471  ,   0.24010919], dtype=float32)}\n",
            "ctrl action chosen: [0.6900313  1.5289061  0.6920819  1.5288051  0.69016206 1.528767\n",
            " 0.6914447  1.5296247 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9377627, dtype=float32), 'agent_0': Array(-1.9377627, dtype=float32), 'agent_1': Array(-1.9377627, dtype=float32), 'agent_2': Array(-1.9377627, dtype=float32), 'agent_3': Array(-1.9377627, dtype=float32)}\n",
            "step: 497\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5601898 , -0.5990796 , -0.04041181,  0.02469323,  0.7992876 ,\n",
            "        0.22592217,  0.8110256 ,  0.33966976,  0.11828155,  0.04192873,\n",
            "        0.80447197, -0.5693197 ,  0.6239772 ,  0.29693425, -3.1421692 ,\n",
            "       -6.309511  ,  7.6379585 ,  9.141205  ], dtype=float32), 'agent_1': Array([ 0.5601898 , -0.5990796 , -0.04041181,  0.02469323,  0.7992876 ,\n",
            "        0.22592217,  0.33966976, -0.9773269 ,  0.11828155,  0.04192873,\n",
            "        0.80447197, -0.5693197 ,  0.6239772 ,  0.29693425, -3.1421692 ,\n",
            "       -6.309511  ,  8.298698  ,  8.749876  ], dtype=float32), 'agent_2': Array([ 0.5601898 , -0.5990796 , -0.04041181,  0.02469323,  0.7992876 ,\n",
            "        0.22592217,  0.33966976,  0.11828155, -0.91347796,  0.04192873,\n",
            "        0.80447197, -0.5693197 ,  0.6239772 ,  0.29693425, -3.1421692 ,\n",
            "       -6.309511  ,  6.405216  ,  8.791906  ], dtype=float32), 'agent_3': Array([ 0.5601898 , -0.5990796 , -0.04041181,  0.02469323,  0.7992876 ,\n",
            "        0.22592217,  0.33966976,  0.11828155,  0.04192873,  0.83189803,\n",
            "        0.80447197, -0.5693197 ,  0.6239772 ,  0.29693425, -3.1421692 ,\n",
            "       -6.309511  ,  6.801192  ,  8.968141  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.30811307 -1.6851      0.31013235 -1.6854883   0.30699912 -1.6839279\n",
            "  0.30683258 -1.6851093 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.8953505, dtype=float32), 'agent_0': Array(-3.8953505, dtype=float32), 'agent_1': Array(-3.8953505, dtype=float32), 'agent_2': Array(-3.8953505, dtype=float32), 'agent_3': Array(-3.8953505, dtype=float32)}\n",
            "step: 498\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5786012 , -0.49729872, -0.03719931,  0.01431762,  0.8666633 ,\n",
            "        0.53593576,  0.77456397,  0.5943602 ,  0.3980592 ,  0.2976616 ,\n",
            "        0.7246494 ,  0.23117065,  0.18810034, -0.68268204,  0.8032023 ,\n",
            "       -1.7499813 ,  2.1257946 , -4.02618   ], dtype=float32), 'agent_1': Array([ 0.5786012 , -0.49729872, -0.03719931,  0.01431762,  0.8666633 ,\n",
            "        0.53593576,  0.5943602 , -1.0114652 ,  0.3980592 ,  0.2976616 ,\n",
            "        0.7246494 ,  0.23117065,  0.18810034, -0.68268204,  0.8032023 ,\n",
            "       -1.7499813 , -0.93799204, -4.37995   ], dtype=float32), 'agent_2': Array([ 0.5786012 , -0.49729872, -0.03719931,  0.01431762,  0.8666633 ,\n",
            "        0.53593576,  0.5943602 ,  0.3980592 , -0.9854266 ,  0.2976616 ,\n",
            "        0.7246494 ,  0.23117065,  0.18810034, -0.68268204,  0.8032023 ,\n",
            "       -1.7499813 ,  2.4245842 , -4.898886  ], dtype=float32), 'agent_3': Array([ 0.5786012 , -0.49729872, -0.03719931,  0.01431762,  0.8666633 ,\n",
            "        0.53593576,  0.5943602 ,  0.3980592 ,  0.2976616 ,  0.78719616,\n",
            "        0.7246494 ,  0.23117065,  0.18810034, -0.68268204,  0.8032023 ,\n",
            "       -1.7499813 ,  2.295329  , -4.371467  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.59937483 -0.34748936  0.5970962  -0.34692284  0.599849   -0.34769565\n",
            "  0.60004836 -0.3472213 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.980667, dtype=float32), 'agent_0': Array(-3.980667, dtype=float32), 'agent_1': Array(-3.980667, dtype=float32), 'agent_2': Array(-3.980667, dtype=float32), 'agent_3': Array(-3.980667, dtype=float32)}\n",
            "step: 499\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7317817e-01, -4.6293855e-01, -3.6795914e-02,  2.3206493e-03,\n",
            "        8.8562328e-01,  5.6355357e-01,  6.3466930e-01,  5.1478660e-01,\n",
            "        5.5438596e-01,  4.5334071e-01,  7.2007179e-01,  3.9138794e-01,\n",
            "       -8.8858604e-02, -7.6473790e-01,  4.7505575e-01, -1.2358303e+00,\n",
            "       -4.9571529e-01, -3.8566110e+00], dtype=float32), 'agent_1': Array([ 5.7317817e-01, -4.6293855e-01, -3.6795914e-02,  2.3206493e-03,\n",
            "        8.8562328e-01,  5.6355357e-01,  5.1478660e-01, -1.1680028e+00,\n",
            "        5.5438596e-01,  4.5334071e-01,  7.2007179e-01,  3.9138794e-01,\n",
            "       -8.8858604e-02, -7.6473790e-01,  4.7505575e-01, -1.2358303e+00,\n",
            "       -2.0332417e+00, -4.1014037e+00], dtype=float32), 'agent_2': Array([ 5.7317817e-01, -4.6293855e-01, -3.6795914e-02,  2.3206493e-03,\n",
            "        8.8562328e-01,  5.6355357e-01,  5.1478660e-01,  5.5438596e-01,\n",
            "       -1.1573863e+00,  4.5334071e-01,  7.2007179e-01,  3.9138794e-01,\n",
            "       -8.8858604e-02, -7.6473790e-01,  4.7505575e-01, -1.2358303e+00,\n",
            "        2.5362659e+00, -3.3640888e+00], dtype=float32), 'agent_3': Array([ 5.7317817e-01, -4.6293855e-01, -3.6795914e-02,  2.3206493e-03,\n",
            "        8.8562328e-01,  5.6355357e-01,  5.1478660e-01,  5.5438596e-01,\n",
            "        4.5334071e-01,  6.2387669e-01,  7.2007179e-01,  3.9138794e-01,\n",
            "       -8.8858604e-02, -7.6473790e-01,  4.7505575e-01, -1.2358303e+00,\n",
            "        3.3881233e+00, -4.3172297e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.0983514  -0.37327525  1.0965114  -0.3720489   1.0978189  -0.3719313\n",
            "  1.1008501  -0.3730316 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7736887, dtype=float32), 'agent_0': Array(0.7736887, dtype=float32), 'agent_1': Array(0.7736887, dtype=float32), 'agent_2': Array(0.7736887, dtype=float32), 'agent_3': Array(0.7736887, dtype=float32)}\n",
            "step: 500\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8873576e-01, -4.4732252e-01, -3.4997247e-02, -3.1153422e-02,\n",
            "        8.9314467e-01,  5.2728593e-01,  4.6874049e-01,  4.9091569e-01,\n",
            "        5.8595413e-01,  5.8328426e-01,  3.3297539e-01,  3.5762787e-04,\n",
            "        1.8700361e-01, -4.2864439e-01, -6.4311075e-01, -4.3638870e-01,\n",
            "       -4.5978561e-01,  1.0220703e+00], dtype=float32), 'agent_1': Array([ 5.8873576e-01, -4.4732252e-01, -3.4997247e-02, -3.1153422e-02,\n",
            "        8.9314467e-01,  5.2728593e-01,  4.9091569e-01, -1.2588463e+00,\n",
            "        5.8595413e-01,  5.8328426e-01,  3.3297539e-01,  3.5762787e-04,\n",
            "        1.8700361e-01, -4.2864439e-01, -6.4311075e-01, -4.3638870e-01,\n",
            "        1.1444486e+00,  6.9516182e-01], dtype=float32), 'agent_2': Array([ 5.8873576e-01, -4.4732252e-01, -3.4997247e-02, -3.1153422e-02,\n",
            "        8.9314467e-01,  5.2728593e-01,  4.9091569e-01,  5.8595413e-01,\n",
            "       -1.2473543e+00,  5.8328426e-01,  3.3297539e-01,  3.5762787e-04,\n",
            "        1.8700361e-01, -4.2864439e-01, -6.4311075e-01, -4.3638870e-01,\n",
            "       -8.7309182e-01,  8.4180844e-01], dtype=float32), 'agent_3': Array([ 5.8873576e-01, -4.4732252e-01, -3.4997247e-02, -3.1153422e-02,\n",
            "        8.9314467e-01,  5.2728593e-01,  4.9091569e-01,  5.8595413e-01,\n",
            "        5.8328426e-01,  4.7823879e-01,  3.3297539e-01,  3.5762787e-04,\n",
            "        1.8700361e-01, -4.2864439e-01, -6.4311075e-01, -4.3638870e-01,\n",
            "        1.1935096e+00,  1.0868489e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.2088003  0.13394868 1.2100441  0.13770564 1.208585   0.13518216\n",
            " 1.2103351  0.13777995]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.309875, dtype=float32), 'agent_0': Array(-1.309875, dtype=float32), 'agent_1': Array(-1.309875, dtype=float32), 'agent_2': Array(-1.309875, dtype=float32), 'agent_3': Array(-1.309875, dtype=float32)}\n",
            "step: 501\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59693295, -0.4407401 , -0.01498608, -0.03248896,  0.89692146,\n",
            "        0.5373849 ,  0.55280817,  0.57713884,  0.5146342 ,  0.56227475,\n",
            "        0.40016174, -0.23145676,  0.01473427, -0.5965935 , -0.510408  ,\n",
            "       -0.1888371 ,  0.76879257,  1.7908734 ], dtype=float32), 'agent_1': Array([ 0.59693295, -0.4407401 , -0.01498608, -0.03248896,  0.89692146,\n",
            "        0.5373849 ,  0.57713884, -1.160127  ,  0.5146342 ,  0.56227475,\n",
            "        0.40016174, -0.23145676,  0.01473427, -0.5965935 , -0.510408  ,\n",
            "       -0.1888371 ,  1.1622732 ,  2.4407988 ], dtype=float32), 'agent_2': Array([ 0.59693295, -0.4407401 , -0.01498608, -0.03248896,  0.89692146,\n",
            "        0.5373849 ,  0.57713884,  0.5146342 , -1.1635201 ,  0.56227475,\n",
            "        0.40016174, -0.23145676,  0.01473427, -0.5965935 , -0.510408  ,\n",
            "       -0.1888371 , -0.75771636,  1.5787683 ], dtype=float32), 'agent_3': Array([ 0.59693295, -0.4407401 , -0.01498608, -0.03248896,  0.89692146,\n",
            "        0.5373849 ,  0.57713884,  0.5146342 ,  0.56227475,  0.54554355,\n",
            "        0.40016174, -0.23145676,  0.01473427, -0.5965935 , -0.510408  ,\n",
            "       -0.1888371 , -1.3171903 ,  1.3444315 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.46901485 -0.7407875   0.46923214 -0.7398531   0.46754372 -0.74290806\n",
            "  0.4675237  -0.7460031 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5929008, dtype=float32), 'agent_0': Array(-1.5929008, dtype=float32), 'agent_1': Array(-1.5929008, dtype=float32), 'agent_2': Array(-1.5929008, dtype=float32), 'agent_3': Array(-1.5929008, dtype=float32)}\n",
            "step: 502\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5749455 , -0.44138357, -0.0117227 , -0.05938152,  0.8952748 ,\n",
            "        0.54935366,  0.49653757,  0.552041  ,  0.5115683 ,  0.51108265,\n",
            "        0.3891945 ,  0.17609596, -0.69744587, -0.65758896,  0.1471129 ,\n",
            "       -0.61925757,  0.38605297, -0.36611158], dtype=float32), 'agent_1': Array([ 0.5749455 , -0.44138357, -0.0117227 , -0.05938152,  0.8952748 ,\n",
            "        0.54935366,  0.552041  , -1.251245  ,  0.5115683 ,  0.51108265,\n",
            "        0.3891945 ,  0.17609596, -0.69744587, -0.65758896,  0.1471129 ,\n",
            "       -0.61925757, -0.8863769 , -1.036252  ], dtype=float32), 'agent_2': Array([ 0.5749455 , -0.44138357, -0.0117227 , -0.05938152,  0.8952748 ,\n",
            "        0.54935366,  0.552041  ,  0.5115683 , -1.2569823 ,  0.51108265,\n",
            "        0.3891945 ,  0.17609596, -0.69744587, -0.65758896,  0.1471129 ,\n",
            "       -0.61925757,  1.7427907 , -0.10333225], dtype=float32), 'agent_3': Array([ 0.5749455 , -0.44138357, -0.0117227 , -0.05938152,  0.8952748 ,\n",
            "        0.54935366,  0.552041  ,  0.5115683 ,  0.51108265,  0.49731132,\n",
            "        0.3891945 ,  0.17609596, -0.69744587, -0.65758896,  0.1471129 ,\n",
            "       -0.61925757,  0.21353848, -0.17540547], dtype=float32)}\n",
            "ctrl action chosen: [ 0.3830169  -0.5938104   0.38099194 -0.5930652   0.38432333 -0.5898689\n",
            "  0.38237906 -0.5938702 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.15324402, dtype=float32), 'agent_0': Array(-0.15324402, dtype=float32), 'agent_1': Array(-0.15324402, dtype=float32), 'agent_2': Array(-0.15324402, dtype=float32), 'agent_3': Array(-0.15324402, dtype=float32)}\n",
            "step: 503\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5598808 , -0.43471482, -0.01173691, -0.07098208,  0.8976897 ,\n",
            "        0.53378403,  0.49437186,  0.5045007 ,  0.5553556 ,  0.5342108 ,\n",
            "        0.45399666,  0.01020432,  0.01363754, -0.4606034 ,  0.8804275 ,\n",
            "       -0.15923983, -0.52303106, -0.20386773], dtype=float32), 'agent_1': Array([ 0.5598808 , -0.43471482, -0.01173691, -0.07098208,  0.8976897 ,\n",
            "        0.53378403,  0.5045007 , -1.2474892 ,  0.5553556 ,  0.5342108 ,\n",
            "        0.45399666,  0.01020432,  0.01363754, -0.4606034 ,  0.8804275 ,\n",
            "       -0.15923983, -0.5317263 , -0.43834996], dtype=float32), 'agent_2': Array([ 0.5598808 , -0.43471482, -0.01173691, -0.07098208,  0.8976897 ,\n",
            "        0.53378403,  0.5045007 ,  0.5553556 , -1.2516265 ,  0.5342108 ,\n",
            "        0.45399666,  0.01020432,  0.01363754, -0.4606034 ,  0.8804275 ,\n",
            "       -0.15923983,  0.11959188, -0.17743824], dtype=float32), 'agent_3': Array([ 0.5598808 , -0.43471482, -0.01173691, -0.07098208,  0.8976897 ,\n",
            "        0.53378403,  0.5045007 ,  0.5553556 ,  0.5342108 ,  0.48768193,\n",
            "        0.45399666,  0.01020432,  0.01363754, -0.4606034 ,  0.8804275 ,\n",
            "       -0.15923983,  0.39757967, -0.37601578], dtype=float32)}\n",
            "ctrl action chosen: [0.7436894  1.8082592  0.74317485 1.8090875  0.7433911  1.8101228\n",
            " 0.7440783  1.8080789 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.47991782, dtype=float32), 'agent_0': Array(0.47991782, dtype=float32), 'agent_1': Array(0.47991782, dtype=float32), 'agent_2': Array(0.47991782, dtype=float32), 'agent_3': Array(0.47991782, dtype=float32)}\n",
            "step: 504\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6792623e-01, -4.2528829e-01,  1.5592658e-03, -4.8809610e-02,\n",
            "        9.0373957e-01,  5.3601575e-01,  7.9657573e-01,  5.4899436e-01,\n",
            "        5.3558260e-01,  5.5195868e-01,  1.4877319e-01, -7.5886250e-01,\n",
            "       -3.8206577e-02,  9.2114699e-01, -1.6832790e+00, -2.1111314e-01,\n",
            "        1.3624296e-01,  8.8394356e+00], dtype=float32), 'agent_1': Array([ 5.6792623e-01, -4.2528829e-01,  1.5592658e-03, -4.8809610e-02,\n",
            "        9.0373957e-01,  5.3601575e-01,  5.4899436e-01, -9.4364351e-01,\n",
            "        5.3558260e-01,  5.5195868e-01,  1.4877319e-01, -7.5886250e-01,\n",
            "       -3.8206577e-02,  9.2114699e-01, -1.6832790e+00, -2.1111314e-01,\n",
            "        8.4834772e-01,  8.8806181e+00], dtype=float32), 'agent_2': Array([ 5.6792623e-01, -4.2528829e-01,  1.5592658e-03, -4.8809610e-02,\n",
            "        9.0373957e-01,  5.3601575e-01,  5.4899436e-01,  5.3558260e-01,\n",
            "       -9.6342194e-01,  5.5195868e-01,  1.4877319e-01, -7.5886250e-01,\n",
            "       -3.8206577e-02,  9.2114699e-01, -1.6832790e+00, -2.1111314e-01,\n",
            "       -8.8815504e-01,  8.3963022e+00], dtype=float32), 'agent_3': Array([ 5.6792623e-01, -4.2528829e-01,  1.5592658e-03, -4.8809610e-02,\n",
            "        9.0373957e-01,  5.3601575e-01,  5.4899436e-01,  5.3558260e-01,\n",
            "        5.5195868e-01,  7.6915008e-01,  1.4877319e-01, -7.5886250e-01,\n",
            "       -3.8206577e-02,  9.2114699e-01, -1.6832790e+00, -2.1111314e-01,\n",
            "       -3.1957465e-01,  8.7410002e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.52458984 0.48416352 0.5269771  0.48758394 0.5244931  0.4848595\n",
            " 0.5251413  0.48340994]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.428994, dtype=float32), 'agent_0': Array(-6.428994, dtype=float32), 'agent_1': Array(-6.428994, dtype=float32), 'agent_2': Array(-6.428994, dtype=float32), 'agent_3': Array(-6.428994, dtype=float32)}\n",
            "step: 505\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6764489e-01, -4.2563099e-01,  2.6776008e-02, -3.0585076e-03,\n",
            "        9.0449548e-01,  5.5012763e-01,  1.1363308e+00,  5.4219580e-01,\n",
            "        5.2535439e-01,  5.1621401e-01,  6.0524940e-01, -7.2200298e-01,\n",
            "        3.1063557e-01,  1.7878522e+00, -2.0326490e+00, -8.1435308e-02,\n",
            "        4.2027110e-01,  5.6942077e+00], dtype=float32), 'agent_1': Array([ 5.6764489e-01, -4.2563099e-01,  2.6776008e-02, -3.0585076e-03,\n",
            "        9.0449548e-01,  5.5012763e-01,  5.4219580e-01, -5.3773069e-01,\n",
            "        5.2535439e-01,  5.1621401e-01,  6.0524940e-01, -7.2200298e-01,\n",
            "        3.1063557e-01,  1.7878522e+00, -2.0326490e+00, -8.1435308e-02,\n",
            "       -6.8947983e-01,  8.7195082e+00], dtype=float32), 'agent_2': Array([ 5.6764489e-01, -4.2563099e-01,  2.6776008e-02, -3.0585076e-03,\n",
            "        9.0449548e-01,  5.5012763e-01,  5.4219580e-01,  5.2535439e-01,\n",
            "       -5.2463979e-01,  5.1621401e-01,  6.0524940e-01, -7.2200298e-01,\n",
            "        3.1063557e-01,  1.7878522e+00, -2.0326490e+00, -8.1435308e-02,\n",
            "        6.2300473e-01,  1.0391536e+01], dtype=float32), 'agent_3': Array([ 5.6764489e-01, -4.2563099e-01,  2.6776008e-02, -3.0585076e-03,\n",
            "        9.0449548e-01,  5.5012763e-01,  5.4219580e-01,  5.2535439e-01,\n",
            "        5.1621401e-01,  1.1999348e+00,  6.0524940e-01, -7.2200298e-01,\n",
            "        3.1063557e-01,  1.7878522e+00, -2.0326490e+00, -8.1435308e-02,\n",
            "       -4.8032716e-01,  8.6319904e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.9006836 1.1009402 0.9017622 1.0945451 0.8993198 1.0995535 0.9004737\n",
            " 1.0968652]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3194269, dtype=float32), 'agent_0': Array(0.3194269, dtype=float32), 'agent_1': Array(0.3194269, dtype=float32), 'agent_2': Array(0.3194269, dtype=float32), 'agent_3': Array(0.3194269, dtype=float32)}\n",
            "step: 506\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59470797, -0.42038637,  0.02483187,  0.02290694,  0.906716  ,\n",
            "        0.55810577,  1.2636237 ,  0.53213805,  0.5656512 ,  0.5403827 ,\n",
            "        0.79045296, -0.31893253,  0.8005738 ,  0.11173744,  0.89005697,\n",
            "       -0.19385384, -0.50436795, -0.82521963], dtype=float32), 'agent_1': Array([ 0.59470797, -0.42038637,  0.02483187,  0.02290694,  0.906716  ,\n",
            "        0.55810577,  0.53213805, -0.46266016,  0.5656512 ,  0.5403827 ,\n",
            "        0.79045296, -0.31893253,  0.8005738 ,  0.11173744,  0.89005697,\n",
            "       -0.19385384,  0.08816496, -1.2908794 ], dtype=float32), 'agent_2': Array([ 0.59470797, -0.42038637,  0.02483187,  0.02290694,  0.906716  ,\n",
            "        0.55810577,  0.53213805,  0.5656512 , -0.4566241 ,  0.5403827 ,\n",
            "        0.79045296, -0.31893253,  0.8005738 ,  0.11173744,  0.89005697,\n",
            "       -0.19385384,  0.21878883, -1.5051461 ], dtype=float32), 'agent_3': Array([ 0.59470797, -0.42038637,  0.02483187,  0.02290694,  0.906716  ,\n",
            "        0.55810577,  0.53213805,  0.5656512 ,  0.5403827 ,  1.2743312 ,\n",
            "        0.79045296, -0.31893253,  0.8005738 ,  0.11173744,  0.89005697,\n",
            "       -0.19385384,  0.84491515, -1.437837  ], dtype=float32)}\n",
            "ctrl action chosen: [0.32271332 1.3203763  0.32176238 1.3215853  0.32242158 1.3210381\n",
            " 0.32266697 1.3221236 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2548957, dtype=float32), 'agent_0': Array(-2.2548957, dtype=float32), 'agent_1': Array(-2.2548957, dtype=float32), 'agent_2': Array(-2.2548957, dtype=float32), 'agent_3': Array(-2.2548957, dtype=float32)}\n",
            "step: 507\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6225027 , -0.42594165,  0.01822359,  0.03359726,  0.90394294,\n",
            "        0.5116356 ,  1.2770902 ,  0.52781034,  0.5293548 ,  0.5429207 ,\n",
            "        0.65312386, -0.5957842 ,  0.19119978,  0.459976  ,  0.06035559,\n",
            "        0.03211715, -0.3246682 , -0.27363572], dtype=float32), 'agent_1': Array([ 0.6225027 , -0.42594165,  0.01822359,  0.03359726,  0.90394294,\n",
            "        0.5116356 ,  0.52781034, -0.49134472,  0.5293548 ,  0.5429207 ,\n",
            "        0.65312386, -0.5957842 ,  0.19119978,  0.459976  ,  0.06035559,\n",
            "        0.03211715,  0.3820426 , -0.55873346], dtype=float32), 'agent_2': Array([ 0.6225027 , -0.42594165,  0.01822359,  0.03359726,  0.90394294,\n",
            "        0.5116356 ,  0.52781034,  0.5293548 , -0.5025543 ,  0.5429207 ,\n",
            "        0.65312386, -0.5957842 ,  0.19119978,  0.459976  ,  0.06035559,\n",
            "        0.03211715, -0.7050223 , -0.5049077 ], dtype=float32), 'agent_3': Array([ 0.6225027 , -0.42594165,  0.01822359,  0.03359726,  0.90394294,\n",
            "        0.5116356 ,  0.52781034,  0.5293548 ,  0.5429207 ,  1.2556214 ,\n",
            "        0.65312386, -0.5957842 ,  0.19119978,  0.459976  ,  0.06035559,\n",
            "        0.03211715, -0.08284938, -0.29704857], dtype=float32)}\n",
            "ctrl action chosen: [-0.6691085   0.72981215 -0.6685498   0.7316179  -0.6683348   0.73031473\n",
            " -0.66916007  0.7325972 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0069623, dtype=float32), 'agent_0': Array(-2.0069623, dtype=float32), 'agent_1': Array(-2.0069623, dtype=float32), 'agent_2': Array(-2.0069623, dtype=float32), 'agent_3': Array(-2.0069623, dtype=float32)}\n",
            "step: 508\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.60862523,  -0.5656043 ,   0.01761432,   0.04089483,\n",
            "         0.8234739 ,   0.1065775 ,   1.2443995 ,   0.16227858,\n",
            "         0.09418989,   0.15034826,   0.59285164,  -0.56648254,\n",
            "        -0.5873561 ,   0.5510179 ,  -0.3007936 ,   8.249892  ,\n",
            "       -10.199712  ,  -0.30974388], dtype=float32), 'agent_1': Array([ 0.60862523, -0.5656043 ,  0.01761432,  0.04089483,  0.8234739 ,\n",
            "        0.1065775 ,  0.16227858, -0.5059058 ,  0.09418989,  0.15034826,\n",
            "        0.59285164, -0.56648254, -0.5873561 ,  0.5510179 , -0.3007936 ,\n",
            "        8.249892  , -9.727765  ,  0.43036595], dtype=float32), 'agent_2': Array([  0.60862523,  -0.5656043 ,   0.01761432,   0.04089483,\n",
            "         0.8234739 ,   0.1065775 ,   0.16227858,   0.09418989,\n",
            "        -0.50421405,   0.15034826,   0.59285164,  -0.56648254,\n",
            "        -0.5873561 ,   0.5510179 ,  -0.3007936 ,   8.249892  ,\n",
            "       -11.158299  ,   0.6928288 ], dtype=float32), 'agent_3': Array([  0.60862523,  -0.5656043 ,   0.01761432,   0.04089483,\n",
            "         0.8234739 ,   0.1065775 ,   0.16227858,   0.09418989,\n",
            "         0.15034826,   1.2444258 ,   0.59285164,  -0.56648254,\n",
            "        -0.5873561 ,   0.5510179 ,  -0.3007936 ,   8.249892  ,\n",
            "       -10.410925  ,   0.2143086 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3334451  -0.977651   -0.33391842 -0.9744204  -0.3342724  -0.97565705\n",
            " -0.33275414 -0.972709  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.33337545, dtype=float32), 'agent_0': Array(-0.33337545, dtype=float32), 'agent_1': Array(-0.33337545, dtype=float32), 'agent_2': Array(-0.33337545, dtype=float32), 'agent_3': Array(-0.33337545, dtype=float32)}\n",
            "step: 509\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.57843107,  -0.6942472 ,  -0.02212163,   0.02108967,\n",
            "         0.7190874 ,  -0.313218  ,   0.85882294,  -0.22521704,\n",
            "        -0.35924911,  -0.26450506,   0.8508682 ,   0.08752346,\n",
            "        -0.5220294 ,   0.84503615,   2.4103663 ,   6.090678  ,\n",
            "        -7.913727  , -10.619668  ], dtype=float32), 'agent_1': Array([ 0.57843107, -0.6942472 , -0.02212163,  0.02108967,  0.7190874 ,\n",
            "       -0.313218  , -0.22521704, -0.80604476, -0.35924911, -0.26450506,\n",
            "        0.8508682 ,  0.08752346, -0.5220294 ,  0.84503615,  2.4103663 ,\n",
            "        6.090678  , -6.988073  , -8.004995  ], dtype=float32), 'agent_2': Array([ 0.57843107, -0.6942472 , -0.02212163,  0.02108967,  0.7190874 ,\n",
            "       -0.313218  , -0.22521704, -0.35924911, -0.78765464, -0.26450506,\n",
            "        0.8508682 ,  0.08752346, -0.5220294 ,  0.84503615,  2.4103663 ,\n",
            "        6.090678  , -8.276471  , -7.8955426 ], dtype=float32), 'agent_3': Array([ 0.57843107, -0.6942472 , -0.02212163,  0.02108967,  0.7190874 ,\n",
            "       -0.313218  , -0.22521704, -0.35924911, -0.26450506,  0.92696595,\n",
            "        0.8508682 ,  0.08752346, -0.5220294 ,  0.84503615,  2.4103663 ,\n",
            "        6.090678  , -7.5206165 , -8.463063  ], dtype=float32)}\n",
            "ctrl action chosen: [0.0439908  0.7962563  0.04262558 0.8015463  0.04412784 0.79944146\n",
            " 0.04352665 0.80501926]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.41124868, dtype=float32), 'agent_0': Array(-0.41124868, dtype=float32), 'agent_1': Array(-0.41124868, dtype=float32), 'agent_2': Array(-0.41124868, dtype=float32), 'agent_3': Array(-0.41124868, dtype=float32)}\n",
            "step: 510\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5425669 , -0.7276923 , -0.00656511,  0.03432971,  0.68501276,\n",
            "       -0.44515514,  0.8290989 , -0.33670983, -0.5016109 , -0.3889949 ,\n",
            "        0.9242058 , -0.51825047, -0.9165406 , -0.31691527, -1.8324054 ,\n",
            "        0.74257535, -1.0874536 ,  3.342388  ], dtype=float32), 'agent_1': Array([ 0.5425669 , -0.7276923 , -0.00656511,  0.03432971,  0.68501276,\n",
            "       -0.44515514, -0.33670983, -0.76084954, -0.5016109 , -0.3889949 ,\n",
            "        0.9242058 , -0.51825047, -0.9165406 , -0.31691527, -1.8324054 ,\n",
            "        0.74257535, -0.45244506,  3.7805884 ], dtype=float32), 'agent_2': Array([ 0.5425669 , -0.7276923 , -0.00656511,  0.03432971,  0.68501276,\n",
            "       -0.44515514, -0.33670983, -0.5016109 , -0.73804843, -0.3889949 ,\n",
            "        0.9242058 , -0.51825047, -0.9165406 , -0.31691527, -1.8324054 ,\n",
            "        0.74257535, -1.4979028 ,  4.03967   ], dtype=float32), 'agent_3': Array([ 0.5425669 , -0.7276923 , -0.00656511,  0.03432971,  0.68501276,\n",
            "       -0.44515514, -0.33670983, -0.5016109 , -0.3889949 ,  0.94009864,\n",
            "        0.9242058 , -0.51825047, -0.9165406 , -0.31691527, -1.8324054 ,\n",
            "        0.74257535, -0.7327491 ,  3.059294  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5444931  -1.9329175   0.5453304  -1.9288527   0.54525965 -1.9309396\n",
            "  0.54698503 -1.9268409 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.6375282, dtype=float32), 'agent_0': Array(0.6375282, dtype=float32), 'agent_1': Array(0.6375282, dtype=float32), 'agent_2': Array(0.6375282, dtype=float32), 'agent_3': Array(0.6375282, dtype=float32)}\n",
            "step: 511\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5091981 , -0.63842577, -0.05101851,  0.00982561,  0.7679278 ,\n",
            "       -0.1384901 ,  0.51233923, -0.01343071, -0.21715954, -0.09014044,\n",
            "        1.1268616 ,  0.39896965, -0.507915  ,  0.03242338,  3.0774393 ,\n",
            "       -6.9954734 ,  8.3678665 , -9.382747  ], dtype=float32), 'agent_1': Array([ 0.5091981 , -0.63842577, -0.05101851,  0.00982561,  0.7679278 ,\n",
            "       -0.1384901 , -0.01343071, -1.0517274 , -0.21715954, -0.09014044,\n",
            "        1.1268616 ,  0.39896965, -0.507915  ,  0.03242338,  3.0774393 ,\n",
            "       -6.9954734 ,  9.14783   , -9.296608  ], dtype=float32), 'agent_2': Array([ 0.5091981 , -0.63842577, -0.05101851,  0.00982561,  0.7679278 ,\n",
            "       -0.1384901 , -0.01343071, -0.21715954, -0.9485586 , -0.09014044,\n",
            "        1.1268616 ,  0.39896965, -0.507915  ,  0.03242338,  3.0774393 ,\n",
            "       -6.9954734 ,  8.221396  , -6.832148  ], dtype=float32), 'agent_3': Array([ 0.5091981 , -0.63842577, -0.05101851,  0.00982561,  0.7679278 ,\n",
            "       -0.1384901 , -0.01343071, -0.21715954, -0.09014044,  0.62078655,\n",
            "        1.1268616 ,  0.39896965, -0.507915  ,  0.03242338,  3.0774393 ,\n",
            "       -6.9954734 ,  8.713891  , -9.296663  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.8056034  1.2307595 -1.8060919  1.22942   -1.808581   1.2339733\n",
            " -1.8052429  1.231075 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.05622, dtype=float32), 'agent_0': Array(-6.05622, dtype=float32), 'agent_1': Array(-6.05622, dtype=float32), 'agent_2': Array(-6.05622, dtype=float32), 'agent_3': Array(-6.05622, dtype=float32)}\n",
            "step: 512\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.49069107,  -0.7531375 ,  -0.01053929,   0.02744206,\n",
            "         0.657206  ,  -0.5411301 ,   0.69518787,  -0.3861237 ,\n",
            "        -0.58670026,  -0.45737734,   1.1634827 ,  -0.44813156,\n",
            "        -0.3343284 ,  -1.4110534 ,  -2.6857708 ,   8.042651  ,\n",
            "       -10.284457  ,   7.585687  ], dtype=float32), 'agent_1': Array([  0.49069107,  -0.7531375 ,  -0.01053929,   0.02744206,\n",
            "         0.657206  ,  -0.5411301 ,  -0.3861237 ,  -0.93453234,\n",
            "        -0.58670026,  -0.45737734,   1.1634827 ,  -0.44813156,\n",
            "        -0.3343284 ,  -1.4110534 ,  -2.6857708 ,   8.042651  ,\n",
            "       -10.202309  ,   7.4237857 ], dtype=float32), 'agent_2': Array([ 0.49069107, -0.7531375 , -0.01053929,  0.02744206,  0.657206  ,\n",
            "       -0.5411301 , -0.3861237 , -0.58670026, -0.6978187 , -0.45737734,\n",
            "        1.1634827 , -0.44813156, -0.3343284 , -1.4110534 , -2.6857708 ,\n",
            "        8.042651  , -8.420603  ,  9.662622  ], dtype=float32), 'agent_3': Array([ 0.49069107, -0.7531375 , -0.01053929,  0.02744206,  0.657206  ,\n",
            "       -0.5411301 , -0.3861237 , -0.58670026, -0.45737734,  0.70539236,\n",
            "        1.1634827 , -0.44813156, -0.3343284 , -1.4110534 , -2.6857708 ,\n",
            "        8.042651  , -9.908095  ,  5.5985856 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.41216403 -1.2201723   0.41135183 -1.217718    0.41246837 -1.2167004\n",
            "  0.4128268  -1.2167579 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.326359, dtype=float32), 'agent_0': Array(-7.326359, dtype=float32), 'agent_1': Array(-7.326359, dtype=float32), 'agent_2': Array(-7.326359, dtype=float32), 'agent_3': Array(-7.326359, dtype=float32)}\n",
            "step: 513\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5010732 , -0.73120123, -0.04687689,  0.01399715,  0.68040544,\n",
            "       -0.46845016,  0.5683326 , -0.34027708, -0.4710478 , -0.4037672 ,\n",
            "        1.1014938 ,  0.09610653, -0.01819134,  1.0859197 ,  2.7727804 ,\n",
            "       -2.9243352 ,  3.8876252 , -6.5999804 ], dtype=float32), 'agent_1': Array([ 0.5010732 , -0.73120123, -0.04687689,  0.01399715,  0.68040544,\n",
            "       -0.46845016, -0.34027708, -1.090215  , -0.4710478 , -0.4037672 ,\n",
            "        1.1014938 ,  0.09610653, -0.01819134,  1.0859197 ,  2.7727804 ,\n",
            "       -2.9243352 ,  3.5867934 , -7.4077535 ], dtype=float32), 'agent_2': Array([ 0.5010732 , -0.73120123, -0.04687689,  0.01399715,  0.68040544,\n",
            "       -0.46845016, -0.34027708, -0.4710478 , -0.8010604 , -0.4037672 ,\n",
            "        1.1014938 ,  0.09610653, -0.01819134,  1.0859197 ,  2.7727804 ,\n",
            "       -2.9243352 ,  4.7459254 , -6.897025  ], dtype=float32), 'agent_3': Array([ 0.5010732 , -0.73120123, -0.04687689,  0.01399715,  0.68040544,\n",
            "       -0.46845016, -0.34027708, -0.4710478 , -0.4037672 ,  0.47574288,\n",
            "        1.1014938 ,  0.09610653, -0.01819134,  1.0859197 ,  2.7727804 ,\n",
            "       -2.9243352 ,  3.9147398 , -5.26649   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5484666   0.10889301 -0.5477291   0.1079258  -0.54813784  0.10910666\n",
            " -0.54948264  0.11136177]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1876218, dtype=float32), 'agent_0': Array(-1.1876218, dtype=float32), 'agent_1': Array(-1.1876218, dtype=float32), 'agent_2': Array(-1.1876218, dtype=float32), 'agent_3': Array(-1.1876218, dtype=float32)}\n",
            "step: 514\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49564236, -0.763514  , -0.04839813, -0.00240227,  0.6439708 ,\n",
            "       -0.562645  ,  0.5206242 , -0.49460796, -0.53441626, -0.5361375 ,\n",
            "        0.9205818 , -0.4266739 , -0.13713837, -0.0343792 ,  0.16583803,\n",
            "        1.2427909 , -0.41713163, -0.00533553], dtype=float32), 'agent_1': Array([ 4.9564236e-01, -7.6351398e-01, -4.8398130e-02, -2.4022735e-03,\n",
            "        6.4397079e-01, -5.6264502e-01, -4.9460796e-01, -1.1377803e+00,\n",
            "       -5.3441626e-01, -5.3613752e-01,  9.2058182e-01, -4.2667389e-01,\n",
            "       -1.3713837e-01, -3.4379195e-02,  1.6583803e-01,  1.2427909e+00,\n",
            "       -3.2412295e+00,  1.2938378e+00], dtype=float32), 'agent_2': Array([ 0.49564236, -0.763514  , -0.04839813, -0.00240227,  0.6439708 ,\n",
            "       -0.562645  , -0.49460796, -0.53441626, -0.8804643 , -0.5361375 ,\n",
            "        0.9205818 , -0.4266739 , -0.13713837, -0.0343792 ,  0.16583803,\n",
            "        1.2427909 , -0.9360368 ,  0.21596417], dtype=float32), 'agent_3': Array([ 0.49564236, -0.763514  , -0.04839813, -0.00240227,  0.6439708 ,\n",
            "       -0.562645  , -0.49460796, -0.53441626, -0.5361375 ,  0.5352281 ,\n",
            "        0.9205818 , -0.4266739 , -0.13713837, -0.0343792 ,  0.16583803,\n",
            "        1.2427909 , -2.1523926 ,  0.5795723 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.6206317   0.00989906 -0.622787    0.0087814  -0.62072235  0.01167748\n",
            " -0.62168175  0.01189168]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.3390932, dtype=float32), 'agent_0': Array(1.3390932, dtype=float32), 'agent_1': Array(1.3390932, dtype=float32), 'agent_2': Array(1.3390932, dtype=float32), 'agent_3': Array(1.3390932, dtype=float32)}\n",
            "step: 515\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50670785, -0.76383746, -0.07369779, -0.01071213,  0.6410976 ,\n",
            "       -0.52035105,  0.51828533, -0.5631494 , -0.5329155 , -0.5492093 ,\n",
            "        0.78811646, -0.22621155, -0.00286102,  0.42090893,  1.0733109 ,\n",
            "       -0.28022   ,  1.0976139 ,  0.23964056], dtype=float32), 'agent_1': Array([ 0.50670785, -0.76383746, -0.07369779, -0.01071213,  0.6410976 ,\n",
            "       -0.52035105, -0.5631494 , -1.1605406 , -0.5329155 , -0.5492093 ,\n",
            "        0.78811646, -0.22621155, -0.00286102,  0.42090893,  1.0733109 ,\n",
            "       -0.28022   , -0.11527029, -0.6137296 ], dtype=float32), 'agent_2': Array([ 0.50670785, -0.76383746, -0.07369779, -0.01071213,  0.6410976 ,\n",
            "       -0.52035105, -0.5631494 , -0.5329155 , -0.9107432 , -0.5492093 ,\n",
            "        0.78811646, -0.22621155, -0.00286102,  0.42090893,  1.0733109 ,\n",
            "       -0.28022   ,  0.24218127, -1.3449677 ], dtype=float32), 'agent_3': Array([ 0.50670785, -0.76383746, -0.07369779, -0.01071213,  0.6410976 ,\n",
            "       -0.52035105, -0.5631494 , -0.5329155 , -0.5492093 ,  0.5489863 ,\n",
            "        0.78811646, -0.22621155, -0.00286102,  0.42090893,  1.0733109 ,\n",
            "       -0.28022   ,  0.4935808 ,  0.15478069], dtype=float32)}\n",
            "ctrl action chosen: [-1.1478691  1.577748  -1.1499399  1.5781898 -1.1499195  1.5765111\n",
            " -1.1486875  1.5825683]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0921304, dtype=float32), 'agent_0': Array(1.0921304, dtype=float32), 'agent_1': Array(1.0921304, dtype=float32), 'agent_2': Array(1.0921304, dtype=float32), 'agent_3': Array(1.0921304, dtype=float32)}\n",
            "step: 516\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5142019 , -0.76527023, -0.04083116, -0.00992134,  0.6423362 ,\n",
            "       -0.5350212 ,  0.8302691 , -0.5482804 , -0.5518709 , -0.5544501 ,\n",
            "        0.4172325 , -0.6128788 ,  0.1311779 , -1.6069708 , -1.9155738 ,\n",
            "       -0.1658779 , -0.75810224,  8.393078  ], dtype=float32), 'agent_1': Array([ 5.1420188e-01, -7.6527023e-01, -4.0831156e-02, -9.9213384e-03,\n",
            "        6.4233619e-01, -5.3502119e-01, -5.4828042e-01, -8.2636493e-01,\n",
            "       -5.5187088e-01, -5.5445009e-01,  4.1723251e-01, -6.1287880e-01,\n",
            "        1.3117790e-01, -1.6069708e+00, -1.9155738e+00, -1.6587789e-01,\n",
            "        6.8389606e-01,  9.9478359e+00], dtype=float32), 'agent_2': Array([ 0.5142019 , -0.76527023, -0.04083116, -0.00992134,  0.6423362 ,\n",
            "       -0.5350212 , -0.5482804 , -0.5518709 , -0.6275716 , -0.5544501 ,\n",
            "        0.4172325 , -0.6128788 ,  0.1311779 , -1.6069708 , -1.9155738 ,\n",
            "       -0.1658779 , -0.45674333,  9.27886   ], dtype=float32), 'agent_3': Array([ 0.5142019 , -0.76527023, -0.04083116, -0.00992134,  0.6423362 ,\n",
            "       -0.5350212 , -0.5482804 , -0.5518709 , -0.5544501 ,  0.7852025 ,\n",
            "        0.4172325 , -0.6128788 ,  0.1311779 , -1.6069708 , -1.9155738 ,\n",
            "       -0.1658779 , -0.25089565,  6.6087375 ], dtype=float32)}\n",
            "ctrl action chosen: [0.9932749  0.67328995 0.994992   0.67867273 0.99403894 0.6765895\n",
            " 0.99567235 0.6825239 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.066206, dtype=float32), 'agent_0': Array(-6.066206, dtype=float32), 'agent_1': Array(-6.066206, dtype=float32), 'agent_2': Array(-6.066206, dtype=float32), 'agent_3': Array(-6.066206, dtype=float32)}\n",
            "step: 517\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4701698e-01, -5.9352016e-01,  1.3072562e-02,  2.3502437e-03,\n",
            "        8.0470961e-01,  3.7108462e-02,  1.1901555e+00,  5.7943426e-02,\n",
            "        7.1084541e-03, -1.4409694e-02,  8.8100433e-01, -5.9382915e-01,\n",
            "        1.0550380e+00, -3.9929178e-01, -1.3407478e+00, -1.2330993e+01,\n",
            "        1.5974149e+01,  5.5389705e+00], dtype=float32), 'agent_1': Array([ 5.4701698e-01, -5.9352016e-01,  1.3072562e-02,  2.3502437e-03,\n",
            "        8.0470961e-01,  3.7108462e-02,  5.7943426e-02, -4.3954328e-01,\n",
            "        7.1084541e-03, -1.4409694e-02,  8.8100433e-01, -5.9382915e-01,\n",
            "        1.0550380e+00, -3.9929178e-01, -1.3407478e+00, -1.2330993e+01,\n",
            "        1.5673080e+01,  1.1234776e+00], dtype=float32), 'agent_2': Array([ 5.4701698e-01, -5.9352016e-01,  1.3072562e-02,  2.3502437e-03,\n",
            "        8.0470961e-01,  3.7108462e-02,  5.7943426e-02,  7.1084541e-03,\n",
            "       -4.5734990e-01, -1.4409694e-02,  8.8100433e-01, -5.9382915e-01,\n",
            "        1.0550380e+00, -3.9929178e-01, -1.3407478e+00, -1.2330993e+01,\n",
            "        1.5280605e+01, -5.8626682e-01], dtype=float32), 'agent_3': Array([ 5.4701698e-01, -5.9352016e-01,  1.3072562e-02,  2.3502437e-03,\n",
            "        8.0470961e-01,  3.7108462e-02,  5.7943426e-02,  7.1084541e-03,\n",
            "       -1.4409694e-02,  1.0916120e+00,  8.8100433e-01, -5.9382915e-01,\n",
            "        1.0550380e+00, -3.9929178e-01, -1.3407478e+00, -1.2330993e+01,\n",
            "        1.4362063e+01,  6.6361799e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.6612414   1.558231   -0.66458905  1.5478424  -0.6648099   1.5432441\n",
            " -0.6634556   1.5601859 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2949598, dtype=float32), 'agent_0': Array(-1.2949598, dtype=float32), 'agent_1': Array(-1.2949598, dtype=float32), 'agent_2': Array(-1.2949598, dtype=float32), 'agent_3': Array(-1.2949598, dtype=float32)}\n",
            "step: 518\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63057303, -0.62279385,  0.02653772,  0.02104196,  0.7816527 ,\n",
            "        0.02708012,  1.2802092 , -0.00580301, -0.06143381, -0.13412622,\n",
            "        1.0596275 , -0.4401207 ,  1.7313242 ,  0.32745343, -0.21834584,\n",
            "        5.5002627 , -5.5050025 ,  0.42269394], dtype=float32), 'agent_1': Array([ 6.3057303e-01, -6.2279385e-01,  2.6537718e-02,  2.1041960e-02,\n",
            "        7.8165269e-01,  2.7080119e-02, -5.8030072e-03, -4.6859148e-01,\n",
            "       -6.1433807e-02, -1.3412622e-01,  1.0596275e+00, -4.4012070e-01,\n",
            "        1.7313242e+00,  3.2745343e-01, -2.1834584e-01,  5.5002627e+00,\n",
            "       -6.7275677e+00, -1.3066955e+00], dtype=float32), 'agent_2': Array([ 6.3057303e-01, -6.2279385e-01,  2.6537718e-02,  2.1041960e-02,\n",
            "        7.8165269e-01,  2.7080119e-02, -5.8030072e-03, -6.1433807e-02,\n",
            "       -4.7995579e-01, -1.3412622e-01,  1.0596275e+00, -4.4012070e-01,\n",
            "        1.7313242e+00,  3.2745343e-01, -2.1834584e-01,  5.5002627e+00,\n",
            "       -6.8464236e+00, -1.6381490e+00], dtype=float32), 'agent_3': Array([ 6.3057303e-01, -6.2279385e-01,  2.6537718e-02,  2.1041960e-02,\n",
            "        7.8165269e-01,  2.7080119e-02, -5.8030072e-03, -6.1433807e-02,\n",
            "       -1.3412622e-01,  1.2856505e+00,  1.0596275e+00, -4.4012070e-01,\n",
            "        1.7313242e+00,  3.2745343e-01, -2.1834584e-01,  5.5002627e+00,\n",
            "       -7.4991727e+00, -9.8933101e-02], dtype=float32)}\n",
            "ctrl action chosen: [0.10304423 0.10590228 0.10669484 0.10452797 0.10626085 0.10449395\n",
            " 0.10652377 0.10888514]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6175528, dtype=float32), 'agent_0': Array(-3.6175528, dtype=float32), 'agent_1': Array(-3.6175528, dtype=float32), 'agent_2': Array(-3.6175528, dtype=float32), 'agent_3': Array(-3.6175528, dtype=float32)}\n",
            "step: 519\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOkuNBb2v4cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}